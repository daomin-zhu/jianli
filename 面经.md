
字符串转Int，疏忽了，没考虑数字非常大(大到long long都存不了)，面试官提醒完成；(15min)
```
class Solution {
public:
    int strToInt(string str) {
        int i = 0, flag = 1;
        long res = 0; //默认flag = 1，正数
        while (str[i] == ' ') i ++;
        if (str[i] == '-') flag = -1;
        if (str[i] == '-' || str[i] == '+') i ++;
        for (; i < str.size() && isdigit(str[i]); i ++)  {
            res = res * 10 + (str[i] - '0');
            if (res >= INT_MAX && flag == 1) return  INT_MAX;
            if (res > INT_MAX && flag == -1) return  INT_MIN;
        } 
        return flag * res;
    }
};

```
判断平衡二叉树；(15min)
```
int getDepth(TreeNode* root, bool& flag){
    if(root){
        int leftDepth = getDepth(root->left, flag);
        int rightDepth = getDepth(root->right, flag);
        if(fabs(leftDepth - rightDepth) > 1){
            flag = false;
        }
        return (leftDepth > rightDepth ? leftDepth : rightDepth) + 1;
    }
    return 0;
}

bool IsBalanced_Solution(TreeNode* root) {
    bool flag = true;
    getDepth(root, flag);
    if(flag){
        return true;
    }
    else{
        return false;
    }
}
```

 redis五种数据类型 + 底层实现 + 跳表解释
```
简单动态字符串（SDS）：
    字符串作为redis中最常见的数据结构，所有键值对的键，字符串对象的值底层都是由简单动态字符串实现的。
    在redis中，它并未使用C语言中的字符串，而是自己实现了一种叫做SDS的数据结构，它的结构表示如下
    struct sdshdr{
        //记录buf数组中已使用字节的长度
        int len;
        //记录buf数组中剩余空间的长度
        int free;
        //字节数组，用于存储字符串
        char buf[];
    };
SDS具有以下特点：
    获取长度的时间复杂度为O(1)，因为len直接保存了当前字符串的长度；
    避免缓存区溢出，当C字符串进行拼接之时，如果未事先对当前字符串的空间进行调整，则可能会导致当前字符串的数据溢出，
    导致拼接过来的字符串内容被意外的修改，而SDS在拼接之前会进行自动的调整和扩展；
    减少内存分配次数，在SDS拼接发生以后，如果此时的len小于1MB则它会多分配和len大小相同的未使用空间，用free表示，
    如果大于1MB，则会分配1MB的为使用空间；
    惰性空间释放，当字符串进行缩短的时候，程序并不会立即回收空间（也可以调用API立即释放），而是记录到free之中，以便于后序拼接的使用
链表:
    链表提供了节点重排以及节点顺序访问的能力，redis中的列表对象主要是由压缩列表和双端链表实现。
双端链表（linkedlist):
    type struct list{
        //表头节点
        listNode *head;
        //表尾节点
        listNode *tail;
        //包含的节点总数
        unsigned long len;
        //一些操作函数 dup free match...
    };
其中每个节点都有一个prev指针和一个next指针，而节点中的value则是列表对象具体的值
    type struct ziplist{
        //整个压缩列表的字节数
        uint32_t zlbytes;
        //记录压缩列表尾节点到头结点的字节数，直接可以求节点的地址
        uint32_t zltail_offset;
        //记录了节点数，有多种类型，默认如下
        uint16_t zllength;
        //节点
        列表节点 entryX;
previous_entry_length:
    记录了压缩列表中前一节点的字节长度，当小于254字节时，它的长度为1字节，当大于254字节时，
    长度为5字节且后4字节保存真正的长度，用于表尾向表头遍历；
content: 节点所存储的内容，可以是一个字节数组或者整数；
encoding: 记录content属性中所保存的数据类型以及长度。

编码：
    当列表对象所存储的字符串元素长度小于64字节并且元素数量小于512个时，使用ziplist编码，否则使用linkedlist编码
集合对象的编码可以是整数集合（intset）或者字典（hashtable）
    typedef struct intset{
    //编码方式
    uint32_t encoding;
    //元素数量
    uint32_t length;
    //存储元素的数组
    int8_t contents[];
    }
整数集合的每个元素都是contents数组的一个数组项，各个项在数组中按值得大小从小到大有序排列，并且不包含重复的项。
contents数组中元素的类型由encoding决定，当新加入元素之时，如果元素的编码大于contents是数组的编码，
    则会将所有元素的编码升级为新加入元素的编码，然后再插入。编码不会发生降级。
哈希表结构如下:
    typedef struct dictht{
    //哈希表数组
    dictEntry **table;
    //哈希表大小
    unsigned long size;
    //哈希表掩码，总是等于size-1，存储时计算索引值
    unsigned long sizemask;
    //已有元素数量
    unsigned long used;
    }

跳跃表
有序集合的编码可以是压缩列表（ziplist）或者跳跃表（skiplist）
    typedef struct zskiplist{
    //跳跃表的头结点
    zskiplistNode header;
    //尾节点
    zskiplistNode tail;
    //跳跃表中层数最大的节点的层数（不包括头结点）
    unsigned long level;
    //跳跃表长度（不包括头节点）
    unsigned int length;

1、 自上而下，查找第一次出现结点的索引，并逐层找到每一层对应的结点（因为每层索引都是由上层索引晋升的），时间复杂度是O(logN)。
2、 删除每一层查找到的结点，如果该层只剩下一个结点，删除整个一层，时间复杂度是O(logN)。
```

cookie session
```
Session是在服务端保存的一个数据结构，用来跟踪用户的状态，这个数据可以保存在集群、数据库、文件中；
Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式。
```
mysql 聚簇索引和非聚簇索引
```
聚簇索引:
    对于 非聚簇索引 来说，每次通过索引检索到所需行号后，还需要通过叶子上的磁盘地址去磁盘内取数据（回行）消耗时间。
    为了优化这部分回行取数据时间，InnoDB 引擎采用了聚簇索引。
聚簇索引，即将数据存入索引叶子页面上。对于 InnoDB 引擎来说，叶子页面不再存该行对应的地址，而是直接存储数据：
聚簇索引的优点:
    聚簇索引将索引和数据行保存在同一个B-Tree中，查询通过聚簇索引可以直接获取数据，相比非聚簇索引需要第二次查询（非覆盖索引的情况下）效率要高。
    聚簇索引对于范围查询的效率很高，因为其数据是按照大小排列的，
聚簇索引的缺点:
    聚簇索引的更新代价比较高，如果更新了行的聚簇索引列，就需要将数据移动到相应的位置。这可能因为要插入的页已满而导致“页分裂”。
    插入速度严重依赖于插入顺序，按照主键进行插入的速度是加载数据到Innodb中的最快方式。如果不是按照主键插入，
        最好在加载完成后使用OPTIMIZE TABLE命令重新组织一下表。
    聚簇索引在插入新行和更新主键时，可能导致“页分裂”问题。
    聚簇索引可能导致全表扫描速度变慢，因为可能需要加载物理上相隔较远的页到内存中（需要耗时的磁盘寻道操作）。
非聚簇索引:
    非聚簇索引，又叫二级索引。二级索引的叶子节点中保存的不是指向行的物理指针，而是行的主键值。
    当通过二级索引查找行，存储引擎需要在二级索引中找到相应的叶子节点，获得行的主键值，
    然后使用主键去聚簇索引中查找数据行，这需要两次B-Tree查找。
```
stl标准库：vector、list、rb_tree

map底层实现，和unordered_map的区别
```
map优点：
    有序性，这是map结构最大的优点，其元素的有序性在很多应用中都会简化很多的操作
    红黑树，内部实现一个红黑书使得map的很多操作在lgn的时间复杂度下就可以实现，因此效率非常的高
    缺点： 
    空间占用率高，因为map内部实现了红黑树，虽然提高了运行效率，但是因为每一个节点都需要额外保存父节点、孩子节点和红/黑性质，
    使得每一个节点都占用大量的空间
适用处：对于那些有顺序要求的问题，用map会更高效一些
unordered_map优点： 
    因为内部实现了哈希表，因此其查找速度非常的快
    缺点： 
        哈希表的建立比较耗费时间
适用处：
    对于查找问题，unordered_map会更加高效一些，因此遇到查找问题，常会考虑一下用unordered_map
总结：
    内存占有率的问题就转化成红黑树 VS hash表 , 还是unorder_map占用的内存要高。
    但是unordered_map执行效率要比map高很多
    对于unordered_map或unordered_set容器，其遍历顺序与创建该容器时输入的顺序不一定相同，
    因为遍历是按照哈希表从前往后依次遍历的
map和unordered_map的使用
    unordered_map的用法和map是一样的，提供了 insert，size，count等操作，并且里面的元素也是以pair类型来存贮的。
    其底层实现是完全不同的，上方已经解释了，但是就外部使用来说却是一致的。
```
C++的多态如何体现？
```
静态多态：
    操作符重载，函数重载，函数模板；
动态多态：虚函数机制；
```
线程池和内存池了解吗？
```
多并发， 解决内存碎片， 分别详细说
```
常用排序方法里哪些平均复杂度？
|排序方式|时间平均情况|最坏情况|最好情况|空间复杂度|稳定性|
|插入排序|O(n2)|O(n2)|O(n)|O(1)|稳定|
|希尔排序|O(n1.3)|||O(1)|不稳定|
|冒泡排序|O(n2)|O(n2)|O(n)|O(1)|稳定|
|快速排序|O(nlogn)|O(n2)|O(nlog2n)|O(logn)|不稳定|
|选择排序|O(n2)|O(n2)|O(n2)|O(1)|不稳定|
|堆排序|O(nlogn)|O(nlog2n)|O(nlog2n)|O(n)|不稳定|
|归并排序|O(nlog2n)|O(nlog2n)|O(nlogn)|O(n)|稳定|

```
快速排序的基本思想
    快速排序使用分治的思想，通过一趟排序将待排序列分割成两部分，其中一部分记录的关键字均比另一部分记录的关键字小。
    之后分别对这两部分记录继续进行排序，以达到整个序列有序的目的。

快速排序的三个步骤
    选择基准：在待排序列中，按照某种方式挑出一个元素，作为 “基准”（pivot）；
    分割操作：以该基准在序列中的实际位置，把序列分成两个子序列。此时，在基准左边的元素都比该基准小，在基准右边的元素都比基准大；
    递归地对两个序列进行快速排序，直到序列为空或者只有一个元素；
选择基准元的方式
    对于分治算法，当每次划分时，算法若都能分成两个等长的子序列时，那么分治算法效率会达到最大。
    也就是说，基准的选择是很重要的。选择基准的方式决定了两个分割后两个子序列的长度，进而对整个算法的效率产生决定性影响。
最理想的方法是，选择的基准恰好能把待排序序列分成两个等长的子序列。
```
```
public static void QsortCommon(int[] arr, int low, int high)
{
    if (low >= high) return;                        //递归出口
    int partition = Partition(arr, low, high);      //将 >= x 的元素交换到右边区域，将 <= x 的元素交换到左边区域
    QsortCommon(arr, low, partition - 1);
    QsortCommon(arr, partition + 1, high);
}
 
/// <summary>
/// 固定基准元，默认数组第一个数为基准元，左右分组，返回基准元的下标
/// </summary>
public static int Partition(int[] arr, int low, int high)
{
    int first = low;
    int last = high;
    int key = arr[low];                             //取第一个元素作为基准元
    while (first < last)
    {
        while (first < last && arr[last] >= key)
            last--;
            arr[first] = arr[last];
            while (first < last && arr[first] <= key)
                first++;
            arr[last] = arr[first];
        }
        arr[first] = key;                               //基准元居中
        return first;
    }
```
讲一下堆排的工作原理
```
堆(heap)，这里所说的堆是数据结构中的堆，而不是内存模型中的堆。堆通常是一个可以被看做一棵树，它满足下列性质：
[性质一] 堆中任意节点的值总是不大于(不小于)其子节点的值；
[性质二] 堆总是一棵完全树。
将任意节点不大于其子节点的堆叫做最小堆或小根堆，而将任意节点不小于其子节点的堆叫做最大堆或大根堆
最大堆：父结点的键值总是大于或等于任何一个子节点的键值；最小堆：父结点的键值总是小于或等于任何一个子节点的键值
/*
 * 最大堆的向上调整算法(从start开始向上直到0，调整堆)
 *
 * 注：数组实现的堆中，第N个节点的左孩子的索引值是(2N+1)，右孩子的索引是(2N+2)。
 *
 * 参数说明：
 *     start -- 被上调节点的起始位置(一般为数组中最后一个元素的索引)
 */
static void maxheap_filterup(int start)
{
    int c = start;            // 当前节点(current)的位置
    int p = (c-1)/2;        // 父(parent)结点的位置 
    int tmp = m_heap[c];        // 当前节点(current)的大小

    while(c > 0)
    {
        if(m_heap[p] >= tmp)
            break;
        else
        {
            m_heap[c] = m_heap[p];
            c = p;
            p = (p-1)/2;   
        }       
    }
    m_heap[c] = tmp;
}
  
/* 
 * 将data插入到二叉堆中
 *
 * 返回值：
 *     0，表示成功
 *    -1，表示失败
 */
int maxheap_insert(int data)
{
    // 如果"堆"已满，则返回
    if(m_size == m_capacity)
        return -1;
 
    m_heap[m_size] = data;        // 将"数组"插在表尾
    maxheap_filterup(m_size);    // 向上调整堆
    m_size++;                    // 堆的实际容量+1

    return 0;
}

```

10. 讲一下BFS与DFS
还有一些问题记不清了。。。。
TCP/IP四层模型
```
数据链路层:
    数据链路层实现了网卡接口的网络驱动程序，以处理数据在物理媒介（比如以太网、令牌环等）上的传输。
    数据链路层两个常用的协议是ARP协议（Address Resolve Protocol，地址解析协议）和
    RARP协议（ReverseAddress Resolve Protocol，逆地址解析协议）。
    它们实现了IP地址和机器物理地址（通常是MAC地址，以太网、令牌环和802.11无线网络都使用MAC地址）之间的相互转换。
    网络层使用IP地址寻址一台机器，而数据链路层使用物理地址寻址一台机器，因此网络层必须先将目标机器的IP地址转化成其物理地址，
    才能使用数据链路层提供的服务，这就是ARP协议的用途
网络层:
    网络层实现数据包的选路和转发。
    WAN（Wide Area Network，广域网）通常使用众多分级的路由器来连接分散的主机或LAN（Local Area Network，局域网），
    因此，通信的两台主机一般不是直接相连的，而是通过多个中间节点（路由器）连接的。
    网络层的任务就是选择这些中间节点，以确定两台主机之间的通信路径。同时，网络层对上层协议隐藏了网络拓扑连接的细节，
    使得在传输层和网络应用程序看来，通信的双方是直接相连的。
    网络层最核心的协议是IP协议（Internet Protocol，因特网协议）。IP协议根据数据包的目的IP地址来决定如何投递它。
    如果数据包不能直接发送给目标主机，那么IP协议就为它寻找一个合适的下一跳（next hop）路由器，并将数据包交付给该路由器来转发。
    多次重复这一过程，数据包最终到达目标主机，或者由于发送失败而被丢弃。可见，IP协议使用逐跳（hop by hop）的方式确定通信路径。
传输层:
    传输层为两台主机上的应用程序提供端到端（end to end）的通信。与网络层使用的逐跳通信方式不同，
    传输层只关心通信的起始端和目的端，而不在乎数据包的中转过程。
    TCP协议（Transmission Control Protocol，传输控制协议）为应用层提供可靠的、面向连接的和基于流（stream）的服务。
    TCP协议使用超时重传、数据确认等方式来确保数据包被正确地发送至目的端，因此TCP服务是可靠的。
    使用TCP协议通信的双方必须先建立TCP连接，并在内核中为该连接维持一些必要的数据结构，比如连接的状态、读写缓冲区，
    以及诸多定时器等。当通信结束时，双方必须关闭连接以释放这些内核数据。TCP服务是基于流的。
    基于流的数据没有边界（长度）限制，它源源不断地从通信的一端流入另一端。
    发送端可以逐个字节地向数据流中写入数据，接收端也可以逐个字节地将它们读出。
    UDP协议（User Datagram Protocol，用户数据报协议）则与TCP协议完全相反，它为应用层提供不可靠、无连接和基于数据报的服务。
    “不可靠”意味着UDP协议无法保证数据从发送端正确地传送到目的端。如果数据在中途丢失，
    或者目的端通过数据校验发现数据错误而将其丢弃，则UDP协议只是单地通知应用程序发送失败。
    因此，使用UDP协议的应用程序通常要自己处理数据确认、超时重传等逻辑。UDP协议是无连接的，即通信双方不保持一个长久的联系，
    因此应用程序每次发送数据都要明确指定接收端的地址（IP地址等信息）。基于数据报的服务，是相对基于流的服务而言的。
    每个UDP数据报都有一个长度，接收端必须以该长度为最小单位将其所有内容一次性读出，否则数据将被截断。
应用层:
    应用层负责处理应用程序的逻辑。数据链路层、网络层和传输层负责处理网络通信细节，这部分必须既稳定又高效，
    因此它们都在内核空间中实现。而应用层则在用户空间实现，因为它负责处理众多逻辑，比如文件传输、名称查询和网络管理等。
    如果应用层也在内核中实现，则会使内核变得非常庞大。当然，也有少数服务器程序是在内核中实现的，
    这样代码就无须在用户空间和内核空间来回切换（主要是数据的复制），极大地提高了工作效率。
    不过这种代码实现起来较复杂，不够灵活，且不便于移植。
ping是应用程序，而不是协议，前面说过它利用ICMP报文检测网络连接，是调试网络环境的必备工具。
telnet协议是一种远程登录协议，它使我们能在本地完成远程任务。
```
写一下strstr的实现函数
```
#include <stdio.h>
#include <assert.h>
const char* strstr(const char* src, const char* sub)
{
    const char *bp;
    const char *sp;
    if(!src || !sub)
    {
        return src;
    }
    /* 遍历src字符串  */
    while(*src)
    {
        /* 用来遍历子串 */
        bp = src;
        sp = sub;
        do
        {
            if(!*sp)  /*到了sub的结束位置，返回src位置   */
                return src;
        }while(*bp++ == *sp ++);
        src ++;
    }
    return NULL;
}
```
•epoll，select实现的功能，聊一聊多路复用的理解；
一个函数在堆栈中是如何放置的，static变量，全局变量是放置在哪里？
```
```
1、算法题：
•提供总数为100万个数，可能会分10次提供，即每次提供10万个，然后你如何在每次的能刷选出TOP10个最大的数据
•实现一个链表可以随意插入的函数，并计算插入的时间复杂度
•双向链表与单向连接插入的时间复杂度怎么表示
•你了解的排序算法有哪些？

2、数据结构：
•是否连接红黑树
•是否了解数据结构的“堆”

3、调试工具
•如果要检测一个程序内存泄漏，需要怎么做？
•gdb中的backtrace是什么意思
```
backtrace命令，可以用于回溯函数调用栈
```
如何用GDB进行内存泄漏调试？

二面：
说一下你做过项目中，你认为比较出现的点是什么：
写一个函数：假如str1=“12345678”，str2=“246”，那么str2可以是str1的顺序子串：

在map中做删除value（注意iterator失效问题）
单向链表的反转（双指针）
现场面二面：
撮合是单进程的么？ 挂了怎么办？（备机。。。）
如果服务端挂了，使得连接断了，怎么恢复从而客户无感知？（不知道。。。）
数据库如果挂了怎么办（备机。。。）
安全编程：知道缓冲区溢出漏洞吗？
问：给定一个n，给出0~n过程中2出现的次数// 比如13，则0/1/2/3..../12 一共出现了两个2，所以结果是2；
答：假设一共有n位，每一位的数字分别为num_n;则num_n上出现2的次数为f(n)。。。。。
问：给出前序遍历和中序遍历，输出后序遍历；
用后序遍历：（用中序遍历确定前序遍历的左子树和右子树范围）
map in_map; 存储中序遍历每个字符的下标便于后面查找
问：由3、5、7的乘积组成的数，求第k个大的值； 3/5/7/9(33)/15(35)
将3、5、7存入set，循环k，每次从set中取出一位，然后3、5、*7再存入set；

三次握手四次挥手，time_wait，2MSL
什么情况下需要在构造函数中做特殊处理：
1.会有一些堆分配的内容  
2.const、包含其他类需要构造 //堆分配、const、包含其他类需要调用构造函数的、（const什么时候初始化—）初始化列表）

构造和析构的顺序：父类的构造、包含其他类，其他类的构造；
线程同步、线程的生产者消费者模式实现（A完成了通知B，B完成了C再接着做这种协作模式）：
算法题：两个有序链表合并；单链表查找倒数第k个节点；（时间复杂度是多少）
多线程：实现单链表的插入和get，线程安全（不仅是atomic，还有atomic_flag、）；
auto和decltype的区别；
多态情况下，父类指针指向子类对象，怎么用这个父类指针调用到父类的对应虚函数？
在main函数之前会执行哪些操作；
lambda表达式[=]中间的等号是什么意思；
```
=按值传递父作用域的变量 &按引用传递父作用域的变量 this 传递this
```

、主要考察项目，通过项目提出基础问题；

2、之前有微服务经验，面试官就详细问到微服务的架构、框架的实现、服务治理、分布式一致性等问题；

3、之前有玩过日志监控系统，首先还是考察架构，ELK的相关知识，重点描述Elasticsearch的一些架构原理，比如倒排索引的原理；

4、问消息队列的相关知识，接触过Kafka，问了Kafka中消息可以被多个消费者消费吗？；以及选举机制和HW机制；

5、开放性问题，讲一个之前遇到的问题，并如何解决的。这个描述生产过程中运行的问题，并描述排查问题；

6、数据库和Redis相关问题，数据库考察索引的原理以及几种事务的区别。Redis问数据结构，延时队列如何实现，分布式锁原理；


问题；

6、数据库和Redis相关问题，数据库考察索引的原理以及几种事务的区别。Redis问数据结构，延时队列如何实现，分布式锁原理；


负载均衡算法；
```
1、轮询法
    将请求按顺序轮流地分配到后端服务器上，它均衡地对待后端的每一台服务器，而不关心服务器实际的连接数和当前的系统负载。
2、随机法
    通过系统的随机算法，根据后端服务器的列表大小值来随机选取其中的一台服务器进行访问。由概率统计理论可以得知，随着客户端调用服务端的次数增多，
    其实际效果越来越接近于平均分配调用量到后端的每一台服务器，也就是轮询的结果。
3、源地址哈希法
    源地址哈希的思想是根据获取客户端的IP地址，通过哈希函数计算得到的一个数值，用该数值对服务器列表的大小进行取模运算，得到的结果便是客服端要访问服务器的序号。
    采用源地址哈希法进行负载均衡，同一IP地址的客户端，当后端服务器列表不变时，它每次都会映射到同一台后端服务器进行访问。
4、加权轮询法
    不同的后端服务器可能机器的配置和当前系统的负载并不相同，因此它们的抗压能力也不相同。给配置高、负载低的机器配置更高的权重，让其处理更多的请；
    而配置低、负载高的机器，给其分配较低的权重，降低其系统负载，加权轮询能很好地处理这一问题，并将请求顺序且按照权重分配到后端。
5、加权随机法
    与加权轮询法一样，加权随机法也根据后端机器的配置，系统的负载分配不同的权重。不同的是，它是按照权重随机请求后端服务器，而非顺序。
6、最小连接数法
    最小连接数算法比较灵活和智能，由于后端服务器的配置不尽相同，对于请求的处理有快有慢，它是根据后端服务器当前的连接情况，动态地选取其中当前
```
ngnix如何做限流；
```
    NGINX限流使用漏桶算法（leaky bucket algorithm），该算法广泛应用于通信和基于包交换计算机网络中，用来处理当带宽被限制时的突发情况。
    和一个从上面进水，从下面漏水的桶的原理很相似；如果进水的速率大于漏水的速率，这个桶就会发生溢出。
    在请求处理过程中，水代表从客户端来的请求，而桶代表了一个队列，请求在该队列中依据先进先出（FIFO）算法等待被处理。
    漏的水代表请求离开缓冲区并被服务器处理，溢出代表了请求被丢弃并且永不被服务
Nginx中我们使用ngx_http_limit_req_module模块来限制请求的访问频率，基于漏桶算法原理实现。
    接下来我们使用 nginx limit_req_zone 和 limit_req 两个指令，限制单个IP的请求处理速率。
    key ：定义限流对象，binary_remote_addr 是一种key，表示基于 remote_addr(客户端IP) 来做限流，binary_ 的目的是压缩内存占用量。
    zone：定义共享内存区来存储访问信息， myRateLimit:10m 表示一个大小为10M，名字为myRateLimit的内存区域。
            1M能存储16000 IP地址的访问信息，10M可以存储16W IP地址访问信息。
    rate 用于设置最大访问速率，rate=10r/s 表示每秒最多处理10个请求。Nginx 实际上以毫秒为粒度来跟踪请求信息，因此 10r/s 实际上是限制：
    每100毫秒处理一个请求。这意味着，自上一个请求处理完后，若后续100毫秒内又有请求到达，将拒绝处理该请求。
二、限制访问频率（突发流量）
    按上面的配置在流量突然增大时，超出的请求将被拒绝，无法处理突发流量，那么在处理突发流量的时候，该怎么处理呢？
    Nginx提供了 burst 参数来解决突发流量的问题，并结合 nodelay 参数一起使用。
    burst 译为突发、爆发，表示在超过设定的处理速率后能额外处理的请求数。

    burst=20 nodelay表示这20个请求立马处理，不能延迟，相当于特事特办。不过，即使这20个突发请求立马处理结束，后续来了请求也不会立马处理。
    burst=20 相当于缓存队列中占了20个坑，即使请求被处理了，这20个位置这只能按 100ms一个来释放。这就达到了速率稳定，但突然流量也能正常处理的效果。
三、限制并发连接数
    Nginx 的ngx_http_limit_conn_module模块提供了对资源连接数进行限制的功能，使用 limit_conn_zone 和 limit_conn 两个指令就可以了。
    limit_conn perip 20：对应的key是 $binary_remote_addr，表示限制单个IP同时最多能持有20个连接。 
    limit_conn perserver 100：对应的key是 $server_name，表示虚拟主机(server) 同时能处理并发连接的总数。
    注意，只有当 request header 被后端server处理后，这个连接才进行计数。
```
5、四层LVS和七层Ngnix的区别；
```
简单理解四层和七层负载均衡:
所谓四层就是基于IP+端口的负载均衡；七层就是基于URL等应用层信息的负载均衡；同理，还有基于MAC地址的二层负载均衡和基于IP地址的三层负载均衡。
    换句换说，二层负载均衡会通过一个虚拟MAC地址接收请求，然后再分配到真实的MAC地址；
    三层负载均衡会通过一个虚拟IP地址接收请求，然后再分配到真实的IP地址；
    四层通过虚拟IP+端口接收请求，然后再分配到真实的服务器；
    七层通过虚拟的URL或主机名接收请求，然后再分配到真实的服务器。

所谓的四到七层负载均衡，就是在对后台的服务器进行负载均衡时，依据四层的信息或七层的信息来决定怎么样转发流量。 
    比如四层的负载均衡，就是通过发布三层的IP地址（VIP），然后加四层的端口号，来决定哪些流量需要做负载均衡，对需要处理的流量进行NAT处理，
    转发至后台服务器，并记录下这个TCP或者UDP的流量是由哪台服务器处理的，后续这个连接的所有流量都同样转发到同一台服务器处理。
    七层的负载均衡，就是在四层的基础上（没有四层是绝对不可能有七层的），再考虑应用层的特征，比如同一个Web服务器的负载均衡，
    除了根据VIP加80端口辨别是否需要处理的流量，还可根据七层的URL、浏览器类别、语言来决定是否要进行负载均衡。
    举个例子，如果你的Web服务器分成两组，一组是中文语言的，一组是英文语言的，那么七层负载均衡就可以当用户来访问你的域名时，
    自动辨别用户语言，然后选择对应的语言服务器组进行负载均衡处理。

    负载均衡器通常称为四层交换机或七层交换机。四层交换机主要分析IP层及TCP/UDP层，实现四层流量负载均衡。
    七层交换机除了支持四层负载均衡以外，还有分析应用层的信息，如HTTP协议URI或Cookie信息。
        负载均衡分为L4 switch（四层交换），即在OSI第4层工作，就是TCP层啦。此种Load Balance不理解应用协议（如HTTP/FTP/MySQL等等）。例子：LVS，F5。
        另一种叫做L7 switch（七层交换），OSI的最高层，应用层。此时，该Load Balancer能理解应用协议。例子：  haproxy，MySQL Proxy。

第一，技术原理上的区别。
    所谓四层负载均衡，也就是主要通过报文中的目标地址和端口，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。
    以常见的TCP为例，负载均衡设备在接收到第一个来自客户端的SYN 请求时，即通过上述方式选择一个最佳的服务器，
    并对报文中目标IP地址进行修改(改为后端服务器IP），直接转发给该服务器。TCP的连接建立，即三次握手是客户端和服务器直接建立的，
    负载均衡设备只是起到一个类似路由器的转发动作。在某些部署情况下，为保证服务器回包可以正确返回给负载均衡设备，
    在转发报文的同时可能还会对报文原来的源地址进行修改。
    所谓七层负载均衡，也称为“内容交换”，也就是主要通过报文中的真正有意义的应用层内容，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。
    以常见的TCP为例，负载均衡设备如果要根据真正的应用层内容再选择服务器，只能先代理最终的服务器和客户端建立连接(三次握手)后，
    才可能接受到客户端发送的真正应用层内容的报文，然后再根据该报文中的特定字段，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。
    负载均衡设备在这种情况下，更类似于一个代理服务器。负载均衡和前端的客户端以及后端的服务器会分别建立TCP连接。所以从这个技术原理上来看，
    七层负载均衡明显的对负载均衡设备的要求更高，处理七层的能力也必然会低于四层模式的部署方式。
第二，应用场景的需求。
    七层应用负载的好处，是使得整个网络更"智能化"。例如访问一个网站的用户流量，可以通过七层的方式，将对图片类的请求转发到特定的图片服务器并可以使用缓存技术；
    将对文字类的请求可以转发到特定的文字服务器并可以使用压缩技术。当然这只是七层应用的一个小案例，从技术原理上，
    这种方式可以对客户端的请求和服务器的响应进行任意意义上的修改，极大的提升了应用系统在网络层的灵活性。很多在后台，
    例如Nginx或者Apache上部署的功能可以前移到负载均衡设备上，例如客户请求中的Header重写，服务器响应中的关键字过滤或者内容插入等功能。

    另外一个常常被提到功能就是安全性。网络中最常见的SYN Flood攻击，即黑客控制众多源客户端，使用虚假IP地址对同一目标发送SYN攻击，通常这种攻击会大量发送SYN报文，
    耗尽服务器上的相关资源，以达到Denial of Service(DoS)的目的。从技术原理上也可以看出，四层模式下这些SYN攻击都会被转发到后端的服务器上；
    而七层模式下这些SYN攻击自然在负载均衡设备上就截止，不会影响后台服务器的正常运营。另外负载均衡设备可以在七层层面设定多种策略，过滤特定报文，
    例如SQL Injection等应用层面的特定攻击手段，从应用层面进一步提高系统整体安全。
    现在的7层负载均衡，主要还是着重于应用HTTP协议，所以其应用范围主要是众多的网站或者内部信息平台等基于B/S开发的系统。
     4层负载均衡则对应其他TCP应用，例如基于C/S开发的ERP等系统。
```

6、微服务架构的设计思路；
```
```
问了秒杀系统的如何设计，分接入层、接口层、消息队列层、逻辑层四个方面讲解，接入层可以做服务治理相关事情，接口层做抢购开关、黑白名单、随机拒绝等处理，逻辑层具体抢购逻辑实现，涉及到redis分布式锁以及DB和Redis的一致性问题。
3、从秒杀系统还引申出分布式事务的几种实现，二段式、三段式、补偿型(TCC)、基于可靠消息服务的消息队列实现。重点讨论了这几种的实现和区别，要求画出基于可靠消息服务的消息队列实现分布式事务的架构图，以及上游服务和下游服务如何保证消息可靠性和一致性。
4、考察微服务架构，服务拆分的原则、RPC框架原理、配置管理(etcd)的一致性协议raft选举原理。
5、考察服务治理，服务限流算法，服务降级的指标和恢复指标，服务熔断。
6、开放性问题：遇到印象最深的问题，以及如何解决的。

C++面向对象的三种特性？（每条详细说说）
C++继承和组合？你在实际项目中是怎么使用的？什么情况下使用继承？什么情况下使用组合？
C++构造函数可以是虚函数吗？为什么？
C++析构函数可以是虚函数吗？为什么要将析构函数设置为虚函数？
C++如何实现多态？虚表指针是什么时候被初始化的？实例化一个对象需要那几个阶段？（三个）
C++偏特化？
重载、重写、覆盖？
static关键字的作用？（要全面）怎么实现的？
inline和宏定义的区别？inline是如何实现的？宏定义是如何实现的？
指针和引用的区别？怎么实现的？
malloc和mmap的底层实现？malloc分配的是什么？（底层详细回答）
Linux进程地址空间布局？（这里又问道虚拟内存和分页、页表这些东西）
tcp的握手挥手过程？（详细）tcp为什么要连接？tcp建立连接这里你是怎么理解的？
半连接队列？全连接队列？
tcp流量控制和拥塞控制？
time_wait状态？为什么是2msl？
有很多close_wait怎么解决？
阻塞和非阻塞？同步和异步？
五种IO模型？
select和epoll有什么区别？epoll的LT和ET模式？
udp为什么是不可靠的？bind和connect对于udp的作用是什么？
NAT是什么？底层实现原理？
斐波那契数列的非递归写法？（写出代码）
共享桌面用你熟悉的任意画图工具画项目架构图？（我用的ProcessOn）
聊项目？
总共用时两个小时吧，问了很多，有些已经想不起来了。
？然后又扯到位域
map如何遍历删除所有元素？迭代器失效？
map和unordered_map的底层实现
一个unique_ptr怎么赋值给另一个unique_ptr对象？（std::move）
一个进程能不能绑定到一个cpu？系统调用接口是什么？线程呢？
对于使用tcp通信的两端，如果client已经退出，此时服务端继续send会出现什么问题？这个当然就要扯到SIGPIPE信号了？
map的底层实现？zset的底层实现？为什么zset不使用红黑树作为其底层实现？为什么map不使用跳表作为其底层实现？
写道题吧：非递归求二叉树的高度？（需要写测试用例）

