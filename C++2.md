
### C++基础
extern 关键字的作用

```
    extern声明变量在外部的定义？
        1、 全局变量如果不在文件开始定义,则其作用域有效区域为定义部分到文件结尾,之前的部分如果需要使用全局变量,需要使用extern声明
        2、 如果多个文件公用一个全局变量,在非定义文件中需要使用extern声明
    extern 修饰函数？
        与修饰变量作用类似,如果在一个文件中定义了函数func1，在另一个文件中可以使用extern声明这个函数，然后直接调用;不需要包含头文件；一般使用在较小的文件中，较大的文件通过头文件来使用；
    extern C的作用
        为了能够正确实现C++代码调用其他C语言代码。加上extern "C"后,会指示编译器这部分代码按C语言的方式进行编译。由于C++支持函数重载,因此编译器编译函数的过程中会将函数的参数类型加到编译后的代码中,而不仅仅是函数名;而C语言不支持函数重载,因此编译C语言代码不会带上函数的参数类型,一般只包含函数名；
```

为什么要使用字节对齐
```
字节对齐是C/C++编译器的一种技术手段，主要是在可接受空间浪费的前提下，尽可能地提高对相同元素过程的快速处理。
（比如32位系统，4字节对齐能使CPU访问速度提高）
需要字节对齐的根本原因在于CPU访问数据的效率问题。
    因为现代计算机都使用了Cache。Cache可以看成一些可以用非常快的速度进行访问的临时内存。但是Cache的容量不大，CPU访问内存非常慢，
    所以硬件会将平时经常使用的内容存放到Cache里面。Cache是通过一些Cache Line来组织的，每一条Cache Line一般包含16个字节，32个字节或64个字节等。 
    比如某个计算机一级Cache的Cache Line长度是32个字节，那么每段Cache Line总是会包含32个字节对齐的一段内存。
    现在有一个4字节的整数，如果它的地址不是4字节对齐的，那么就有可能访问它的时候，需要使用两条Cache Line,这增加了总线通讯量，而且增加了对Cache的使用量，
    而且使用的数据没有在Cache里面（这时需要将数据从内存调入Cache,会非常慢）的机会会增加，这些都降低了程序的速度。
字节对齐的原则
    从0位置开始存储；
    变量存储的起始位置是该变量大小的整数倍；
    结构体总的大小是其最大元素的整数倍，不足的后面要补齐；
    结构体中包含结构体，从结构体中最大元素的整数倍开始存；
    如果加入pragma pack(n) ，取n和变量自身大小较小的一个。
```
C++11有哪些新特性
```
    1）关键字及新语法：auto、nullptr、for
    2）STL容器：std::array、std::forward_list、std::unordered_map、std::unordered_set
    3）多线程：std::thread、std::atomic、std::condition_variable
    4）智能指针内存管理：std::shared_ptr、std::weak_ptr
    5）其他：std::function、std::bind和lamda表达式
```
引用和指针的区别？
```
1) 指针是一个实体，需要分配内存空间。引用只是变量的别名，不需要分配内存空间。
2) 引用在定义的时候必须进行初始化，并且不能够改变。指针在定义的时候不一定要初始化，并且指向的空间可变。（注：不能有引用的值不能为NULL）
3) 有多级指针，但是没有多级引用，只能有一级引用。
4) 指针和引用的自增运算结果不一样。（指针是指向下一个空间，引用时引用的变量值加1）
5) sizeof 引用得到的是所指向的变量（对象）的大小，而sizeof 指针得到的是指针本身的大小。
6) 引用访问一个变量是直接访问，而指针访问一个变量是间接访问。
7) 使用指针前最好做类型检查，防止野指针的出现；
8) 引用底层是通过指针实现的；
9) 作为参数时也不同，传指针的实质是传值，传递的值是指针的地址；传引用的实质是传地址，传递的是变量的地址。
```

指针与数组千丝万缕的联系
```
    一个一维int数组的数组名实际上是一个int* const 类型；
    一个二维int数组的数组名实际上是一个int (*const p)[n];
    数组名做参数会退化为指针，除了sizeof
```
静态变量什么时候初始化
```
1) 初始化只有一次，但是可以多次赋值，在主程序之前，编译器已经为其分配好了内存。
2) 静态局部变量和全局变量一样，数据都存放在全局区域，所以在主程序之前，编译器已经为其分配好了内存，但在C和C++中静态局部变量的初始化节点又有点不太一样。
    在C中，初始化发生在代码执行之前，编译阶段分配好内存之后，就会进行初始化，所以我们看到在C语言中无法使用变量对静态局部变量进行初始化，在程序运行结束，
    变量所处的全局内存会被全部回收。
    在C++中，初始化时在执行相关代码时才会进行初始化，主要是由于C++引入对象后，要进行初始化必须执行相应构造函数和析构函数，
    在构造函数或析构函数中经常会需要进行某些程序中需要进行的特定操作，并非简单地分配内存。所以C++标准定为全局或静态对象是有首次用到时才会进行构造，
    并通过atexit()来管理。在程序结束，按照构造顺序反方向进行逐个析构。
    所以在C++中是可以使用变量对静态局部变量进行初始化的。
```
指针和const的用法
```
1) 当const修饰指针时，由于const的位置不同，它的修饰对象会有所不同。
2) int const p2中const修饰p2的值,所以理解为p2的值不可以改变，即p2只能指向固定的一个变量地址，但可以通过p2读写这个变量的值。顶层指针表示指针本身是一个常量
3) int const *p1或者const int p1两种情况中const修饰p1，所以理解为p1的值不可以改变，即不可以给p1赋值改变p1指向变量的值，但可以通过给p赋值不同的地址改变这个指针指向。底层指针表示指针所指向的变量是一个常量。
4) int const *const p;
```
5. C++中的指针参数传递和引用参数传递
```
1) 指针参数传递本质上是值传递，它所传递的是一个地址值。值传递过程中，被调函数的形式参数作为被调函数的局部变量处理，会在栈中开辟内存空间以存放由主调函数传递进来的实参值，从而形成了实参的一个副本（替身）。值传递的特点是，被调函数对形式参数的任何操作都是作为局部变量进行的，不会影响主调函数的实参变量的值（形参指针变了，实参指针不会变）。
2) 引用参数传递过程中，被调函数的形式参数也作为局部变量在栈中开辟了内存空间，但是这时存放的是由主调函数放进来的实参变量的地址。被调函数对形参（本体）的任何操作都被处理成间接寻址，即通过栈中存放的地址访问主调函数中的实参变量（根据别名找到主调函数中的本体）。因此，被调函数对形参的任何操作都会影响主调函数中的实参变量。
3) 引用传递和指针传递是不同的，虽然他们都是在被调函数栈空间上的一个局部变量，但是任何对于引用参数的处理都会通过一个间接寻址的方式操作到主调函数中的相关变量。而对于指针传递的参数，如果改变被调函数中的指针地址，它将应用不到主调函数的相关变量。如果想通过指针参数传递来改变主调函数中的相关变量（地址），那就得使用指向指针的指针或者指针引用。
4) 从编译的角度来讲，程序在编译时分别将指针和引用添加到符号表上，符号表中记录的是变量名及变量所对应地址。指针变量在符号表上对应的地址值为指针变量的地址值，而引用在符号表上对应的地址值为引用对象的地址值（与实参名字不同，地址相同）。符号表生成之后就不会再改，因此指针可以改变其指向的对象（指针变量中的值可以改），而引用对象则不能修改。
```
6. 形参与实参的区别？
```
1) 形参变量只有在被调用时才分配内存单元，在调用结束时， 即刻释放所分配的内存单元。因此，形参只有在函数内部有效。 函数调用结束返回主调函数后则不能再使用该形参变量。
2) 实参可以是常量、变量、表达式、函数等， 无论实参是何种类型的量，在进行函数调用时，它们都必须具有确定的值， 以便把这些值传送给形参。 因此应预先用赋值，输入等办法使实参获得确定值，会产生一个临时变量。
3) 实参和形参在数量上，类型上，顺序上应严格一致， 否则会发生“类型不匹配”的错误。
4) 函数调用中发生的数据传送是单向的。 即只能把实参的值传送给形参，而不能把形参的值反向地传送给实参。 因此在函数调用过程中，形参的值发生改变，而实参中的值不会变化。
5) 当形参和实参不是指针类型时，在该函数运行时，形参和实参是不同的变量，他们在内存中位于不同的位置，形参将实参的内容复制一份，在该函数运行结束的时候形参被释放，而实参内容不会改变。
    1) 值传递：有一个形参向函数所属的栈拷贝数据的过程，如果值传递的对象是类对象  或是大的结构体对象，将耗费一定的时间和空间。（传值）
    2) 指针传递：同样有一个形参向函数所属的栈拷贝数据的过程，但拷贝的数据是一个固定为4字节的地址。（传值，传递的是地址值）
    3) 引用传递：同样有上述的数据拷贝过程，但其是针对地址的，相当于为该数据所在的地址起了一个别名。（传地址）
    4) 效率上讲，指针传递和引用传递比值传递效率高。一般主张使用引用传递，代码逻辑上更加紧凑、清晰。
```
7. static的用法和作用？
```
1.先来介绍它的第一条也是最重要的一条：隐藏。（static函数，static变量均可）当同时编译多个文件时，所有未加static前缀的全局变量和函数都具有全局可见性。
2.static的第二个作用是保持变量内容的持久。（static变量中的记忆功能和全局生存期）存储在静态数据区的变量会在程序刚开始运行时就完成初始化，也是唯一的一次初始化。
    共有两种变量存储在静态存储区：全局变量和static变量，只不过和全局变量比起来，static可以控制变量的可见范围，说到底static还是用来隐藏的。
3.static的第三个作用是默认初始化为0（static变量）其实全局变量也具备这一属性，因为全局变量也存储在静态数据区。
    在静态数据区，内存中所有的字节默认值都是0x00，某些时候这一特点可以减少程序员的工作量。
4.static的第四个作用：
    C++中的类成员声明static
        1) 函数体内static变量的作用范围为该函数体，不同于auto变量，该变量的内存只被分配一次，因此其值在下次调用时仍维持上次的值； 
        2) 在模块内的static全局变量可以被模块内所用函数访问，但不能被模块外其它函数访问；  
        3) 在模块内的static函数只可被这一模块内的其它函数调用，这个函数的使用范围被限制在声明它的模块内；  
        4) 在类中的static成员变量属于整个类所拥有，对类的所有对象只有一份拷贝；  
        5) 在类中的static成员函数属于整个类所拥有，这个函数不接收this指针，因而只能访问类的static成员变量。类内：
        6) static类对象必须要在类外进行初始化，static修饰的变量先于对象存在，所以static修饰的变量要在类外初始化；
        7) 由于static修饰的类成员属于类，不属于对象，因此static类成员函数是没有this指针的，this指针是指向本对象的指针。正因为没有this指针，
            所以static类成员函数不能访问非static的类成员，只能访问 static修饰的类成员；
        8) static成员函数不能被virtual修饰，static成员不属于任何对象或实例，所以加上virtual没有任何实际意义；静态成员函数没有this指针，
            虚函数的实现是为每一个对象分配一个vptr指针，而vptr是通过this指针调用的，所以不能为virtual；虚函数的调用关系，this->vptr->ctable->virtual function

-----------------------------------------------------------------------------------------------------------------------------------------------
    static 修饰全局变量
        限定变量使用范围只能在本文件中使用,即使使用extern外部声明也不可以在其他文件内使用；
    static 修饰普通函数
        限定使用范围,这个函数只能在本文件内使用,不能被其他文件调用.
    static 修饰成员变量
        static成员变量属于类,不属于某个具体的对象,即使创建多个对象,所有对象使用的都是这份内存中的数据,当某个对象修改这个变量,其他对象也会影响其他对象
        static成员变量必须在类声明的外部初始化,具体形式为:  type class::name = value
        静态成员变量初始化时不能再加static 但必须要有数据类型
        static成员变量的内存既不是在声明类时分配,也不是在创建对象时分配,而是在初始化时分配；
        static既可以通过类直接访问 Class::static 也可以通过Object.static访问,也可以Point->static访问
        这三种方式等效
        static成员变量不占用对象的内存,而是在所有对象之外开辟内存,即使不创建对象也可以访问

    static 修饰成员函数
        1. static成员函数不包含this指针，所以static成员函数不能访问非static类成员,只能访问static修饰的类成员
        2.static成员函数不能定义为const的，static函数不能访问非静态成员变量(备注:编译错误 static member function  cannot have cv-qualifier)   
引用:
    2.1 总的来说
    （1）在修饰变量的时候，static 修饰的静态局部变量只执行初始化一次，而且延长了局部变量的生命周期，直到程序运行结束以后才释放。
    （2）static 修饰全局变量的时候，这个全局变量只能在本文件中访问，不能在其它文件中访问，即便是 extern 外部声明也不可以。
    （3）static 修饰一个函数，则这个函数的只能在本文件中调用，不能被其他文件调用。static 修饰的变量存放在全局数据区的静态变量区，包括全局静态变量和局部静态变量，都在全局数据区分配内存。初始化的时候自动初始化为 0。
    （4）不想被释放的时候，可以使用static修饰。比如修饰函数中存放在栈空间的数组。如果不想让这个数组在函数调用结束释放可以使用 static 修饰。
    （5）考虑到数据安全性（当程序想要使用全局变量的时候应该先考虑使用 static）。
    2.2 静态变量与普通变量
    静态全局变量有以下特点：

    （1）静态变量都在全局数据区分配内存，包括后面将要提到的静态局部变量;
    （2）未经初始化的静态全局变量会被程序自动初始化为0（在函数体内声明的自动变量的值是随机的，除非它被显式初始化，而在函数体外被声明的自动变量也会被初始化为 0）；
    （3）静态全局变量在声明它的整个文件都是可见的，而在文件之外是不可见的。
    优点：静态全局变量不能被其它文件所用；其它文件中可以定义相同名字的变量，不会发生冲突。

    （1）全局变量和全局静态变量的区别
    1）全局变量是不显式用 static 修饰的全局变量，全局变量默认是有外部链接性的，作用域是整个工程，在一个文件内定义的全局变量，在另一个文件中，通过 extern 全局变量名的声明，就可以使用全局变量。
    2）全局静态变量是显式用 static 修饰的全局变量，作用域是声明此变量所在的文件，其他的文件即使用 extern 声明也不能使用。
    2.3 静态局部变量有以下特点：
    （1）该变量在全局数据区分配内存；
    （2）静态局部变量在程序执行到该对象的声明处时被首次初始化，即以后的函数调用不再进行初始化；
    （3）静态局部变量一般在声明处初始化，如果没有显式初始化，会被程序自动初始化为 0；
    （4）它始终驻留在全局数据区，直到程序运行结束。但其作用域为局部作用域，当定义它的函数或语句块结束时，其作用域随之结束。
    一般程序把新产生的动态数据存放在堆区，函数内部的自动变量存放在栈区。自动变量一般会随着函数的退出而释放空间，静态数据（即使是函数内部的静态局部变量）也存放在全局数据区。全局数据区的数据并不会因为函数的退出而释放空间。


    static 修饰局部变量 
        存储区: 由栈变为静态存储区,生存期为整个源程序,只能在定义该变量的函数内使用.退出该函数后,尽管变量还继续存在,但不能使用他；
        作用域: 作用域仍为局部作用域,当定义它的函数或者语句块结束的时候,作用域随之结束.
    static 修饰对象,如果类生命了构造函数,则会调用类的构造函数来初始化对象,如果没有的话,不会合成默认构造函数,但是依然会初始化,类的内置类型成员与普通内置类型初始化相同； 
```
8. volatile的作用是什么
```
        1. 访问寄存器要比访问内存快,因此CPU会优先访问该数据在寄存器中的存储效果,但是内存中的数据可能已经发生改变,而寄存器中还保留着原来的结果.为了避免这种情况的发生,将该变量声明为volatile,告诉cpu每次都从内存去读取数据.
        2. 一个参数可以即是const又是volatile的吗？ 可以
```    
9. const的作用: 
```
        1. const 修饰全局变量
        2. const 修饰局部变量
        3. const 修饰指针const int *;
        5. const 修饰指针指向的对象 int * const
        6. const 修饰成员变量,必须在构造函数列表中初始化
        7. const 修饰成员函数,说明该函数不应该修改非静态成员,但是这并不十分可靠,指针所指的非静态成员可能会被改变
 ```   
10. new与malloc的区别: 验证下 operator new delete 与 delete new的效果
```
        1. new分配内存按照数据类型进行分配,malloc分配内存按照大下分配；
        2. new不仅分配一段内存,而且会调用构造函数,但是malloc不会；
            解析:
            new实现的原理:  
                调用operator new 函数申请空间
                在申请的空间上执行构造函数,完成对象的构造
            delete的原理:
                在空间上执行析构函数,完成对象中资源的清理工作在空间上执行析构函数,完成对象中资源的清理工作
            new T[N]的原理:
                调用operator new[]函数,在operator new[]中实际调用operator new函数完成N个对象的申请
                在申请的空间上执行N次构造函数
            delete[]的原理;
                在是否的对象空间上执行N次析构函数,完成N个对象中的资源的清理
                调用operator delete[]释放空间,实际在operator delete[]中调用operator delete来释放空间

        3. new返回的是指定对象的指针,而malloc返回的是void*
        4. new是一个操作符可以重载,malloc是一个库函数
        5. new分配的内存要用delete销毁,malloc要用free来销毁;delete销毁的时候会调用对象的析构函数,而free不会
        6. malloc分配的内不够的时候,可以用realloc扩容(扩容的原理？) new没有这样的操作
        7. new如果分配失败了会抛出bad_malloc的异常,而malloc失败了会返回NULL。因此对于new，正确的字试是采用try...catch语法,而malloc则应该判断指针的返回值,为了兼容很多c语言程序员的习惯,c++也可以采用new nothrow的方法禁止抛出异常返回NULL;
        8. new和new[] 的区别,new[]一次分配所有内存,多次调用构造函数;分别搭配使用delete和delete[].
        9. 谈谈new和malloc的实现,空闲链表,分配方法(首次适配原则,最佳视频原则,最差适配原则,快速适配原则)。delete和free实现原理；free为什么知道销毁多大的空间;

    malloc的实现方案：
        1）malloc 函数的实质是它有一个将可用的内存块连接为一个长长的列表的所谓空闲链表。
        2）调用 malloc（）函数时，它沿着连接表寻找一个大到足以满足用户请求所需要的内存块。然后，将该内存块一分为二（一块的大小与用户申请的大小相等，另一块的大小就是剩下来的字节）。接下来，将分配给用户的那块内存存储区域传给用户，并将剩下的那块（如果有的话）返回到连接表上。
        3）调用 free 函数时，它将用户释放的内存块连接到空闲链表上。
        4）到最后，空闲链会被切成很多的小内存片段，如果这时用户申请一个大的内存片段， 那么空闲链表上可能没有可以满足用户要求的片段了。于是，malloc（）函数请求延时，并开始在空闲链表上检查各内存片段，对它们进行内存整理，将相邻的小空闲块合并成较大的内存块。

    brk和mmap：从操作系统角度来看，进程分配内存有两种方式，分别由两个系统调用完成：brk和mmap（不考虑共享内存）。
        1、brk是将数据段(.data)的最高地址指针_edata往高地址推；
        2、mmap是在进程的虚拟地址空间中（堆和栈中间，称为文件映射区域的地方）找一块空闲的虚拟内存。这两种方式分配的都是虚拟内存，没有分配物理内存。在第一次访问已分配的虚拟地址空间的时候，发生缺页中断，操作系统负责分配物理内存，然后建立虚拟内存和物理内存之间的映射关系。在标准C库中，提供了malloc/free函数分配释放内存，这两个函数底层是由brk，mmap，munmap这些系统调用实现的。
    申请后系统的响应
        栈：只要栈的剩余空间大于所申请空间，系统将为程序提供内存，否则将报异常提示栈溢出。
        堆：首先应该知道操作系统有一个记录空闲内存地址的链表，当系统收到程序的申请时，会遍历该链表，寻找第一个空间大于所申请空间的堆结点，然后将该结点从空闲 结点链表中删除，
            并将该结点的空间分配给程序，另外，对于大多数系统，会在这块内存空间中的首地址处记录本次分配的大小，这样，代码中的delete语句才能正确的释放本内存空间。
            另外，由于找到的堆结点的大小不一定正好等于申请的大小，系统会自动的将多余的那部分重新放入空闲链表中。
    申请大小的限制及生长方向
        栈：在Windows下,栈是向低地址扩展的数据结构，是一块连续的内存的区域。这句话的意思是栈顶的地址和栈的最大容量是系统预先规定好的，在WINDOWS下，
            栈的大小是2M（也可能是1M，它是一个编译时就确定的常数），如果申请的空间超过栈的剩余空间时，将提示overflow。
            因此，能从栈获得的空间较小 。
        堆：堆是向高地址扩展的数据结构，是不连续的内存区域。这是由于系统是用链表来存储的空闲内存地址的，自然是不连续的，而链表的遍历方向是由低地址向高地址。
            堆的大小受限于计算机系统中有效的虚拟内存。由此可见，堆获得的空间比较灵活，也比较大。
    申请效率的比较：
        栈由系统自动分配，速度较快。但程序员是无法控制的。
        堆是由new分配的内存，一般速度比较慢，而且容易产生内存碎片,不过用起来最方便.
    堆和栈中的存储内容
    栈：在函数调用时，第一个进栈的是主函数中后的下一条指令（函数调用语句的下一条可执行语句）的地址，然后是函数的各个参数，在大多数的C编译器中，
        参数是由右往左入栈的，然后是函数中的局部变量。
        注意静态变量是不入栈的。当本次函数调用结束后，局部变量先出栈，然后是参数，最后栈顶指针指向最开始存的地址，也就是主函数中的下一条指令，程序由该点继续运行。
```
11. sizeof和strlen的区别
```
1 sizeof是运算符，而strlen是函数；
2 sizeof的用法是sizeof(参数)，这个参数可以是数组，指针，类型，对象，甚至是函数，其值在编译的时候就计算好了，而strlen的参数必须是字符型指针（char*）,
    其值必须在函数运行的时候才能计算出来；
3 sizeof的功能是获得保证能容纳实现的建立的最大对象的字节的大小，而strlen的功能是返回字符串的长度，切记这里的字符串的长度是包括结束符的；
4 当数组作为参数传递给函数的时候，传的是指针，而不是数组，传递数组的首地址；
```

12. C++多态性和虚函数表
```
       多态分为静态多态和动态多态。静态多态是通过重载和模板技术实现,在编译的时候确定。
       动态多态通过虚函数和继承关系实现,执行动态绑定,在运行的时候确定。
       动态多态实现有几个条件:
        1. 虚函数
        2. 一个基类的指针或引用指向派生类的对象

            基类指针在调用成员函数(虚函数)时,就会去查找该对象的虚函数表。虚函数表的地址在每个对象的首地址。
            查找该虚函数表中该函数的指针进行调用。每个对象中保存的只是一个虚函数表的指针，C++内部为每一个类维持一个虚函数表，
            该类的对象的都指向这同一个虚函数表。虚函数表中为什么就能准确查找相应的函数指针呢？因为在类设计的时候，
            虚函数表直接从基类也继承过来，如果覆盖了其中的某个虚函数，那么虚函数表的指针就会被替换，因此可以根据指针准确找到该调用哪个函数。
        虚函数实现原理：
            虚函数表和虚函数指针。纯虚函数： virtual int fun() = 0;函数的运行版本由实参决定，在运行时选择函数的版本，所以动态绑定又称为运行时绑定。当编译器遇到一个模板定义时，它并不生成代码。只有当实例化出模板的一个特定版本时，编译器才会生成代码。
```
13. 虚函数可以声明为inline吗?
```
1)  虚函数用于实现运行时的多态，或者称为晚绑定或动态绑定。
    而内联函数用于提高效率。内联函数的原理是，在编译期间，对调用内联函数的地方的代码替换成函数代码。
    内联函数对于程序中需要频繁使用和调用的小函数非常有用。
2)  虚函数要求在运行时进行类型确定，而内敛函数要求在编译期完成相关的函数替换；
```

50. 虚函数的作用？
```
    虚函数用于实现多态，这点大家都能答上来
    但是虚函数在设计上还具有封装和抽象的作用。比如抽象工厂模式。(实现下)
    动态绑定是如何实现的？
    第一个问题中基本回答了，主要都是结合虚函数表来答就行。
    静态多态和动态多态。静态多态是指通过模板技术或者函数重载技术实现的多态，其在编译器确定行为。动态多态是指通过虚函数技术实现在运行期动态绑定的技术。

    虚函数表
        虚函数表是针对类的还是针对对象的？同一个类的两个对象的虚函数表是怎么维护的？
        编译器为每一个类维护一个虚函数表，每个对象的首地址保存着该虚函数表的指针，同一个类的不同对象实际上指向同一张虚函数表。
    纯虚函数如何定义，为什么对于存在虚函数的类中析构函数要定义成虚函数
        为了实现多态进行动态绑定，将派生类对象指针绑定到基类指针上，对象销毁时，如果析构函数没有定义为析构函数，
        则会调用基类的析构函数，显然只能销毁部分数据。
        如果要调用对象的析构函数，就需要将该对象的析构函数定义为虚函数，销毁时通过虚函数表找到对应的析构函数。
        纯虚函数定义
        virtual ~myClass() = 0;
```

51. 析构函数能抛出异常吗
```
    答案肯定是不能。 
    C++标准指明析构函数不能、也不应该抛出异常。
    C++异常处理模型最大的特点和优势就是对C++中的面向对象提供了最强大的无缝支持。
    那么如果对象在运行期间出现了异常，C++异常处理模型有责任清除那些由于出现异常所导致的已经失效了的对象(也即对象超出了它原来的作用域)，
    并释放对象原来所分配的资源， 这就是调用这些对象的析构函数来完成释放资源的任务，
    所以从这个意义上说，析构函数已经变成了异常处理的一部分。
    (1) 如果析构函数抛出异常，则异常点之后的程序不会执行，如果析构函数在异常点之后执行了某些必要的动作比如释放某些资源，
        则这些动作不会执行，会造成诸如资源泄漏的问题。
    (2) 通常异常发生时，c++的机制会调用已经构造对象的析构函数来释放资源，此时若析构函数本身也抛出异常，
        则前一个异常尚未处理，又有新的异常，会造成程序崩溃的问题。
```

14. 类成员初始化方式？构造函数的执行顺序 ？为什么用成员初始化列表会快一些？
```
1)  赋值初始化，通过在函数体内进行赋值初始化；
    列表初始化，在冒号后使用初始化列表进行初始化。
    这两种方式的主要区别在于：
        对于在函数体中初始化,是在所有的数据成员被分配内存空间后才进行的。
        列表初始化是给数据成员分配内存空间时就进行初始化,就是说分配一个数据成员只要冒号后有此数据成员的赋值表达式(此表达式必须是括号赋值表达式),
        那么分配了内存空间后在进入函数体之前给数据成员赋值，就是说初始化这个数据成员此时函数体还未执行。 
2)  一个派生类构造函数的执行顺序如下：
    ① 虚拟基类的构造函数（多个虚拟基类则按照继承的顺序执行构造函数）。
    ② 基类的构造函数（多个普通基类也按照继承的顺序执行构造函数）。
    ③ 类类型的成员对象的构造函数（按照初始化顺序）
    ④ 派生类自己的构造函数。
3) 方法一是在构造函数当中做赋值的操作，而方法二是做纯粹的初始化操作。
    我们都知道，C++的赋值操作是会产生临时对象的。临时对象的出现会降低程序的效率。
```
15. 成员列表初始化？
```
1) 必须使用成员初始化的四种情况
    ① 当初始化一个引用成员时；
    ② 当初始化一个常量成员时；
    ③ 当调用一个基类的构造函数，而它拥有一组参数时；
    ④ 当调用一个成员类的构造函数，而它拥有一组参数时；
2) 成员初始化列表做了什么
    ① 编译器会一一操作初始化列表，以适当的顺序在构造函数之内安插初始化操作，并且在任何显示用户代码之前；
    ② list中的项目顺序是由类中的成员声明顺序决定的，不是由初始化列表的顺序决定的；
```

16. 必须在构造函数初始化式里进行初始化的数据成员有哪些
```
    (1) 常量成员，因为常量只能初始化不能赋值，所以必须放在初始化列表里面
    (2) 引用类型，引用必须在定义的时候初始化，并且不能重新赋值，所以也要写在初始化列表里面
    (3) 没有默认构造函数的类类型，因为使用初始化列表可以不必调用默认构造函数来初始化，而是直接调用拷贝构造函数初始化
```

17. 构造函数为什么不能为虚函数？析构函数为什么要虚函数？
```
1.  从存储空间角度，虚函数相应一个指向vtable虚函数表的指针，这大家都知道，但是这个指向vtable的指针事实上是存储在对象的内存空间的。
    问题出来了，假设构造函数是虚的，就须要通过 vtable来调用，但是对象还没有实例化，也就是内存空间还没有，怎么找vtable呢？
    所以构造函数不能是虚函数。 
2.  从使用角度，虚函数主要用于在信息不全的情况下，能使重载的函数得到相应的调用。
    构造函数本身就是要初始化实例，那使用虚函数也没有实际意义呀。所以构造函数没有必要是虚函数。
    虚函数的作用在于通过父类的指针或者引用来调用它的时候可以变成调用子类的那个成员函数。
    而构造函数是在创建对象时自己主动调用的，不可能通过父类的指针或者引用去调用，因此也就规定构造函数不能是虚函数。 
3.  构造函数不须要是虚函数，也不同意是虚函数，由于创建一个对象时我们总是要明白指定对象的类型，
    虽然我们可能通过实验室的基类的指针或引用去訪问它但析构却不一定，我们往往通过基类的指针来销毁对象。
    这时候假设析构函数不是虚函数，就不能正确识别对象类型从而不能正确调用析构函数。 
4.  从实现上看，vbtl在构造函数调用后才建立，因而构造函数不可能成为虚函数从实际含义上看，
    在调用构造函数时还不能确定对象的真实类型（由于子类会调父类的构造函数）；
    并且构造函数的作用是提供初始化，在对象生命期仅仅运行一次，不是对象的动态行为，也没有必要成为虚函数。 
5.  当一个构造函数被调用时，它做的首要的事情之中的一个是初始化它的VPTR。
    因此，它仅仅能知道它是“当前”类的，而全然忽视这个对象后面是否还有继承者。
    当编译器为这个构造函数产生代码时，它是为这个类的构造函数产生代码——既不是为基类，也不是为它的派生类（由于类不知道谁继承它）。
    所以它使用的VPTR必须是对于这个类的VTABLE。并且，仅仅要它是最后的构造函数调用，那么在这个对象的生命期内，VPTR将保持被初始化为指向这个VTABLE,
    但假设接着另一个更晚派生的构造函数被调用，这个构造函数又将设置VPTR指向它的 VTABLE，等.直到最后的构造函数结束。
    VPTR的状态是由被最后调用的构造函数确定的。这就是为什么构造函数调用是从基类到更加派生类顺序的还有一个理由。
    可是，当这一系列构造函数调用正发生时，每一个构造函数都已经设置VPTR指向它自己的VTABLE。
    假设函数调用使用虚机制，它将仅仅产生通过它自己的VTABLE的调用，而不是最后的VTABLE（全部构造函数被调用后才会有最后的VTABLE）。
    因为构造函数本来就是为了明确初始化对象成员才产生的，然而virtual function主要是为了再不完全了解细节的情况下也能正确处理对象。
    另外，virtual函数是在不同类型的对象产生不同的动作，现在对象还没有产生，如何使用virtual函数来完成你想完成的动作。
    直接的讲，C++中基类采用virtual虚析构函数是为了防止内存泄漏。具体地说，如果派生类中申请了内存空间，并在其析构函数中对这些内存空间进行释放。
    假设基类中采用的是非虚析构函数，当删除基类指针指向的派生类对象时就不会触发动态绑定，因而只会调用基类的析构函数，而不会调用派生类的析构函数。
    那么在这种情况下，派生类中申请的空间就得不到释放从而产生内存泄漏。所以，为了防止这种情况的发生，C++中基类的析构函数应采用virtual虚析构函数。
```
18. 析构函数的作用，如何起作用？
 ```
1)  构造函数只是起初始化值的作用，但实例化一个对象的时候，可以通过实例去传递参数，从主函数传递到其他的函数里面，这样就使其他的函数里面有值了。
    规则，只要你一实例化对象，系统自动回调用一个构造函数，就是你不写，编译器也自动调用一次。
2)  析构函数与构造函数的作用相反，用于撤销对象的一些特殊任务处理，可以是释放对象分配的内存空间；
    特点：析构函数与构造函数同名，但该函数前面加~。 析构函数没有参数，也没有返回值，而且不能重载，在一个类中只能有一个析构函数。 
    当撤销对象时，编译器也会自动调用析构函数。 每一个类必须有一个析构函数，用户可以自定义析构函数，也可以是编译器自动生成默认的析构函数。
    一般析构函数定义为类的公有成员。
 ```
19. 构造函数和析构函数可以调用虚函数吗，为什么
```
1) 在C++中，提倡不在构造函数和析构函数中调用虚函数；
2) 构造函数和析构函数调用虚函数时都不使用动态联编，如果在构造函数或析构函数中调用虚函数，则运行的是为构造函数或析构函数自身类型定义的版本；
3) 因为父类对象会在子类之前进行构造，此时子类部分的数据成员还未初始化，因此调用子类的虚函数时不安全的，故而C++不会进行动态联编；
4) 析构函数是用来销毁一个对象的，在销毁一个对象时，先调用子类的析构函数，然后再调用基类的析构函数。所以在调用基类的析构函数时，
    派生类对象的数据成员已经销毁，这个时候再调用子类的虚函数没有任何意义。
```

20. 构造函数的执行顺序？析构函数的执行顺序？构造函数内部干了啥？拷贝构造干了啥？
```
1) 构造函数顺序
    ① 基类构造函数。如果有多个基类，则构造函数的调用顺序是某类在类派生表中出现的顺序，而不是它们在成员初始化表中的顺序。
    ② 成员类对象构造函数。如果有多个成员类对象则构造函数的调用顺序是对象在类中被声明的顺序，而不是它们出现在成员初始化表中的顺序。
    ③ 派生类构造函数。
2) 析构函数顺序
    ① 调用派生类的析构函数；
    ② 调用成员类对象的析构函数；
    ③ 调用基类的析构函数。
```

21. 虚析构函数的作用，父类的析构函数是否要设置为虚函数？
```
1) C++中基类采用virtual虚析构函数是为了防止内存泄漏。
    具体地说，如果派生类中申请了内存空间，并在其析构函数中对这些内存空间进行释放。
    假设基类中采用的是非虚析构函数，当删除基类指针指向的派生类对象时就不会触发动态绑定，因而只会调用基类的析构函数，而不会调用派生类的析构函数。
    那么在这种情况下，派生类中申请的空间就得不到释放从而产生内存泄漏。
    所以，为了防止这种情况的发生，C++中基类的析构函数应采用virtual虚析构函数。
2)  纯虚析构函数一定得定义，因为每一个派生类析构函数会被编译器加以扩张，以静态调用的方式调用其每一个虚基类以及上一层基类的析构函数。
    因此，缺乏任何一个基类析构函数的定义，就会导致链接失败。因此，最好不要把虚析构函数定义为纯虚析构函数。
```
22. 构造函数析构函数可以调用虚函数吗？
```
1) 在构造函数和析构函数中最好不要调用虚函数；
2) 构造函数或者析构函数调用虚函数并不会发挥虚函数动态绑定的特性，跟普通函数没区别；
3) 即使构造函数或者析构函数如果能成功调用虚函数， 程序的运行结果也是不可控的。
```

23. 构造函数析构函数可否抛出异常
```
1)  C++只会析构已经完成的对象，对象只有在其构造函数执行完毕才算是完全构造妥当。在构造函数中发生异常，控制权转出构造函数之外。
    因此，在对象b的构造函数中发生异常，对象b的析构函数不会被调用。因此会造成内存泄漏。
2)  用auto_ptr对象来取代指针类成员，便对构造函数做了强化，免除了抛出异常时发生资源泄漏的危机，不再需要在析构函数中手动释放资源；
3)  如果控制权基于异常的因素离开析构函数，而此时正有另一个异常处于作用状态，C++会调用terminate函数让程序结束；
4)  如果异常从析构函数抛出，而且没有在当地进行捕捉，那个析构函数便是执行不全的。如果析构函数执行不全，就是没有完成他应该执行的每一件事情。
```
24. 在有继承关系的父子类中，构建和析构一个子类对象时，父子构造函数和析构函数的执行顺序分别是怎样的？
```
父构造函数 子构造函数 子析构函数 父析构函数
```
25. 在有继承关系的类体系中，父类的构造函数和析构函数一定要申明为 virtual 吗？如果不申明为 virtual 会怎样？
```
    构造函数不能够声明为虚函数:
        1. 构造一个对象需要先确定对象的类型,而虚函数是在运行时确定的，虚构造函数无法在构造对象的时候确定所构造的对象类型;
        2. 虚函数的执行需要依赖于虚函数表。而虚函数表在构造函数中进行初始化工作,即初始化vptr，让它指向正确的虚函数表。而在构造
            对象期间,虚函数表还没有被初始化,将无法进行。
    析构函数可以被声明为虚函数,且在某些情况下必须声明为虚函数:
        1. 在类的继承中,如果有积累指针执行派生类,那么用基类指针delete是时,如果不定义为虚函数,派生类中派生的那部分无法析构;
    构造函数析构函数是否能够调用虚函数:
    １.　从语法上讲，调用完全没有问题。
    ２.　但是从效果上看，往往不能达到需要的目的。
    Effective 的解释是：
        派生类对象构造期间进入基类的构造函数时，对象类型变成了基类类型，而不是派生类类型。
        同样，进入基类析构函数时，对象也是基类类型。
        所以，虚函数始终仅仅调用基类的虚函数（如果是基类调用虚函数），不能达到多态的效果，所以放在构造函数中是没有意义的，而且往往不能达到本来想要的效果。
```
26. 什么是虚表？虚表的内存结构布局如何？虚表的第一项（或第二项）是什么？
```
    虚表:  虚函数的地址表,按照虚函数声明的顺序存储,如果子类覆盖父类函数,虚函数表中同样会覆盖;
```

33. mutable
```
1) 如果需要在const成员方法中修改一个成员变量的值，那么需要将这个成员变量修饰为mutable。即用mutable修饰的成员变量不受const成员方法的限制;
2) 可以认为mutable的变量是类的辅助状态，但是只是起到类的一些方面表述的功能，修改他的内容我们可以认为对象的状态本身并没有改变的。实际上由于const_cast的存在，这个概念很多时候用处不是很到了。
```
34. 深拷贝与浅拷贝？
```
1) 浅复制 —-只是拷贝了基本类型的数据，而引用类型数据，复制后也是会发生引用，我们把这种拷贝叫做“（浅复制）浅拷贝”，换句话说，浅复制仅仅是指向被复制的内存地址，如果原地址中对象被改变了，那么浅复制出来的对象也会相应改变。深复制 —-在计算机中开辟了一块新的内存地址用于存放复制的对象。
2) 在某些状况下，类内成员变量需要动态开辟堆内存，如果实行位拷贝，也就是把对象里的值完全复制给另一个对象，如A=B。这时，如果B中有一个成员变量指针已经申请了内存，那A中的那个成员变量也指向同一块内存。这就出现了问题：当B把内存释放了（如：析构），这时A内的指针就是野指针了，出现运行错误。
```
35. C++模板是什么，底层怎么实现的？
```
1) 编译器并不是把函数模板处理成能够处理任意类的函数；编译器从函数模板通过具体类型产生不同的函数；编译器会对函数模板进行两次编译：在声明的地方对模板代码本身进行编译，在调用的地方对参数替换后的代码进行编译。
2) 这是因为函数模板要被实例化后才能成为真正的函数，在使用函数模板的源文件中包含函数模板的头文件，如果该头文件中只有声明，没有定义，那编译器无法实例化该模板，最终导致链接错误。
```
36. C语言struct和C++struct区别
```
1) C语言中：struct是用户自定义数据类型（UDT）；C++中struct是抽象数据类型（ADT），支持成员函数的定义，（C++中的struct能继承，能实现多态）。
2) C中struct是没有权限的设置的，且struct中只能是一些变量的集合体，可以封装数据却不可以隐藏数据，而且成员不可以是函数。
3) C++中，struct的成员默认访问说明符为public（为了与C兼容），class中的默认访问限定符为private，struct增加了访问权限，且可以和类一样有成员函数。
4) struct作为类的一种特例是用来自定义数据结构的。一个结构标记声明后，在C中必须在结构标记前加上struct，才能做结构类型名
```
37. 类如何实现只能静态分配和只能动态分配
```
1) 前者是把new、delete运算符重载为private属性。后者是把构造、析构函数设为protected属性，再用子类来动态创建
2) 建立类的对象有两种方式：① 静态建立，静态建立一个类对象，就是由编译器为对象在栈空间中分配内存；② 动态建立，A *p = new A();动态建立一个类对象，就是使用new运算符为对象在堆空间中分配内存。这个过程分为两步，第一步执行operator new()函数，在堆中搜索一块内存并进行分配；第二步调用类构造函数构造对象；
3) 只有使用new运算符，对象才会被建立在堆上，因此只要限制new运算符就可以实现类对象只能建立在栈上。可以将new运算符设为私有。
```
38. 如果想将某个类用作基类，为什么该类必须定义而非声明？
```
1) 派生类中包含并且可以使用它从基类继承而来的成员，为了使用这些成员，派生类必须知道他们是什么。
```
39. 什么情况会自动生成默认构造函数？
```
1) 带有默认构造函数的类成员对象，如果一个类没有任何构造函数，但它含有一个成员对象，而后者有默认构造函数，那么编译器就为该类合成出一个默认构造函数。不过这个合成操作只有在构造函数真正被需要的时候才会发生；如果一个类A含有多个成员类对象的话，那么类A的每一个构造函数必须调用每一个成员对象的默认构造函数而且必须按照类对象在类A中的声明顺序进行；
2) 带有默认构造函数的基类，如果一个没有任务构造函数的派生类派生自一个带有默认构造函数基类，那么该派生类会合成一个构造函数调用上一层基类的默认构造函数；
3) 带有一个虚函数的类
4) 带有一个虚基类的类
5) 合成的默认构造函数中，只有基类子对象和成员类对象会被初始化。所有其他的非静态数据成员都不会被初始化。
```
40. 什么是类的继承？
```
1) 类与类之间的关系has-A包含关系，用以描述一个类由多个部件类构成，实现has-A关系用类的成员属性表示，即一个类的成员属性是另一个已经定义好的类；use-A，一个类使用另一个类，通过类之间的成员函数相互联系，定义友元或者通过传递参数的方式来实现；is-A，继承关系，关系具有传递性；
2) 继承的相关概念所谓的继承就是一个类继承了另一个类的属性和方法，这个新的类包含了上一个类的属性和方法，被称为子类或者派生类，被继承的类称为父类或者基类；
3) 继承的特点子类拥有父类的所有属性和方法，子类可以拥有父类没有的属性和方法，子类对象可以当做父类对象使用；
4) 继承中的访问控制public、protected、private
5) 继承中的构造和析构函数
6) 继承中的兼容性原则
```
41. 什么是组合？
```
1) 一个类里面的数据成员是另一个类的对象，即内嵌其他类的对象作为自己的成员；创建组合类的对象：首先创建各个内嵌对象，难点在于构造函数的设计。创建对象时既要对基本类型的成员进行初始化，又要对内嵌对象进行初始化。
2) 创建组合类对象，构造函数的执行顺序：先调用内嵌对象的构造函数，然后按照内嵌对象成员在组合类中的定义顺序，与组合类构造函数的初始化列表顺序无关。然后执行组合类构造函数的函数体，析构函数调用顺序相反。
```
42. 抽象基类为什么不能创建对象？
```
抽象类是一种特殊的类，它是为了抽象和设计的目的为建立的，它处于继承层次结构的较上层。
（1）抽象类的定义：   称带有纯虚函数的类为抽象类。
（2）抽象类的作用：   抽象类的主要作用是将有关的操作作为结果接口组织在一个继承层次结构中，由它来为派生类提供一个公共的根，派生类将具体实现在其基类中作为接口的操作。所以派生类实际上刻画了一组子类的操作接口的通用语义，这些语义也传给子类，子类可以具体实现这些语义，也可以再将这些语义传给自己的子类。
（3）使用抽象类时注意：  抽象类只能作为基类来使用，其纯虚函数的实现由派生类给出。如果派生类中没有重新定义纯虚函数，而只是继承基类的纯虚函数，则这个派生类仍然还是一个抽象类。如果派生类中给出了基类纯虚函数的实现，则该派生类就不再是抽象类了，它是一个可以建立对象的具体的类。抽象类是不能定义对象的。一个纯虚函数不需要（但是可以）被定义。
    一、纯虚函数定义 　纯虚函数是一种特殊的虚函数，它的一般格式如下： 　　class <类名> 　　{ 　　virtual <类型><函数名>(<参数表>)=0; 　　… 　　}; 　在许多情况下，在基类中不能对虚函数给出有意义的实现，而把它声明为纯虚函数，它的实现留给该基类的派生类去做。这就是纯虚函数的作用。 　　
    纯虚函数可以让类先具有一个操作名称，而没有操作内容，让派生类在继承时再去具体地给出定义。凡是含有纯虚函数的类叫做抽象类。这种类不能声明对象，只是作为基类为派生类服务。除非在派生类中完全实现基类中所有的的纯虚函数，否则，派生类也变成了抽象类，不能实例化对象。
    二、纯虚函数引入原因 　 
        1、为了方便使用多态特性，我们常常需要在基类中定义虚拟函数。 　 
        2、在很多情况下，基类本身生成对象是不合情理的。例如，动物作为一个基类可以派生出老虎、孔 雀等子类，但动物本身生成对象明显不合常理。 　　
        为了解决上述问题，引入了纯虚函数的概念，将函数定义为纯虚函数（方法：virtual ReturnType Function()= 0;）。
        若要使派生类为非抽象类，则编译器要求在派生类中，必须对纯虚函数予以重载以实现多态性。同时含有纯虚函数的类称为抽象类，它不能生成对象。
        这样就很好地解决了上述两个问题。 例如，绘画程序中，shape作为一个基类可以派生出圆形、矩形、正方形、梯形等， 如果我要求面积总和的话，那么会可以使用一个 shape * 的数组，只要依次调用派生类的area()函数了。如果不用接口就没法定义成数组，因为既可以是circle ,也可以是square ,而且以后还可能加上rectangle，等等.三、相似概念 1、多态性指相同对象收到不同消息或不同对象收到相同消息时产生不同的实现动作。
        C++支持两种多态性：编译时多态性，运行时多态性。 　　
            a.编译时多态性：通过重载函数实现 　　
            b.运行时多态性：通过虚函数实现。 2、虚函数 　　虚函数是在基类中被声明为virtual，并在派生类中重新定义的成员函数，可实现成员函数的动态重载。 
    3、抽象类 　　包含纯虚函数的类称为抽象类。由于抽象类包含了没有定义的纯虚函数，所以不能定义抽象类的对象。
```

43. 类什么时候会析构？
```
1) 对象生命周期结束，被销毁时；
2) delete指向对象的指针时，或delete指向对象的基类类型指针，而其基类虚构函数是虚函数时；
3) 对象i是对象o的成员，o的析构函数被调用时，对象i的析构函数也被调用。
```
44. 为什么友元函数必须在类内部声明？
```
1) 因为编译器必须能够读取这个结构的声明以理解这个数据类型的大、行为等方面的所有规则。有一条规则在任何关系中都很重要，那就是谁可以访问我的私有部分
```

46. 继承机制中对象之间如何转换？
```
指针和引用之间如何转换？
1) 向上类型转换将派生类指针或引用转换为基类的指针或引用被称为向上类型转换，向上类型转换会自动进行，而且向上类型转换是安全的。
2) 向下类型转换将基类指针或引用转换为派生类指针或引用被称为向下类型转换，向下类型转换不会自动进行，因为一个基类对应几个派生类，所以向下类型转换时不知道对应哪个派生类，所以在向下类型转换时必须加动态类型识别技术。RTTI技术，用dynamic_cast进行向下类型转换。
```
47. 组合与继承优缺点？
```
一：继承继承是Is a 的关系，比如说Student继承Person,则说明Student is a Person。
    继承的优点是子类可以重写父类的方法来方便地实现对父类的扩展。
    继承的缺点有以下几点：
        ①：父类的内部细节对子类是可见的。
        ②：子类从父类继承的方法在编译时就确定下来了，所以无法在运行期间改变从父类继承的方法的行为。
        ③：如果对父类的方法做了修改的话（比如增加了一个参数），则子类的方法必须做出相应的修改。
        所以说子类与父类是一种高耦合，违背了面向对象思想。
二：组合组合也就是设计类的时候把要组合的类的对象加入到该类中作为自己的成员变量。
    组合的优点：
        ①：当前对象只能通过所包含的那个对象去调用其方法，所以所包含的对象的内部细节对当前对象时不可见的。
        ②：当前对象与包含的对象是一个低耦合关系，如果修改包含对象的类中代码不需要修改当前对象类的代码。
        ③：当前对象可以在运行时动态的绑定所包含的对象。可以通过set方法给所包含对象赋值。
    组合的缺点：
        ①：容易产生过多的对象。
        ②：为了能组合多个对象，必须仔细对接口进行定义。
```
48. 左值右值
```
1) 在C++11中所有的值必属于左值、右值两者之一，右值又可以细分为纯右值、将亡值。
    在C++11中可以取地址的、有名字的就是左值，反之，不能取地址的、没有名字的就是右值（将亡值或纯右值）。
    举个例子，int a = b+c, a 就是左值，其有变量名为a，通过&a可以获取该变量的地址；
    表达式b+c、函数int func()的返回值是右值，在其被赋值给某一变量前，我们不能通过变量名找到它，＆(b+c)这样的操作则不会通过编译。
2) C++11对C++98中的右值进行了扩充。
    在C++11中右值又分为纯右值（prvalue，Pure Rvalue）和将亡值（xvalue，eXpiring Value）。
    其中纯右值的概念等同于我们在C++98标准中右值的概念，指的是临时变量和不跟对象关联的字面量值；将亡值则是C++11新增的跟右值引用相关的表达式，
    这样表达式通常是将要被移动的对象（移为他用），比如返回右值引用T&&的函数返回值、std::move的返回值，或者转换为T&&的类型转换函数的返回值。
    将亡值可以理解为通过“盗取”其他变量内存空间的方式获取到的值。在确保其他变量不再被使用、或即将被销毁时，通过“盗取”的方式可以避免内存空间的释放和分配，能够延长变量值的生命期。
3) 左值引用就是对一个左值进行引用的类型。右值引用就是对一个右值进行引用的类型，事实上，由于右值通常不具有名字，我们也只能通过引用的方式找到它的存在。右值引用和左值引用都是属于引用类型。无论是声明一个左值引用还是右值引用，都必须立即进行初始化。而其原因可以理解为是引用类型本身自己并不拥有所绑定对象的内存，只是该对象的一个别名。左值引用是具名变量值的别名，而右值引用则是不具名（匿名）变量的别名。左值引用通常也不能绑定到右值，但常量左值引用是个“万能”的引用类型。它可以接受非常量左值、常量左值、右值对其进行初始化。不过常量左值所引用的右值在它的“余生”中只能是只读的。相对地，非常量左值只能接受非常量左值对其进行初始化。
4) 右值值引用通常不能绑定到任何的左值，要想绑定一个左值到右值引用，通常需要std::move()将左值强制转换为右值。
```
49. 移动构造函数
```
1) 我们用对象a初始化对象b，后对象a我们就不在使用了，但是对象a的空间还在呀（在析构之前），既然拷贝构造函数，实际上就是把a对象的内容复制一份到b中，那么为什么我们不能直接使用a的空间呢？这样就避免了新的空间的分配，大大降低了构造的成本。这就是移动构造函数设计的初衷；
2) 拷贝构造函数中，对于指针，我们一定要采用深层复制，而移动构造函数中，对于指针，我们采用浅层复制。浅层复制之所以危险，是因为两个指针共同指向一片内存空间，若第一个指针将其释放，另一个指针的指向就不合法了。所以我们只要避免第一个指针释放空间就可以了。避免的方法就是将第一个指针（比如a->value）置为NULL，这样在调用析构函数的时候，由于有判断是否为NULL的语句，所以析构a的时候并不会回收a->value指向的空间；
3) 移动构造函数的参数和拷贝构造函数不同，拷贝构造函数的参数是一个左值引用，但是移动构造函数的初值是一个右值引用。意味着，移动构造函数的参数是一个右值或者将亡值的引用。也就是说，只用用一个右值，或者将亡值初始化另一个对象的时候，才会调用移动构造函数。而那个move语句，就是将一个左值变成一个将亡值。
```
54. 智能指针是怎么实现的？什么时候改变引用计数？
```
    构造函数中计数初始化为1；
    拷贝构造函数中计数值加1；
    赋值运算符中，左边的对象引用计数减一，右边的对象引用计数加一；
    析构函数中引用计数减一；
    在赋值运算符和析构函数中，如果减一后为0，则调用delete释放对象。
    share_prt<T>与weak_ptr<T>的区别？
    //share_ptr可能出现循环引用，从而导致内存泄露
    class A
    {
        public:
        share_ptr<B> p;
    };

    class B
    {
        public:
        share_ptr<A> p;
    }
    int main()
    {
        while(true)
        {
            share_prt<A> pa(new A()); //pa的引用计数初始化为1
            share_prt<B> pb(new B()); //pb的引用计数初始化为1
            pa->p = pb; //pb的引用计数变为2
            pb->p = pa; //pa的引用计数变为2
        }
        //假设pa先离开，引用计数减一变为1，不为0因此不会调用class A的析构函数，因此其成员p也不会被析构，pb的引用计数仍然为2；
        //同理pb离开的时候，引用计数也不能减到0
        return 0;
    }
    /*
    ** weak_ptr是一种弱引用指针，其存在不会影响引用计数，从而解决循环引用的问题
    */
```
55. C++四种类型转换：static_cast, dynamic_cast, const_cast, reinterpret_cast
```
    const_cast用于将const变量转为非const
    static_cast用的最多，对于各种隐式转换，非const转const，void*转指针等, static_cast能用于多态想上转化，如果向下转能成功但是不安全，结果未知；
    dynamic_cast用于动态类型转换。只能用于含有虚函数的类，用于类层次间的向上和向下转化。
        只能转指针或引用。向下转化时，如果是非法的对于指针返回NULL，对于引用抛异常。要深入了解内部转换的原理。
    reinterpret_cast几乎什么都可以转，比如将int转指针，可能会出问题，尽量少用；
    为什么不使用C的强制转换？C的强制转换表面上看起来功能强大什么都能转，但是转化不够明确，不能进行错误检查，容易出错。
```


57. 内联函数有什么优点？内联函数与宏定义的区别？
```
    宏定义在预编译的时候就会进行宏替换；
    内联函数在编译阶段，在调用内联函数的地方进行替换，减少了函数的调用过程，但是使得编译文件变大。因此，内联函数适合简单函数，对于复杂函数，即使定义了内联编译器可能也不会按照内联的方式进行编译。
    内联函数相比宏定义更安全，内联函数可以检查参数，而宏定义只是简单的文本替换。因此推荐使用内联函数，而不是宏定义。
    使用宏定义函数要特别注意给所有单元都加上括号，#define MUL(a, b) a b，这很危险，正确写法：#define MUL(a, b) ((a) (b))
```



### STL

59. STL里的内存池实现
```
    STL内存分配分为一级分配器和二级分配器，一级分配器就是采用malloc分配内存，二级分配器采用内存池。
        二级分配器设计的非常巧妙，分别给8k，16k,..., 128k等比较小的内存片都维持一个空闲链表，每个链表的头节点由一个数组来维护。
        需要分配内存时从合适大小的链表中取一块下来。假设需要分配一块10K的内存，那么就找到最小的大于等于10k的块，也就是16K，
        从16K的空闲链表里取出一个用于分配。释放该块内存时，将内存节点归还给链表。
        如果要分配的内存大于128K则直接调用一级分配器。为了节省维持链表的开销，采用了一个union结构体，
        分配器使用union里的next指针来指向下一个节点，而用户则使用union的空指针来表示该节点的地址。
```

60. STL里set和map是基于什么实现的。红黑树的特点？
```
set和map都是基于红黑树实现的。
    红黑树是一种平衡二叉查找树，与AVL树的区别是什么？AVL树是完全平衡的，红黑树基本上是平衡的。
    为什么选用红黑数呢？因为红黑数是平衡二叉树，其插入和删除的效率都是N(logN)，与AVL相比红黑数插入和删除最多只需要3次旋转，
        而AVL树为了维持其完全平衡性，在坏的情况下要旋转的次数太多。
    红黑树的定义：
    (1) 节点是红色或者黑色；
    (2) 父节点是红色的话，子节点就不能为红色；
    (3) 从根节点到每个页子节点路径上黑色节点的数量相同；
    (4) 根是黑色的，NULL节点被认为是黑色的。

STL里的其他数据结构和算法实现也要清楚
这个问题，把STL源码剖析好好看看，不仅面试不慌，自己对STL的使用也会上升一个层次。
```

61. 模板特化
```
    (1) 模板特化分为全特化和偏特化，模板特化的目的就是对于某一种变量类型具有不同的实现，因此需要特化版本。
    例如，在STL里迭代器为了适应原生指针就将原生指针进行特化。
```
容器的区别
```
array 是固定大小的顺序容器，它们保存了一个以严格的线性顺序排列的特定数量的元素。
vector 是表示可以改变大小的数组的序列容器。
deque 容器为一个给定类型的元素进行线性处理，像向量一样，它能够快速地随机访问任一个元素，并且能够高效地插入和删除容器的尾部元素。
    但它又与vector不同，deque支持高效插入和删除容器的头部元素，因此也叫做双端队列。
    deque的中控器: deque是由一段一段的定量连续空间构成。一旦有必要在deque的前端或尾端增加新空间，便配置一段定量连续空间，串接在整个deque的头端或尾端。
    deque的最大任务，便是在这些分段的定量连续空间上，维护其整体连续的假象，并提供随机存取的接口。避开了“重新配置、复制、释放”的轮回，代价则是复杂的迭代器结构。
list时双链表，forward_list是单链表，forward_list（单向链表）是序列容器，允许在序列中的任何地方进行恒定的时间插入和擦除操作。
    在链表的任何位置进行插入/删除操作都非常快。
    forward_list只提供钱箱迭代器，因此不支持反向迭代器，比如rbegin()等成员函数。
    forward_list不提供size（）成员函数。
    forward_list没有指向最末元素的锚点，因此不提供back（）、push_back（）和pop_back（）。
    forward_list不提供随机访问，这一点跟list相同。
    插入和删除元素不会造成“指向至其他元素”的指针，引用和迭代器失效。
    list双向链表，是序列容器，允许在序列中的任何地方进行常数时间插入和擦除操作，并在两个方向上进行迭代,可以高效地进行插入删除元素。
stack没有迭代器，是一种容器适配器，用于在LIFO（后进先出）的操作，其中元素仅从容器的一端插入和提取。 
    stack底层一般用list或deque实现，封闭头部即可，不用vector的原因应该是容量大小有限制，扩容耗时
queue 是一种容器适配器，用于在FIFO（先入先出）的操作，其中元素插入到容器的一端并从另一端提取。
    队列不提供迭代器，不实现遍历操作。
优先队列，其底层是用堆来实现的。在优先队列中，队首元素一定是当前队列中优先级最高的那一个。

set 是按照特定顺序存储唯一元素的容器。
    set 的 底层数据结构是 红黑树，一种高效的平衡检索二叉树。
    对 set 进行插入删除操作 都不会引起iterator的失效，因为迭代器相当于一个指针指向每一个二叉树的节点，对set的插入删除并不会改变原有内存中节点的改变， 
    但是vector的插入删除操作一般会发生内存移动和内存拷贝，所以会发生迭代器的失效。
    set容器的检索速度很快，因为采用二分查找的方法 。
map 是关联容器，按照特定顺序存储由 key value (键值) 和 mapped value (映射值) 组合形成的元素。
vector中的reserve和resize的区别
    reserve是直接扩充到已经确定的大小，可以减少多次开辟、释放空间的问题（优化push_back），就可以提高效率，其次还可以减少多次要拷贝数据的问题。
    reserve只是保证vector中的空间大小（capacity）最少达到参数所指定的大小n。reserve()只有一个参数。
resize()可以改变有效空间的大小，也有改变默认值的功能。capacity的大小也会随着改变。resize()可以有多个参数

vector中的size和capacity的区别
    size表示当前vector中有多少个元素（finish - start）;
    capacity函数则表示它已经分配的内存中可以容纳多少元素（end_of_storage - start）;
vector中erase方法与algorithn中的remove方法区别
    vector中erase方法真正删除了元素，迭代器不能访问了
    remove只是简单地将元素移到了容器的最后面，迭代器还是可以访问到。因为algorithm通过迭代器进行操作，不知道容器的内部结构，所以无法进行真正的删除
vector迭代器失效的情况
    当插入一个元素到vector中，由于引起了内存重新分配，所以指向原内存的迭代器全部失效。
    当删除容器中一个元素后,该迭代器所指向的元素已经被删除，那么也造成迭代器失效。
    erase方法会返回下一个有效的迭代器，所以当我们要删除某个元素时，需要it=vec.erase(it);。
正确释放vector的内存(clear(), swap(), shrink_to_fit())
    vec.clear()：清空内容，但是不释放内存。
    vector<int>().swap(vec)：清空内容，且释放内存，想得到一个全新的vector。
    vec.shrink_to_fit()：请求容器降低其capacity和size匹配。
    vec.clear();vec.shrink_to_fit();：清空内容，且释放内存。

什么情况下用vector，什么情况下用list，什么情况下用deque
    vector:可以随机存储元素（即可以通过公式直接计算出元素地址，而不需要挨个查找），但在非尾部插入删除数据时，效率很低，适合对象简单，对象数量变化不大，
        随机访问频繁。除非必要，我们尽可能选择使用vector而非deque，因为deque的迭代器比vector迭代器复杂很多。
    list:不支持随机存储，适用于对象大，对象数量变化频繁，插入和删除频繁，比如写多读少的场景。
    deque: 需要从首尾两端进行插入或删除操作的时候需要选择deque。
    priority_queue：优先队列，其底层是用堆来实现的。在优先队列中，队首元素一定是当前队列中优先级最高的那一个。

为何map和set的插入删除效率比其他序列容器高
    因为不需要内存拷贝和内存移动

为何map和set每次Insert之后，以前保存的iterator不会失效？
    因为插入操作只是结点指针换来换去，结点内存没有改变。而iterator就像指向结点的指针，内存没变，指向内存的指针也不会变。

map 、set、multiset、multimap的特点
    set和multiset会根据特定的排序准则自动将元素排序，set中元素不允许重复，multiset可以重复。
    map和multimap将key和value组成的pair作为元素，根据key的排序准则自动将元素排序（因为红黑树也是二叉搜索树，所以map默认是按key排序的），
        map中元素的key不允许重复，multimap可以重复。
    map和set的增删改查速度为都是logn，是比较高效的。
为何map和set的插入删除效率比其他序列容器高，而且每次insert之后，以前保存的iterator不会失效？
    存储的是结点，不需要内存拷贝和内存移动。
    插入操作只是结点指针换来换去，结点内存没有改变。
    而iterator就像指向结点的指针，内存没变，指向内存的指针也不会变。

hash_map与map的区别？什么时候用hash_map，什么时候用map？ 
    构造函数：hash_map需要hash function和等于函数，而map需要比较函数（大于或小于）。
    存储结构：hash_map以hashtable为底层，而map以RB-TREE为底层。
    总的说来，hash_map查找速度比map快，而且查找速度基本和数据量大小无关，属于常数级别。
    而map的查找速度是logn级别。但不一定常数就比log小，而且hash_map还有hash function耗时。
    如果考虑效率，特别当元素达到一定数量级时，用hash_map。
    考虑内存，或者元素数量较少时，用map。

线程不安全的情况:
    在对同一个容器进行多线程的读写、写操作时；
    在每次调用容器的成员函数期间都要锁定该容器；
    在每个容器返回的迭代器（例如通过调用begin或end）的生存期之内都要锁定该容器；
    在每个在容器上调用的算法执行期间锁定该容器。
```

### 编程基础
33. strcat,strcpy,strncpy,memset,memcpy的内部实现？
```
c++11标准增加了全局函数std::to_string可以使用std::stoi/stol/stoll等等函数strcpy拥有返回值，有时候函数原本不需要返回值，但为了增加灵活性如支持链式表达，
```
22. 手写strcpy
```
    char strcpy(char dst, const char src)
    {
    assert(dst);
    assert(src);
    char ret = dst;
    while((dst++ = src++) != '\0');
    return ret;
    }
    //该函数是没有考虑重叠的
    char strcpy(char dst, const char src)
    {
    assert((dst != NULL) && (src != NULL));
    char ret = dst;
    int size = strlen(src) + 1;
    if(dst > src || dst < src + len)
    {
    dst = dst + size - 1;
    src = src + size - 1;
    while(size--)
    {
    dst-- = src--;
    }
    }
    else
    {
    while(size--)
    {
    dst++ = src++;
    }
    }
    return ret;
    }
```


22. 手写memcpy函数
```
void memcpy(void dst, const void src, size_t size)
{
if(dst == NULL || src == NULL)
{
return NULL;
}
void res = dst;
char pdst = (char)dst;
char psrc = (char)src;
if(pdst > psrc && pdst < psrc + size) //重叠

{

pdst = pdst + size - 1;

psrc = pdst + size - 1;

while(size--)

{

*pdst-- = *psrc--;

}

}

else //无重叠

{

while(size--)

{

*dst++ = *src++;

}

}

return ret;

}

```

23. 手写strcat函数
```
char strcat(char dst, const char src)
{
char ret = dst;



while(*dst != '\0')

++dst;



while((*dst++ = *src) != '\0');

return ret;

}
```


24. 手写strcmp函数
```
int strcmp(const char str1, const char str2)
{



while(*str1 == *str2 && *str1 != '\0')

{

++str1;

++str2;

}

return *str1 - *str2;

}
```
- 判断大小端
```
union un
{
int i;
char ch;
};

void fun()
{
union un test;
test.i = 1;
if(ch == 1)
cout << "小端" << endl;
else
cout << "大端" << endl;
}
```
设计模式
单例模式线程安全的写法
STL里的迭代器使用了迭代器模式
1. 有序  查找  如果包含这两个关键字首先要想到的时二分查找法
2. 字符串替换，顺序调整 可以考虑逆序复制
3. 反转字符串 可以考虑先把每个单词逆序,然后整个字符串逆序  负负得正


### 数据结构

Hash表实现（拉链和分散地址）
```
开链法: 使用数组链表的方式来保存数据,建立一个数据，每个数组的元素是一个链表
分散地址法: 出现冲突时,使用通过查找数组空位而不是通过哈希函数来获取数组下标
```
Hash策略常见的有哪些？
```
线性探测法: 查找距离冲突单元最近的空闲单元保存
二次探测法: 避免聚簇；从冲突位置将搜索单元向前推进一定的距离
双重哈希法: 引入两个hash函数,使偏移到下一个位置与key值相关
随机散列法: 探测序列是由密钥播种的伪随机数生成器的输出生成

```
STL中hash_map扩容发生什么？
```
创建一个新桶，该桶是原来桶两倍大最接近的质数(判断n是不是质数的方法：用n除2到$sqrt(n)$范围内的数) ；
将原来桶里的数通过指针的转换，插入到新桶中(注意STL这里做的很精细，没有直接将数据从旧桶遍历拷贝数据插入到新桶，而是通过指针转换)
通过swap函数将新桶和旧桶交换，销毁新桶。
```

26.二叉树
```
二叉树结构，二叉查找树实现；
二叉树的六种遍历；
二叉树的按层遍历；
递归是解决二叉树相关问题的神级方法；
树的各种常见算法题(http://blog.csdn.net/xiajun07061225/article/details/12760493)；
```

27. Trie树(字典树)]
```
每个节点保存一个字符
根节点不保存字符
每个节点最多有n个子节点(n是所有可能出现字符的个数)
查询的复杂父为O(k)，k为查询字符串长度
```

28. 链表
```
链表和插入和删除，单向和双向链表都要会
链表的问题考虑多个指针和递归
    反向打印链表(递归)
    打印倒数第K个节点(前后指针)
    链表是否有环(快慢指针)
```

队列和栈的区别(从实现，应用，自身特点多个方面来阐述，不要只说一个先入先出，先入后出，这个你会别人也会，要展现出你比别人掌握的更深)
```
相同点:
    都是线性结构
    插入操作都是限定在表尾进行
    都可以通过顺序结构和链式结构实现
    插入和删除的时间复杂度都是O(1),空间复杂度上也一样
    多链栈和多链队列的管理模式可以相同
不同点:
    删除数据元素的位置不同,栈的删除操作在表尾队列的删除操作在表头
    顺序栈能够实现多栈空间共享,顺序队列不能
    应用场景不同
```
典型的应用场景
```
栈的应用场景:
    括号问题的求解 表达式的转换和求值 函数调用和递归实现 深度优先搜索遍历
队列的应用场景
    各种资源的管理 消息缓冲器管理  广度游戏搜索遍历
```


30. 海量数据问题
```
- 十亿整数（随机生成，可重复）中前K最大的数

类似问题的解决方法思路：
    首先哈希将数据分成N个文件，然后对每个文件建立K个元素最小/大堆（根据要求来选择）。
    最后将文件中剩余的数插入堆中，并维持K个元素的堆。最后将N个堆中的元素合起来分析。
    可以采用归并的方式来合并。在归并的时候为了提高效率还需要建一个N个元素构成的最大堆，先用N个堆中的最大值填充这个堆，然后就是弹出最大值，指
    针后移的操作了。
    当然这种问题在现在的互联网技术中，一般就用map-reduce框架来做了。

大数据排序相同的思路：
    先哈希（哈希是好处是分布均匀，相同的数在同一个文件中），
    然后小文件装入内存快排，排序结果输出到文件。最后建堆归并。
十亿整数（随机生成，可重复）中出现频率最高的一千个
```

32. 排序算法
```
- 排序算法当然是基础内容了，必须至少能快速写出，快排，建堆，和归并

- 每种算法的时间空间复杂度，最好最差平均情况
```


33. 位运算
```
### 布隆过滤器

几十亿个数经常要查找某一个数在不在里面，使用布隆过滤器，布隆过滤器的原理。布隆过滤器可能出现误判，怎么保证无误差？
```

******************
# 网络与TCP/IP
- [TCP与UDP之间的区别](http://blog.csdn.net/shanghairuoxiao/article/details/68927070)
```
(1) IP首部，TCP首部，UDP首部
TCP首部:  
        16位源端口  | 16位目的端口
            32位序列号
            32位确认号
        4位头部长度|6位保留字段|SYN|ACK|RST| 16位窗口
        16位校验和|16位紧急指针
IP首部:

UDP首部:
    源端口|目的端口|长度|校验和

(2) TCP和UDP区别
    UDP:
        面向无连接的,发送数据前不需要进行三次握手建立连接
        有单播，多播，广播的功能,udp不止支持一对一,还支持一对多,多对多
        upd是面向报文的
        不可靠
        头部开销小,传输数据报文时很高效
    TCP:
        面向连接,发送数据前必须建立连接
        仅支持单播传输
        面向字节流
        可靠传输
        提供拥塞控制
        提供全双工通信

(3) TCP和UDP应用场景
    TCP适用于可靠性要求高的地方入文件传输
    UDP适用于实时应用 IP电话 视频会议 直播等
(4) 如何实现可靠的UDP
1、添加seq/ack机制，确保数据发送到对端
2、添加发送和接收缓冲区，主要是用户超时重传。
3、添加超时重传机制。

```

```
(1) 三次握手和四次挥手状态变化；
三次握手:
    SYNc   ----> 
    (此时状态为SYN_SENT)
        <------ SYNs ACKc  其中ACKc = SYNc+1
    (此时状态为SYN_RECV)
    ACKc-------->          其中ACKc=SYNs+1
    (此时状态为ESTABLISHED)

四次挥手:
    FIN -------->
    (进入FIN_WAIT_1状态)
    <----------- ACK
    (进入FIN_WAIT_2状态) 
     
    <---------------- FIN
    (进入TIME_WAIT状态,等待2MSL后即可回到CLOSED状态)
    ACK ---------------->
    
为什么建立连接协议是三次握手，而关闭连接却是四次握手呢？
这是因为服务端的LISTEN状态下的SOCKET当收到SYN的报文的建连请求后,它可以把ACK和SYN放在一个报文
里发送,但关闭连接时,当收到对方的FIN报文通知时,他仅仅表示对方没有数据发送,未必你所有的数据都发送
给对方了，所以你未必会马上关闭SOCKET,所以这里报文多数情况下是要分开发送的;

(2) 2MSL是什么状态？作用是什么？
虽然双方都同意关闭连接了,而且握手的4个报文也都发送完毕,按理可以直接回到CLOSED状态,但是,我们必须假想网络时不可靠的,无法保证你最后发送的ACK报文一定会被对方收到,即对方处于LAST_ACK状态下的SOCKET可能因为超时未收到ACK报文而重发FIN报文，所以这个TIME_WAIT状态的作用就是用来重发可能丢失的ACK报文
```
stl

|容器|底层数据结构|时间复杂度|有无序|是否可重复|
|----|-----------|---------|-----|---------|
|array|数组|随机读改O(1)|无序|可重复|
|vector|数组|随机读改,尾部插入，尾部删除O(1)头部插入、头部删除O(n)|无序|可重复|
|dequeue|双端队列|头尾插入、头尾删除O(1)|无序|可重复|
|forward_list|单向链表|插入删除O(1)|无序|可重复|
|list|双向链表|插入删除O(1)|无序|可重复|
|stack|deque/list|顶部插入、顶部删除O(1)|无序|可重复|
|queue|deque/list|尾部插入、头部删除O(1)|无序|可重复|
|priority_quue|vector/max-heap|插入、删除O(logn)|有序|可重复|
|set|红黑树|插入、删除、查找O(logn)|有序|不可重复|

TCP如何保证可靠传输的？
```
连接管理 --- 三次握手和四次挥手
数据破坏 --- 通过校验和
丢包     --- 应答与超时重复机制
分片乱序 --- 序列号
滑动窗口 --- 提高发送效率,对发送端和接收端流量进行控制
加快通信速度 --- 快速重发,三次收到重发消息进行重发
流控制  ---- 避免网络流量消费
拥塞控制 --- 慢启动算法 拥塞窗口
```
Nagle算法
```
数据在发送端被缓存,如果缓存到达指定大小就将其发送,或者上一个数据的应答包到达,将缓存取一次性全部发送；Nagle算法从发送端角度考虑减少了数据包的个数,时延应答从接受端角度考虑减少了数据包的个数
```
TCP窗口
```
滑动窗口协议的基本原理就是在任意时刻，发送方都维持了一个连续的允许发送的帧的序号，称为发送窗口；同时，接收方也维持了一个连续的允许接收的帧的序号，称为接收窗口

比特滑动窗口协议
 当发送窗口和接收窗口的大小固定为1时，滑动窗口协议退化为停等协议
后退n协议
  发送方在发完一个数据帧后，不停下来等待应答帧，而是连续发送若干个数据帧，即使在连续发送过程中收到了接收方发来的应答帧，也可以继续发送。且发送方在每发送完一个数据帧时都要设置超时定时器。只要在所设置的超时时间内仍收到确认帧，就要重发相应的数据帧
选择重传协议
    当接收方发现某帧出错后，其后继续送来的正确的帧虽然不能立即递交给接收方的高层，但接收方仍可收下来，存放在一个缓冲区中，同时要求发送方重新传送出错的那一帧。一旦收到重新传来的帧后，就可以原已存于缓冲区中的其余帧一并按正确的顺序递交高层
```
TCP客户与服务器模型，用到哪些函数
```
#include <sys/socket.h>
 int socket(int family,int type,int protocol); 　　　
  　　 　返回：非负描述字－－－成功　　　-1－－－失败

#include <sys/socket.h> 　
int bind(int sockfd, const struct sockaddr * server, socklen_t addrlen);
 返回：0－－－成功　　　-1－－－失败　

   #include<sys/socket.h>
int listen(int sockfd, int backlog);
TCP的三次握手是在调用connect函数时完成的，服务器端没有调用函数，但是必须有套接字在某个端口监听，不然会返回客户端RST，终止连接。

#include <sys/socket.h> 　　 　 　 　
int accept(int listenfd, struct sockaddr *client, socklen_t * addrlen); 　

#include <unistd.h> 　　 　 　 　
 int write(int sockfd, char *buf, int len);　
  回：非负－－－成功　　　-1－－－失败

  #include <unistd.h> 　　 　 　 　
 int read(int sockfd, char *buf, intlen); 　
  回：非负－－－成功　　　-1－－－失败

   #include <sys/socket.h>　　 　 　
 int connect(int sockfd, const struct sockaddr * addr, socklen_t addrlen); 　
 返回：0－－－成功　　　-1－－－失败
 如果客户端没有收到SYN的响应包，根据TCP的超时重发机制进行重发。75秒后还没收到，就返回错误。
2. 如果目的主机没有监听目的端口号，就会返回一个RST的分节，客户端收到RST后立刻返回错误。
3. 如果SYN在中间路由遇到目的不可达，客户端收到ICMP报文，客户端保存这个报文信息，并采用第一种情况方案解决，也就是重发
```

UDP客户与服务器模型，用到哪些函数
```
#include <sys/types.h>
#include <sys/socket.h>
sockfd = socket(AF_INET, SOCK_DGRAM, 0)；

#include <sys/types.h>          /* See NOTES */
#include <sys/socket.h>
int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);

#include <sys/types.h>
#include <sys/socket.h>

ssize_t sendto(int sockfd, const void *buf, size_t len, int flags, const struct sockaddr *dest_addr, socklen_t addrlen);
```
域名解析过程
```
1、在浏览器中输入www  . qq  .com 域名，操作系统会先检查自己本地的hosts文件是否有这个网址映射关系，如果有，就先调用这个IP地址映射，完成域名解析。 
2、如果hosts里没有这个域名的映射，则查找本地DNS解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析。 
3、如果hosts与本地DNS解析器缓存都没有相应的网址映射关系，首先会找TCP/ip参数中设置的首选DNS服务器，在此我们叫它本地DNS服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。 
4、如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析，此解析不具有权威性。 
5、如果本地DNS服务器本地区域文件与缓存解析都失效，则根据本地DNS服务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地DNS就把请求发至13台根DNS，根DNS服务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的一个IP。本地DNS服务器收到IP信息后，将会联系负责.com域的这台服务器。这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com域的下一级DNS服务器地址(http://qq.com)给本地DNS服务器。当本地DNS服务器收到这个地址后，就会找http://qq.com域服务器，重复上面的动作，进行查询，直至找到www  . qq  .com主机。 
6、如果用的是转发模式，此DNS服务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。不管是本地DNS服务器用是是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。
```
ARP的机制
```
ARP协议的主要工作就是建立、查询、更新、删除ARP表项

```


36. Ping和TraceRoute实现原理
```
(1) Ping是通过发送ICMP报文回显请求实现。
(2) TraceRoute通过发送UDP报文，设置目的端口为一个不可能的值，将IP首部中的TTL分别设置从1到N，每次逐个增加，如果收到端口不可达，说明到达目的主机，如果是因为TTL跳数超过，路由器会发送主机不可达的ICMP报文。
```

*****

1. http的主要特点:
```
简单快速：当客户端向服务器端发送请求时，只是简单的填写请求路径和请求方法即可，然后就可以通过浏览器或其他方式将该请求发送就行了
灵活：HTTP 协议允许客户端和服务器端传输任意类型任意格式的数据对象
无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接，采用这种方式可以节省传输时间。(当今多数服务器支持Keep-Alive功能，使用服务器支持长连接，解决无连接的问题)
无状态：无状态是指协议对于事务处理没有记忆能力，服务器不知道客户端是什么状态。即客户端发送HTTP请求后，服务器根据请求，会给我们发送数据，发送完后，不会记录信息。(使用 cookie 机制可以保持 session，解决无状态的问题)
```
2. http1.1的特点
```
a、默认持久连接节省通信量，只要客户端服务端任意一端没有明确提出断开TCP连接，就一直保持连接，可以发送多次HTTP请求
b、管线化，客户端可以同时发出多个HTTP请求，而不用一个个等待响应
c、断点续传ftghh
```

3. [http2.0的特点](http://www.cnblogs.com/frankyou/p/6145485.html)
```
a、HTTP/2采用二进制格式而非文本格式
b、HTTP/2是完全多路复用的，而非有序并阻塞的——只需一个HTTP连接就可以实现多个请求响应
c、使用报头压缩，HTTP/2降低了开销
d、HTTP/2让服务器可以将响应主动“推送”到客户端缓存中
```

get/post 区别
```
区别一：
get重点在从服务器上获取资源，post重点在向服务器发送数据；
区别二：
get传输数据是通过URL请求，以field（字段）= value的形式，置于URL后，并用"?"连接，多个请求数据间用"&"连接，如http://127.0.0.1/Test/login.action?name=admin&password=admin，这个过程用户是可见的；
post传输数据通过Http的post机制，将字段与对应值封存在请求实体中发送给服务器，这个过程对用户是不可见的；
区别三：
Get传输的数据量小，因为受URL长度限制，但效率较高；
Post可以传输大量数据，所以上传文件时只能用Post方式；
区别四：
get是不安全的，因为URL是可见的，可能会泄露私密信息，如密码等；
post较get安全性较高；
```

返回状态码
```
200：请求被正常处理
204：请求被受理但没有资源可以返回
206：客户端只是请求资源的一部分，服务器只对请求的部分资源执行GET方法，相应报文中通过Content-Range指定范围的资源。
301：永久性重定向
302：临时重定向
303：与302状态码有相似功能，只是它希望客户端在请求一个URI的时候，能通过GET方法重定向到另一个URI上
304：发送附带条件的请求时，条件不满足时返回，与重定向无关
307：临时重定向，与302类似，只是强制要求使用POST方法
400：请求报文语法有误，服务器无法识别
401：请求需要认证
403：请求的对应资源禁止被访问
404：服务器无法找到对应资源
500：服务器内部错误
503：服务器正忙
```

http 协议头相关
```
http数据由请求行，首部字段，空行，报文主体四个部分组成
首部字段分为：通用首部字段，请求首部字段，响应首部字段，实体首部字段
```

https与http的区别？如何实现加密传输？
```
- https就是在http与传输层之间加上了一个SSL
- 对称加密与非对称加密
```

浏览器中输入一个URL发生什么，用到哪些协议？

```
    浏览器中输入URL，首先浏览器要将URL解析为IP地址，解析域名就要用到DNS协议，首先主机会查询DNS的缓存，如果没有就给本地DNS发送查询请求。
    DNS查询分为两种方式，一种是递归查询，一种是迭代查询。如果是迭代查询，本地的DNS服务器，向根域名服务器发送查询请求，
    根域名服务器告知该域名的一级域名服务器，然后本地服务器给该一级域名服务器发送查询请求，然后依次类推直到查询到该域名的IP地址。
    DNS服务器是基于UDP的，因此会用到UDP协议。得到IP地址后，浏览器就要与服务器建立一个http连接。因此要用到http协议，http协议报文格式上面已经提到。
    http生成一个get请求报文，将该报文传给TCP层处理。如果采用https还会先对http数据进行加密。TCP层如果有需要先将HTTP数据包分片，分片依据路径MTU和MSS。TCP的数据包然后会发送给IP层，用到IP协议。IP层通过路由选路，一跳一跳发送到目的地址。当然在一个网段内的寻址是通过以太网协议实现
    (也可以是其他物理层协议，比如PPP，SLIP)，以太网协议需要直到目的IP地址的物理地址，有需要ARP协议。
```
----
#### **安全相关**

- SQL注入

```
通过把SQL命令插入到Web表单提交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意的SQL命令

把应用服务器的数据库权限降至最低，尽可能地减少 SQL 注入攻击带来的危害
避免网站打印出SQL错误信息，比如类型错误、字段不匹配等，把代码里的SQL语句暴露出来，以防止攻击者利用这些错误信息进行SQL注入。
对进入数据库的特殊字符（'"\尖括号&*;等）进行转义处理，或编码转换。
所有的查询语句建议使用数据库提供的参数化查询接口，参数化的语句使用参数而不是将用户输入变量嵌入到SQL语句中，即不要直接拼接SQL语句。
在测试阶段，建议使用专门的 SQL 注入检测工具进行检测。网上有很多这方面的开源工具，例如sqlmap、SQLninja等。
善用数据库操作库，有些库包可能已经做好了相关的防护，我们只需阅读其文档，看是否支持相应的功能即可。

```

- XSS
```
黑客想尽一切方法 将一段脚本内容放到目标网站的目标浏览器上解释执行

```
APR欺骗
```
ARP攻击就是通过伪造IP地址和MAC地址实现ARP欺骗，能够在网络中产生大量的ARP通信量使网络阻塞，攻击者只要持续不断的发出伪造的ARP响应包就能更改目标主机ARP缓存中的IP-MAC条目，造成网络中断或中间人攻击
同时对局域网内的一台主机和网关进行ARP欺骗，更改这台主机和网关的ARP缓存表
```


****************
- SQL语言(内外连接，子查询，分组，聚集，嵌套，逻辑)

- MySQL索引方法？索引的优化？
```
B+Tree的特点:
数据都存储在叶子节点，并且每个叶子节点的数据都是按相同顺序（升序或降序）排列存储的，再者相邻的叶子节点都用指针连接在一点，这种结构非常适合于范围查找。

B-Tree索引能够显著加快访问数据的速度，因为存储引擎不再需要进行全表扫描来获取需要的数据，而是从索引的根节点逐层往下进行搜索，这大大缩小了存储引擎扫描数据的范围，因此对查询速度的提升非常明显。

主键索引 PRIMARY KEY：它是一种特殊的唯一索引，不允许有空值。一般是在建表的时候同时创建主键索引
唯一索引 UNIQUE：唯一索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一
普通索引 INDEX：这是最基本的索引，它没有任何限制
组合索引 INDEX：即一个索引包含多个列，多用于避免回表查询
全文索引 FULLTEXT：也称全文检索，是目前搜索引擎使用的一种关键技术
```
索引设计的原则
```
适合索引的列是出现在where子句中的列，或者连接子句中指定的列
基数较小的类，索引效果较差，没有必要在此列建立索引
使用短索引，如果对长字符串列进行索引，应该指定一个前缀长度，这样能够节省大量索引空间；
不要过度索引。索引需要额外的磁盘空间，并降低写操作的性能。在修改表内容的时候，索引会进行更新甚至重构，索引列越多，这个时间就会越长。所以只保持需要的索引有利于查询即可
```
回表：当对一个列创建索引之后，索引会包含该列的键值及键值对应行所在的rowid。通过索引中记录的rowid访问表中的数据就叫回表。回表次数太多会严重影响SQL性能，如果回表次数太多，就不应该走索引扫描，应该直接走全表扫描。

EXPLAIN命令结果中的Using Index意味着不会回表，通过索引就可以获得主要的数据。Using Where则意味着需要回表取数据。

索引优化规则：
```
如果MySQL估计使用索引比全表扫描还慢，则不会使用索引   返回数据的比例是重要的指标，比例越低越容易命中索引。记住这个范围值——30%
前导模糊查询不能命中索引  
    EXPLAIN SELECT * FROM user WHERE name LIKE '%s%';
非前导模糊查询则可以使用索引，可优化为使用非前导模糊查询：
    EXPLAIN SELECT * FROM user WHERE name LIKE 's%';
数据类型出现隐式转换的时候不会命中索引，特别是当列类型是字符串，一定要将字符常量值用引号引起来
复合索引的情况下，查询条件不包含索引列最左边部分（不满足最左原则），不会命中符合索引
    注意，最左原则并不是说是查询条件的顺序 而是查询条件中是否包含索引最左列字段
union、in、or都能够命中索引，建议使用in
用or分割开的条件，如果or前的条件中列有索引，而后面的列中没有索引，那么涉及到的索引都不会被用到
    因为or后面的条件列中没有索引，那么后面的查询肯定要走全表扫描，在存在全表扫描的情况下，就没有必要多一次索引扫描增加IO访问
负向条件查询不能使用索引，可以优化为in查询。
    负向条件有：!=、<>、not in、not exists、not like等。
范围条件查询可以命中索引。范围条件有：<、<=、>、>=、between等。
数据库执行计算不会命中索引
利用覆盖索引进行查询，避免回表
建立索引的列，不允许为null。
更新十分频繁的字段上不宜建立索引：因为更新操作会变更B+树，重建索引。这个过程是十分消耗数据库性能的。
区分度不大的字段上不宜建立索引：类似于性别这种区分度不大的字段，建立索引的意义不大。因为不能有效过滤数据，性能和全表扫描相当。另外返回数据的比例在30%以外的情况下，优化器不会选择使用索引。
业务上具有唯一特性的字段，即使是多个字段的组合，也必须建成唯一索引。虽然唯一索引会影响insert速度，但是对于查询的速度提升是非常明显的。另外，即使在应用层做了非常完善的校验控制，只要没有唯一索引，在并发的情况下，依然有脏数据产生。
多表关联时，要保证关联字段上一定有索引。
创建索引时避免以下错误观念：索引越多越好，认为一个查询就需要建一个索引；宁缺勿滥，认为索引会消耗空间、严重拖慢更新和新增速度；抵制唯一索引，认为业务的唯一性一律需要在应用层通过“先查后插”方式解决；过早优化，在不了解系统的情况下就开始优化。
```

- InnoDB与MyISAM区别？

```
InnoDB支持事务，MyISAM不支持，对于InnoDB每一条SQL语言都默认封装成事务，自动提交，这样会影响速度，所以最好把多条SQL语言放在begin和commit之间，组成一个事务； 
InnoDB支持外键，而MyISAM不支持。对一个包含外键的InnoDB表转为MYISAM会失败； 
InnoDB是聚集索引，使用B+Tree作为索引结构，数据文件是和（主键）索引绑在一起的（表数据文件本身就是按B+Tree组织的一个索引结构），必须要有主键，
    通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。
    MyISAM是非聚集索引，也是使用B+Tree作为索引结构，索引和数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。
    也就是说：InnoDB的B+树主键索引的叶子节点就是数据文件，辅助索引的叶子节点是主键的值；而MyISAM的B+树主键索引和辅助索引的叶子节点都是数据文件的地址指针。
InnoDB不保存表的具体行数，执行select count(*) from table时需要全表扫描。而MyISAM用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快（注意不能加有任何WHERE条件）；
Innodb不支持全文索引，而MyISAM支持全文索引，在涉及全文索引领域的查询效率上MyISAM速度更快高；PS：5.7以后的InnoDB支持全文索引了
MyISAM表格可以被压缩后进行查询操作
InnoDB支持表、行(默认)级锁，而MyISAM支持表级锁
    InnoDB的行锁是实现在索引上的，而不是锁在物理行记录上。潜台词是，如果访问没有命中索引，也无法使用行锁，将要退化为表锁。
InnoDB表必须有主键（用户没有指定的话会自己找或生产一个主键），而Myisam可以没有
Innodb存储文件有frm、ibd，而Myisam是frm、MYD、MYI
        Innodb：frm是表定义文件，ibd是数据文件
        Myisam：frm是表定义文件，myd是数据文件，myi是索引文件
```

- 事务的ACID
```
原子性（A）：是指事务要么都成功，要么都失败。成功就影响数据库，失败就对数据库不影响，保持原样。
一致性（C）：是指应用层系统从一种正确的状态，在事务成功后，达成另一种正确的状态。比如：A、B账面共计100W，A向B转账，加上事务控制，转成功后，他们账户总额应还是100W，事务应保持这种应用逻辑正确一致。还有，转账（事务成功）前后，数据库内部的数据结构--比如账户表的主键、外键、列必须大于0、Btree、双向链表等约束需要是正确的，和原来一致的。
隔离性（I）：隔离是指当多个事务提交时，让它们按顺序串行提交，每个时刻只有一个事务提交。但隔离处理并发事务，效率很差。所以SQL标准制作者妥协了，提出了4种事务隔离等级（1，read-uncommited 未提交就读，可能产生脏读  2，read-commited 提交后读  可能产生不可重复读  3，repeatable-read 可重复读  可能产生幻读    4，serializable 序列化，最高级别，按顺序串行提交） 事务的隔离性实现详见https://zhuanlan.zhihu.com/p/27035174
持久性（D）：是指事务一旦提交后，对数据库中的数据改变是永久性的。
```
```
一）脏读：就是A事务在读取数据时，B事务对同一个数据修改了，但B未提交，A再读取时，读到了B修改后的数据，但是B事务提交失败，回滚，A后读到的数据就是B修改后的脏数据，此为脏读。

二）不可重复读：就是A事务读取数据，B事务改了这个数据，也提交成功了，A再读取就是B修改后的数据，再也不能重复读到最开始的那个数据值了，此为不可重复读

三）幻读：可重复读就是A事务读取数据，B事务改了这个数据（update），也提交成功了，A再读这个数据，SQL机制强行让A仍然读之前读到的数据值，这就是可重复读，这种机制对Insert操作无效，A事务在可重复读的机制下，读取数据，B事务insert一条数据，提交成功，A再读这个数据，会显示B插入的数据，此为幻读。
```

- 事务的四个隔离级别
```
Read uncommitted(未授权读取、读未提交)： 
    如果一个事务已经开始写数据，则另外一个事务则不允许同时进行写操作，但允许其他事务读此行数据。该隔离级别可以通过“排他写锁”实现。这样就避免了更新丢失，却可能出现脏读。也就是说事务B读取到了事务A未提交的数据。
Read committed（授权读取、读提交）： 
    读取数据的事务允许其他事务继续访问该行数据，但是未提交的写事务将会禁止其他事务访问该行。该隔离级别避免了脏读，但是却可能出现不可重复读。事务A事先读取了数据，事务B紧接了更新了数据，并提交了事务，而事务A再次读取该数据时，数据已经发生了改变。
Repeatable read（可重复读取）： 
    可重复读是指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据之间，即使第二个事务对数据进行修改，第一个事务两次读到的的数据是一样的。这样就发生了在一个事务内两次读到的数据是一样的，因此称为是可重复读。读取数据的事务将会禁止写事务（但允许读事务），写事务则禁止任何其他事务。这样避免了不可重复读取和脏读，但是有时可能出现幻象读。（读取数据的事务）这可以通过“共享读锁”和“排他写锁”实现。
Serializable（序列化）： 
    提供严格的事务隔离。它要求事务序列化执行，事务只能一个接着一个地执行，但不能并发执行。如果仅仅通过“行级锁”是无法实现事务序列化的，必须通过其他机制保证新插入的数据不会被刚执行查询操作的事务访问到。序列化是最高的事务隔离级别，同时代价也花费最高，性能很低，一般很少使用，在该级别下，事务顺序执行，不仅可以避免脏读、不可重复读，还避免了幻像读。 
```

```
悲观锁
    悲观锁，它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度。因此，在整个数据处理过程中，将数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制。也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统的数据访问层中实现了加锁机制，也无法保证外部系统不会修改数据。
乐观锁（ Optimistic Locking ） 
    相对悲观锁而言，乐观锁假设认为数据一般情况下不会造成冲突，所以只会在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则返回用户错误的信息，让用户决定如何去做。实现乐观锁一般来说有以下2种方式：
使用版本号 
    使用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式。何谓数据版本？即为数据增加一个版本标识，一般是通过为数据库表增加一个数字类型的 “version” 字段来实现。当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值加一。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的version值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据。
使用时间戳 
    乐观锁定的第二种实现方式和第一种差不多，同样是在需要乐观锁控制的table中增加一个字段，名称无所谓，字段类型使用时间戳（timestamp）, 和上面的version类似，也是在更新提交的时候检查当前数据库中数据的时间戳和自己更新前取到的时间戳进行对比，如果一致则OK，否则就是版本冲突。
```

- 查询优化(从索引上优化，从SQL语言上优化)

- B-与B+树区别？

- MySQL的联合索引(又称多列索引)是什么？生效的条件？

- 分库分表




### IO模型

- **五种IO模型：**阻塞IO，非阻塞IO，IO复用，信号驱动式IO，异步IO

- **select，poll，epoll的区别**

**select：**是最初解决IO阻塞问题的方法。用结构体fd_set来告诉内核监听多个文件描述符，该结构体被称为描述符集。由数组来维持哪些描述符被置位了。对结构体的操作封装在三个宏定义中。通过轮寻来查找是否有描述符要被处理，如果没有返回**

存在的问题：
1. 内置数组的形式使得select的最大文件数受限与FD_SIZE；
2. 每次调用select前都要重新初始化描述符集，将fd从用户态拷贝到内核态，每次调用select后，都需要将fd从内核态拷贝到用户态；
3. 轮寻排查当文件描述符个数很多时，效率很低；

**poll：**通过一个可变长度的数组解决了select文件描述符受限的问题。数组中元素是结构体，该结构体保存描述符的信息，每增加一个文件描述符就向数组中加入一个结构体，结构体只需要拷贝一次到内核态。poll解决了select重复初始化的问题。轮寻排查的问题未解决。**

**epoll：**轮寻排查所有文件描述符的效率不高，使服务器并发能力受限。因此，epoll采用只返回状态发生变化的文件描述符，便解决了轮寻的瓶颈。
- 为什么使用IO多路复用，最主要的原因是什么？
- epoll有两种触发模式？这两种触发模式有什么区别？编程的时候有什么区别？
- 上一题中编程的时候有什么区别，是在边缘触发的时候要把套接字中的数据读干净，那么当有多个套接字时，在读的套接字一直不停的有数据到达，如何保证其他套接字不被饿死(面试网易游戏的时候问的一个问题，答不上来，印象贼深刻)。

1. [select/poll/epoll区别](https://segmentfault.com/a/1190000003063859)
2. [几种网络服务器模型的介绍与比较](https://www.ibm.com/developerworks/cn/linux/l-cn-edntwk/index.html?ca=drs-)
3. [epoll为什么这么快](http://www.jianshu.com/p/b5bc204da984)(搞懂这篇文章，关于IO复用的问题就信手拈来了)
### TCP网络

nagle算法；
keepalive选项；
Linger选项；
对于某一端出现大量CLOSE_WAIT 或者 TIME_WAIT如何解决；
通讯协议如何设计或如何解决数据包的粘包与分片问题；
心跳机制如何设计；（可能不会直接问问题本身，如问如何检查死链）
断线重连机制如何设计；
对 IO Multiplexing 技术的理解；
收发数据包正确的方式，收发缓冲区如何设计；
优雅关闭；
定时器如何设计；
epoll 的实现原理。

#### 安全相关

- SQL注入

- XSS

- RCFS

- APR欺骗



## [数据库](http://blog.csdn.net/shanghairuoxiao/article/details/76888423)

- SQL语言(内外连接，子查询，分组，聚集，嵌套，逻辑)

- MySQL索引方法？索引的优化？

- InnoDB与MyISAM区别？

- 事务的ACID

- 事务的四个隔离级别

- 查询优化(从索引上优化，从SQL语言上优化)

- B-与B+树区别？

- MySQL的联合索引(又称多列索引)是什么？生效的条件？

- 分库分表

***********

# Linux

### [**进程与线程**](http://blog.csdn.net/shanghairuoxiao/article/details/74012512)
```
(1) 进程与线程区别？

(2) 线程比进程具有哪些优势？

(3) 什么时候用多进程？什么时候用多线程？

(4) LINUX中进程和线程使用的几个函数？

(5) 线程同步？

在Windows下线程同步的方式有：互斥量，信号量，事件，关键代码段

在Linux下线程同步的方式有：互斥锁，自旋锁，读写锁，屏障(并发完成同一项任务时，屏障的作用特别好使)

知道这些锁之间的区别，使用场景？

```

### Linux的API
- **fork与vfork区别**
fork和vfork都用于创建子进程。但是vfork创建子进程后，父进程阻塞，直到子进程调用exit()或者excle()。
对于内核中过程fork通过调用clone函数，然后clone函数调用do_fork()。do_fork()中调用copy_process()函数先复制task_struct结构体，然后复制其他关于内存，文件，寄存器等信息。fork采用写时拷贝技术，因此子进程和父进程的页表指向相同的页框。但是vfork不需要拷贝页表，因为父进程会一直阻塞，直接使用父进程页表。

- **exit()与_exit()区别**
exit()清理后进入内核，_exit()直接陷入内核。


- 孤儿进程与僵死进程
1. 孤儿进程是怎么产生的？
2. 僵死进程是怎么产生的？
3. 僵死进程的危害？
4. 如何避免僵死进程的产生？

- **Linux是如何避免内存碎片的**
1. 伙伴算法，用于管理物理内存，避免内存碎片;
2. 高速缓存Slab层用于管理内核分配内存，避免碎片。

- **共享内存的实现原理？**

共享内存实现分为两种方式一种是采用mmap，另一种是采用XSI机制中的共享内存方法。mmap是内存文件映射，将一个文件映射到进程的地址空间，用户进程的地址空间的管理是通过vm_area_struct结构体进行管理的。mmap通过映射一个相同的文件到两个不同的进程，就能实现这两个进程的通信，采用该方法可以实现任意进程之间的通信。mmap也可以采用匿名映射，不指定映射的文件，但是只能在父子进程间通信。XSI的内存共享实际上也是通过映射文件实现，只是其映射的是一种特殊文件系统下的文件，该文件是不能通过read和write访问的。

二者区别：

> 1、 系统V共享内存中的数据，从来不写入到实际磁盘文件中去；而通过mmap()映射普通文件实现的共享内存通信可以指定何时将数据写入磁盘文件中。注：前面讲到，系统V共享内存机制实际是通过映射特殊文件系统shm中的文件实现的，文件系统shm的安装点在交换分区上，系统重新引导后，所有的内容都丢失。



> 2、 系统V共享内存是随内核持续的，即使所有访问共享内存的进程都已经正常终止，共享内存区仍然存在（除非显式删除共享内存），在内核重新引导之前，对该共享内存区域的任何改写操作都将一直保留。



> 3、 通过调用mmap()映射普通文件进行进程间通信时，一定要注意考虑进程何时终止对通信的影响。而通过系统V共享内存实现通信的进程则不然。注：这里没有给出shmctl的使用范例，原理与消息队列大同小异。



- 系统调用与库函数(open, close, create, lseek, write, read)

- 同步方法有哪些？

1. 互斥锁，自旋锁，信号量，读写锁，屏障

2. 互斥锁与自旋锁的区别：互斥锁得不到资源的时候阻塞，不占用cpu资源。自旋锁得不到资源的时候，不停的查询，而然占用cpu资源。

3. [死锁](http://blog.csdn.net/shanghairuoxiao/article/details/70444940)

### [**进程间通讯方式**](http://www.cnblogs.com/CheeseZH/p/5264465.html)



> **管道( pipe )**：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。

>

**命名管道 (FIFO) **： 有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。

>

> **信号量**：信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据，有XSI信号量和POSIX信号量，POSIX信号量更加完善。

>

**消息队列( message queue )** ： 消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。

>

**共享内存( shared memory ) **：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。(原理一定要清楚，常考)

>

>**信号 ( sinal ) **： 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生，常见的信号。

>

**套接字( socket ) **： 套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同及其间的进程通信。



- **匿名管道与命名管道的区别**：匿名管道只能在具有公共祖先的两个进程间使用。

- **共享文件映射mmap**

mmap建立进程空间到文件的映射，在建立的时候并不直接将文件拷贝到物理内存，同样采用缺页终端。mmap映射一个具体的文件可以实现任意进程间共享内存，映射一个匿名文件，可以实现父子进程间共享内存。



- **常见的信号有哪些？**：SIGINT，SIGKILL(不能被捕获)，SIGTERM(可以被捕获)，SIGSEGV，SIGCHLD，SIGALRM

### 进程调度

1. Linux进程分为两种，实时进程和非实时进程；

2. 优先级分为静态优先级和动态优先级，优先级的范围；

3. 调度策略，FIFO，LRU，时间片轮转

4. 交互进程通过平均睡眠时间而被奖励；
### 命令行
- Linux命令 在一个文件中，倒序打印第二行前100个大写字母
cat filename | head -n 2 | tail -n 1 | grep '[[:upper:]]' -o | tr -d '\n'| cut -c 1-100 | rev

- 与CPU，内存，磁盘相关的命令(top，free, df, fdisk)
- 网络相关的命令netstat，tcpdump等
- sed, awk, grep三个超强大的命名，分别用与格式化修改，统计，和正则查找
- ipcs和ipcrm命令
- 查找当前目录以及字母下以.c结尾的文件，且文件中包含"hello world"的文件的路径
- 创建定时任务


**********
### [**内存管理**](http://blog.csdn.net/shanghairuoxiao/article/details/70256247)

1. 虚拟内存的作用？

2. 虚拟内存的实现？

3. 操作系统层面对内存的管理？

4. 内存池的作用？STL里[内存池如何实现](https://github.com/oscarwin/MemoryPool)？

5. 进程空间和内核空间对内存的管理不同？

6. Linux的slab层，VAM？

7. 伙伴算法

8. 高端内存

58. C++内存管理
```
在c++中内存主要分为5个存储区：
栈（Stack）：局部变量，函数参数等存储在该区，由编译器自动分配和释放.栈属于计算机系统的数据结构，进栈出栈有相应的计算机指令支持，
            而且分配专门的寄存器存储栈的地址，效率分高，内存空间是连续的，但栈的内存空间有限。
堆(Heap)：  需要程序员手动分配和释放（new,delete），属于动态分配方式。内存空间几乎没有限制，内存空间不连续，因此会产生内存碎片。
            操作系统有一个记录空间内存的链表，当收到内存申请时遍历链表，找到第一个空间大于申请空间的堆节点，将该节点分配给程序，
            并将该节点从链表中删除。一般，系统会在该内存空间的首地址处记录本次分配的内存大小，用于delete释放该内存空间。
全局/静态存储区:     全局变量，静态变量分配到该区，到程序结束时自动释放，包括DATA段（全局初始化区）与BSS段（全局未初始化段）。
                    其中，初始化的全局变量和静态变量存放在DATA段，未初始化的全局变量和静态变量存放在BSS段。
                    BSS段特点：在程序执行前BSS段自动清零，所以未初始化的全局变量和静态变量在程序执行前已经成为0.
文字常量区：存放常量，而且不允许修改。程序结束后由系统释放。
程序代码区：存放程序的二进制代码

    学会迁移，可以说到malloc，从malloc说到操作系统的内存管理???
    说道内核态和用户态，然后就什么高端内存，slab层，伙伴算法，VMA可以巴拉巴拉了，接着可以迁移到fork()。???
```
21. 定位内存泄露
```
(1)在windows平台下通过CRT中的库函数进行检测；
(2)在可能泄漏的调用前后生成块的快照，比较前后的状态，定位泄漏的位置
(3)Linux下通过工具valgrind检测
```

********


### 多线程
### [**死锁**](http://blog.csdn.net/shanghairuoxiao/article/details/70444940)

(1) 死锁产生的条件；

(2) 死锁的避免；
25、线程间的同步方式，最好说出具体的系统调用
哈希表的桶个数为什么是质数，合数有何不妥？
3. enable_share_from_this 是做什么的，请举一个场景说明？
```
然后就开始聊多线程编程模式、线程安全等问题。
我觉得这个问题是一个很好的问题，从语言出发，扩展到工程经验和对编程的理解。
而且弱指针确实是c++非常有特色的一个特性
```

 ++i是否是原子操作
明显不是，++i主要有三个步骤，把数据从内存放在寄存器上，在寄存器上进行自增，把数据从寄存器拷贝会内存，每个步骤都可能被中断。

1. 了解进程线程的基本概念，能用一种语言在一个平台上实现一个多线程的例子。
2. 了解为什么要用Mutex之类的工具做锁来同步和保护资源。弄懂诸如racing condition，死锁之类的概念。50%公司的见面题，用来砍死大无畏。
3. 了解编译器优化带来的影响，了解cache的影响，了解volatile，memory barrier之类的概念。
4. 了解一下你主攻平台＋语言所提供的工具库，知道常用的工具的用法和使用场景：Mutex，Semaphore，原子操作集，Condition Variable，spin lock。这几个算是比较常用的，在各个平台＋语言也都有对应实现。老实说，spinlock，condition variable是我工作里从没用过的
5. 了解常用的多线程设计范式，比如读写锁（Reader/Writer Lock，非常经典的范式，有偏向读和写的不同变形，至少被要求写过3次），生产消费范式（写过2次），一些常用容器的实现，比如BlockingQueue（写过3次）或者concurrentHashmap（写过2次）。
熟悉一下一些算不上多线程设计模式的小技巧，比如传递只读对象可以避免加锁，或者Copy传递以防外部修改之类的（讨论环节被问过）。
另外值得特别一提的一个小细节是，Singleton的线程安全是个很有意思而且容易出错的话题，值得一看（只被问过一次，不过我答挂了，所以印象及其深）。还有可能会问的是一些有趣的小场景让你实现一些功能需要线程安全


### Redis
redis 的网络通信模型、redis 各种数据结构的实现

```
1.Redis 是一个基于内存的高性能key-value数据库。
2.Redis相比memcached有哪些优势：

memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型redis的速度比memcached快很多redis可以持久化其数据
3.Redis是单线程redis利用队列技术将并发访问变为串行访问，消除了传统数据库串行控制的开销
4.Reids常用5种数据类型string，list，set，sorted set，hash
6.Reids6种淘汰策略：
    noeviction: 不删除策略, 达到最大内存限制时, 如果需要更多内存, 直接返回错误信息。大多数写命令都会导致占用更多的内存(有极少数会例外。**allkeys-lru:**所有key通用; 优先删除最近最少使用(less recently used ,LRU) 的 key。
    **volatile-lru:**只限于设置了 expire 的部分; 优先删除最近最少使用(less recently used ,LRU) 的 key。
    **allkeys-random:**所有key通用; 随机删除一部分 key。volatile-random: 只限于设置了 expire 的部分; 随机删除一部分 key。
    volatile-ttl: 只限于设置了 expire 的部分; 优先删除剩余时间(time to live,TTL) 短的key。
```    

7. Redis的并发竞争问题如何解决?
```
单进程单线程模式，采用队列模式将并发访问变为串行访问。Redis本身没有锁的概念，Redis对于多个客户端连接并不存在竞争，利用setnx实现锁。
8.Redis是使用c语言开发的。
```
9.Redis前端启动命令./redis-server
10.Reids支持的语言：java、C、C#、C++、php、Node.js、Go等。
11.Redis 持久化方案：
Rdb 和 Aof

12.Redis 的主从复制持久化保证了即使redis服务重启也不会丢失数据，因为redis服务重启后会将硬盘上持久化的数据恢复到内存中，但是当redis服务器的硬盘损坏了可能会导致数据丢失，如果通过redis的主从复制机制就可以避免这种单点故障，

13.Redis是单线程的，但Redis为什么这么快？
1、完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；
2、数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的；
3、采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；
4、使用多路I/O复用模型，非阻塞IO；这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程
5、使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；
14.为什么Redis是单线程的？
Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了（毕竟采用多线程会有很多麻烦！）。

15.Redis info查看命令：info memory

16.Redis内存模型
    used_memory：Redis分配器分配的内存总量（单位是字节），包括使用的虚拟内存（即swap）；Redis分配器后面会介绍。
    used_memory_human只是显示更友好。
    used_memory_rss**：**Redis进程占据操作系统的内存（单位是字节），与top及ps命令看到的值是一致的；除了分配器分配的内存之外，
    used_memory_rss还包括进程运行本身需要的内存、内存碎片等，但是不包括虚拟内存。
    mem_fragmentation_ratio**：**内存碎片比率，该值是used_memory_rss / used_memory的比值。
    mem_allocator**：**Redis使用的内存分配器，在编译时指定；可以是 libc 、jemalloc或者tcmalloc，默认是jemalloc；截图中使用的便是默认的jemalloc。

17.Redis内存划分数据
    作为数据库，数据是最主要的部分；这部分占用的内存会统计在used_memory中。
    进程本身运行需要的内存Redis主进程本身运行肯定需要占用内存，如代码、常量池等等；
    这部分内存大约几兆，在大多数生产环境中与Redis数据占用的内存相比可以忽略。
    这部分内存不是由jemalloc分配，因此不会统计在used_memory中。缓冲内存缓冲内存包括客户端缓冲区、复制积压缓冲区、AOF缓冲区等；
    其中，客户端缓冲存储客户端连接的输入输出缓冲；复制积压缓冲用于部分复制功能；
    AOF缓冲区用于在进行AOF重写时，保存最近的写入命令。在了解相应功能之前，不需要知道这些缓冲的细节；这部分内存由jemalloc分配，因此会统计在used_memory中。内存碎片内存碎片是Redis在分配、回收物理内存过程中产生的。例如，如果对数据的更改频繁，而且数据之间的大小相差很大，可能导致redis释放的空间在物理内存中并没有释放，但redis又无法有效利用，这就形成了内存碎片。内存碎片不会统计在used_memory中。18.Redis对象有5种类型无论是哪种类型，Redis都不会直接存储，而是通过redisObject对象进行存储。
19.Redis没有直接使用C字符串(即以空字符’\0’结尾的字符数组)作为默认的字符串表示，而是使用了SDS。SDS是简单动态字符串(Simple Dynamic String)的缩写。
20.Reidis的SDS在C字符串的基础上加入了free和len字段
21.Reids主从复制复制是高可用Redis的基础，哨兵和集群都是在复制基础上实现高可用的。复制主要实现了数据的多机备份，以及对于读操作的负载均衡和简单的故障恢复。缺陷：故障恢复无法自动化；写操作无法负载均衡；存储能力受到单机的限制。
22.Redis哨兵在复制的基础上，哨兵实现了自动化的故障恢复。缺陷：写操作无法负载均衡；存储能力受到单机的限制。
23.Reids持久化触发条件RDB持久化的触发分为手动触发和自动触发两种。
24.Redis 开启AOFRedis服务器默认开启RDB，关闭AOF；要开启AOF，需要在配置文件中配置：appendonly yes
25.AOF常用配置总结下面是AOF常用的配置项，以及默认值；前面介绍过的这里不再详细介绍。
    appendonly no：是否开启
    AOFappendfilename "appendonly.aof"：AOF文件名
    dir ./：RDB文件和AOF文件所在目录
    appendfsync everysec：fsync持久化策略
    no-appendfsync-on-rewrite no：AOF重写期间是否禁止
    fsync；如果开启该选项，可以减轻文件重写时CPU和硬盘的负载（尤其是硬盘），但是可能会丢失AOF重写期间的数据；需要在负载和安全性之间进行平衡
    auto-aof-rewrite-percentage 100：文件重写触发条件之一
    auto-aof-rewrite-min-size 64mb：文件重写触发提交之一
    aof-load-truncated yes：如果AOF文件结尾损坏，Redis启动时是否仍载入AOF文件
26.RDB和AOF的优缺点
    RDB持久化优点：RDB文件紧凑，体积小，网络传输快，适合全量复制；恢复速度比AOF快很多。当然，与AOF相比，RDB最重要的优点之一是对性能的影响相对较小。
        缺点：RDB文件的致命缺点在于其数据快照的持久化方式决定了必然做不到实时持久化，而在数据越来越重要的今天，数据的大量丢失很多时候是无法接受的，因此AOF持久化成为主流。此外，RDB文件需要满足特定格式，兼容性差（如老版本的Redis不兼容新版本的RDB文件）。
    AOF持久化与RDB持久化相对应，AOF的优点在于支持秒级持久化、兼容性好，缺点是文件大、恢复速度慢、对性能影响大。
27.持久化策略选择
    （1）如果Redis中的数据完全丢弃也没有关系（如Redis完全用作DB层数据的cache），那么无论是单机，还是主从架构，都可以不进行任何持久化。
    （2）在单机环境下（对于个人开发者，这种情况可能比较常见），如果可以接受十几分钟或更多的数据丢失，选择RDB对Redis的性能更加有利；如果只能接受秒级别的数据丢失，应该选择AOF。
    （3）但在多数情况下，我们都会配置主从环境，slave的存在既可以实现数据的热备，也可以进行读写分离分担Redis读请求，以及在master宕掉后继续提供服务。

28.redis缓存被击穿处理机制使用mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法

29.Redis还提供的高级工具像慢查询分析、性能测试、Pipeline、事务、Lua自定义命令、Bitmaps、HyperLogLog、发布/订阅、Geo等个性化功能。

30.Redis常用管理命令
```
# dbsize 返回当前数据库 key 的数量。
# info 返回当前 redis 服务器状态和一些统计信息。
# monitor 实时监听并返回redis服务器接收到的所有请求信息。
# shutdown 把数据同步保存到磁盘上，并关闭redis服务。
# config get parameter 获取一个 redis 配置参数信息。（个别参数可能无法获取）
# config set parameter value 设置一个 redis 配置参数信息。（个别参数可能无法获取）
# config resetstat 重置 info 命令的统计信息。（重置包括：keyspace 命中数、
# keyspace 错误数、 处理命令数，接收连接数、过期 key 数）
# debug object key 获取一个 key 的调试信息。
# debug segfault 制造一次服务器当机。
# flushdb 删除当前数据库中所有 key,此方法不会失败。小心慎用
# flushall 删除全部数据库中所有 key，此方法不会失败。小心慎用
```

31.Reids工具命令
```
#redis-server：Redis 服务器的 daemon 启动程序
#redis-cli：Redis 命令行操作工具。当然，你也可以用 telnet 根据其纯文本协议来操作
#redis-benchmark：Redis 性能测试工具，测试 Redis 在你的系统及你的配置下的读写性能
$redis-benchmark -n 100000 –c 50
#模拟同时由 50 个客户端发送 100000 个 SETs/GETs 查询
#redis-check-aof：更新日志检查
#redis-check-dump：本地数据库检查
```

32.为什么需要持久化？
```
由于Redis是一种内存型数据库，即服务器在运行时，系统为其分配了一部分内存存储数据，一旦服务器挂了，或者突然宕机了，那么数据库里面的数据将会丢失，为了使服务器即使突然关机也能保存数据，必须通过持久化的方式将数据从内存保存到磁盘中。33.判断key是否存在exists key +key名字
```

34.删除keydel key1 key2 ...

35.缓存和数据库间数据一致性问题分布式环境下（单机就不用说了）

非常容易出现缓存和数据库间的数据一致性问题，针对这一点的话，只能说，如果你的项目对缓存的要求是强一致性的，那么请不要使用缓存。我们只能采取合适的策略来降低缓存和数据库间数据不一致的概率，而无法保证两者间的强一致性。合适的策略包括 合适的缓存更新策略，更新数据库后要及时更新缓存、缓存失败时增加重试机制，例如MQ模式的消息队列。

36.布隆过滤器bloomfilter就类似于一个hash set，用于快速判某个元素是否存在于集合中，其典型的应用场景就是快速判断一个key是否存在于某容器，不存在就直接返回。布隆过滤器的关键就在于hash算法和容器大小

37.缓存雪崩问题存在同一时间内大量键过期（失效），接着来的一大波请求瞬间都落在了数据库中导致连接异常。
```
    解决方案：1、也是像解决缓存穿透一样加锁排队。
                2、建立备份缓存，缓存A和缓存B，A设置超时时间，B不设值超时时间，先从A读缓存，A没有读B，并且更新A缓存和B缓存;
```

38.缓存并发问题
    这里的并发指的是多个redis的client同时set key引起的并发问题。比较有效的解决方案就是把redis.set操作放在队列中使其串行化，必须的一个一个执行，具体的代码就不上了，当然加锁也是可以的，至于为什么不用redis中的事务，留给各位看官自己思考探究。
39.Redis分布式redis支持主从的模式。
    原则：Master会将数据同步到slave，而slave不会将数据同步到master。Slave启动时会连接master来同步数据。这是一个典型的分布式读写分离模型。
    我们可以利用master来插入数据，slave提供检索服务。这样可以有效减少单个机器的并发访问数量
40.读写分离模型通过增加Slave DB的数量，读的性能可以线性增长。为了避免Master DB的单点故障，集群一般都会采用两台Master DB做双机热备，所以整个集群的读和写的可用性都非常高。读写分离架构的缺陷在于，不管是Master还是Slave，每个节点都必须保存完整的数据，如果在数据量很大的情况下，集群的扩展能力还是受限于单个节点的存储能力，而且对于Write-intensive类型的应用，读写分离架构并不适合。

41.数据分片模型为了解决读写分离模型的缺陷，可以将数据分片模型应用进来。可以将每个节点看成都是独立的master，然后通过业务实现数据分片。结合上面两种模型，可以将每个master设计成由一个master和多个slave组成的模型。

42. redis常见性能问题和解决方案：
    Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内尽量避免在压力很大的主库上增加从库
43. redis通讯协议RESP 是redis客户端和服务端之前使用的一种通讯协议；
    RESP 的特点：实现简单、快速解析、可读性好
44. Redis分布式锁实现先拿setnx来争抢锁，抢到之后，再用expire给锁加一个过期时间防止锁忘记了释放。

 **如果在setnx之后执行expire之前进程意外crash或者要重启维护了，那会怎么样？**
    set指令有非常复杂的参数，这个应该是可以同时把setnx和expire合成一条指令来用的！
45.Redis做异步队列一般使用list结构作为队列，rpush生产消息，lpop消费消息。当lpop没有消息的时候，要适当sleep一会再重试。
    缺点：在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如rabbitmq等。

**能不能生产一次消费多次呢？**
    使用pub/sub主题订阅者模式，可以实现1:N的消息队列。

46. Redis中海量数据的正确操作方式利用SCAN系列命令（SCAN、SSCAN、HSCAN、ZSCAN）完成数据迭代。
47. SCAN系列命令注意事项SCAN的参数没有key，因为其迭代对象是DB内数据；返回值都是数组，第一个值都是下一次迭代游标；
    时间复杂度：每次请求都是O(1)，完成所有迭代需要O(N)，N是元素数量；可用版本：version >= 2.8.0；
48. Redis 管道 Pipeline在某些场景下我们在一次操作中可能需要执行多个命令，而如果我们只是一个命令一个命令去执行则会浪费很多网络消耗时间，如果将命令一次性传输到 Redis中去再执行，则会减少很多开销时间。但是需要注意的是 pipeline中的命令并不是原子性执行的，也就是说管道中的命令到达 Redis服务器的时候可能会被其他的命令穿插
49. 事务不支持回滚
50.手写一个 LRU 算法class LRUCache<K, V> extends LinkedHashMap<K, V> {
    private final int CACHE_SIZE;

    /**
     * 传递进来最多能缓存多少数据
     *
     * @param cacheSize 缓存大小
     */
    public LRUCache(int cacheSize) {
        // true 表示让 linkedHashMap 按照访问顺序来进行排序，最近访问的放在头部，最老访问的放在尾部。
        super((int) Math.ceil(cacheSize / 0.75) + 1, 0.75f, true);
        CACHE_SIZE = cacheSize;
    }

    @Override
    protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {
        // 当 map中的数据量大于指定的缓存个数的时候，就自动删除最老的数据。
        return size() > CACHE_SIZE;
    }
}

51.多节点 Redis 分布式锁：
    Redlock 算法获取当前时间（start）。依次向 N 个 Redis节点请求锁。请求锁的方式与从单节点 Redis获取锁的方式一致。
    为了保证在某个 Redis节点不可用时该算法能够继续运行，获取锁的操作都需要设置超时时间，需要保证该超时时间远小于锁的有效时间。
    这样才能保证客户端在向某个 Redis节点获取锁失败之后，可以立刻尝试下一个节点。计算获取锁的过程总共消耗多长时间（consumeTime = end - start）。
    如果客户端从大多数 Redis节点（>= N/2 + 1) 成功获取锁，并且获取锁总时长没有超过锁的有效时间，这种情况下，客户端会认为获取锁成功，否则，获取锁失败。
    如果最终获取锁成功，锁的有效时间应该重新设置为锁最初的有效时间减去 consumeTime。如果最终获取锁失败，客户端应该立刻向所有 Redis节点发起释放锁的请求。
52.Redis 中设置过期时间主要通过以下四种方式
    expire key seconds：设置 key 在 n 秒后过期；
    pexpire key milliseconds：设置 key 在 n 毫秒后过期；
    expireat key timestamp：设置 key 在某个时间戳（精确到秒）之后过期；
    pexpireat key millisecondsTimestamp：设置 key 在某个时间戳（精确到毫秒）之后过期；
53.Reids三种不同删除策略定时删除：
    在设置键的过期时间的同时，创建一个定时任务，当键达到过期时间时，立即执行对键的删除操作惰性删除：
    放任键过期不管，但在每次从键空间获取键时，都检查取得的键是否过期，如果过期的话，就删除该键，如果没有过期，就返回该键定期删除：
    每隔一点时间，程序就对数据库进行一次检查，删除里面的过期键，至于要删除多少过期键，以及要检查多少个数据库，则由算法决定。

54.定时删除
    **优点：**对内存友好，定时删除策略可以保证过期键会尽可能快地被删除，并释放国期间所占用的内存
    **缺点：**对cpu时间不友好，在过期键比较多时，删除任务会占用很大一部分cpu时间，在内存不紧张但cpu时间紧张的情况下，将cpu时间用在删除和当前任务无关的过期键上，影响服务器的响应时间和吞吐量
55.定期删除由于定时删除会占用太多cpu时间，影响服务器的响应时间和吞吐量以及惰性删除浪费太多内存，有内存泄露的危险，所以出现一种整合和折中这两种策略的定期删除策略。定期删除策略每隔一段时间执行一次删除过期键操作，并通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响。定时删除策略有效地减少了因为过期键带来的内存浪费。
56.惰性删除
    **优点：**对cpu时间友好，在每次从键空间获取键时进行过期键检查并是否删除，删除目标也仅限当前处理的键，这个策略不会在其他无关的删除任务上花费任何cpu时间。
    **缺点：**对内存不友好，过期键过期也可能不会被删除，导致所占的内存也不会释放。甚至可能会出现内存泄露的现象，当存在很多过期键，而这些过期键又没有被访问到，这会可能导致它们会一直保存在内存中，造成内存泄露。
57.Reids 管理工具：
    Redis Manager 2.0github地址

58.Redis常见的几种缓存策略Cache-AsideRead-ThroughWrite-ThroughWrite-Behind
59.Redis Module 实现布隆过滤器Redis module 是Redis 4.0 以后支持的新的特性，这里很多国外牛逼的大学和机构提供了很多牛逼的Module 只要编译引入到Redis 中就能轻松的实现我们某些需求的功能。在Redis 官方Module 中有一些我们常见的一些模块，我们在这里就做一个简单的使用。neural-redis 主要是神经网络的机器学，集成到redis 可以做一些机器训练感兴趣的可以尝试RedisSearch 主要支持一些富文本的的搜索RedisBloom 支持分布式环境下的Bloom 过滤器
60.Redis 到底是怎么实现“附近的人”使用方式GEOADD key longitude latitude member [longitude latitude member ...]
将给定的位置对象（纬度、经度、名字）添加到指定的key。其中，key为集合名称，member为该经纬度所对应的对象。在实际运用中，当所需存储的对象数量过多时，可通过设置多key(如一个省一个key)的方式对对象集合变相做sharding，避免单集合数量过多。成功插入后的返回值：(integer) N其中N为成功插入的个数。







、hash表的实现，包括STL中的哈希桶长度常数。hash表的实现主要涉及两个问题：散列函数和碰撞处理。
    1）hash function （散列函数）。最常见的散列函数：f(x) = x % TableSize 
    .2）碰撞问题（不同元素的散列值相同）。解决碰撞问题的方法有许多种，包括线性探测、二次探测、开链等做法。
        SGL版本使用开链法，使用一个链表保持相同散列值的元素。虽然开链法并不要求表格大小必须为质数，但SGI STL仍然以质数来设计表格大小，并且将28个质数（逐渐呈现大约两倍的关系）计算好，以备随时访问，同时提供一个函数，用来查询在这28个质数之中，“最接近某数并大于某数”的质数。

9、hash表如何rehash，怎么处理其中保存的资源
    先想想为什么需要rehash:因为，当loadFactor（负载因子）<=1时，hash表查找的期望复杂度为O(1). 因此，每次往hash表中添加元素时，我们必须保证是在loadFactor <1的情况下，才能够添加。模仿C++的vector扩容方式，Hash表中每次发现loadFactor==1时，就开辟一个原来桶数组的两倍空间（称为新桶数组），然后把原来的桶数组中元素全部转移过来到新的桶数组中。注意这里转移是需要元素一个个重新哈希到新桶中的。
10、Redis的rehash怎么做的，为什么要渐进rehash，渐进rehash怎么实现的为了避免rehash对服务器造成影响，服务器不是一次将ht[0]里面的所有键值对全部rehash到ht[1]，而是分多次、渐进式地将ht[0]里面的键值对慢慢地rehash到ht[1].

Redis服务器是一个事件驱动程序，服务器需要处理以下两类事件：文件事件（服务器对套接字操作的抽象）和时间事件（服务器对定时操作的抽象）。Redis的定时机制就是借助时间事件实现的。一个时间事件主要由以下三个属性组成：id：时间事件标识号；when：记录时间事件的到达时间；timeProc：时间事件处理器，当时间事件到达时，服务器就会调用相应的处理器来处理时间。一个时间事件根据时间事件处理器的返回值来判断是定时事件还是周期性事件。


Reactor模型：
    1）Handle：即操作系统中的句柄，是对资源在操作系统层面上的一种抽象，它可以是打开的文件、一个连接(Socket)、Timer等。
        由于Reactor模式一般使用在网络编程中，因而这里一般指Socket Handle，即一个网络连接。
    2）Synchronous Event Demultiplexer（同步事件复用器）：阻塞等待一系列的Handle中的事件到来，如果阻塞等待返回，即表示在返回的Handle中可以不阻塞的执行返回的事件类型。这个模块一般使用操作系统的select来实现。
    3）Initiation Dispatcher：用于管理Event Handler，即EventHandler的容器，用以注册、移除EventHandler等；另外，它还作为Reactor模式的入口调用Synchronous Event Demultiplexer的select方法以阻塞等待事件返回，当阻塞等待返回时，根据事件发生的Handle将其分发给对应的Event Handler处理，即回调EventHandler中的handle_event()方法。
    4）Event Handler：定义事件处理方法：handle_event()，以供InitiationDispatcher回调使用。
    5）Concrete Event Handler：事件EventHandler接口，实现特定事件处理逻辑。

单核机器上写多线程程序，是否需要考虑加锁，为什么？
线程需要保存哪些上下文，SP、PC、EAX这些寄存器是干嘛用的

质数比合数更容易避免冲撞，也就是说使用质数时，哈希效果更好，原始数据经哈希后分布更均匀。
redis的主从复制怎么做的

Redis旧版复制功能只有同步和命令传播。新版复制功能加入了部分同步的功能。
）命令传播：当主服务器会将自己执行的写命令，也即是造成主从服务器不一致的那条写命令，发送给从服务器执行，当从服务器执行了相同的写命令之后，主从服务器将再次回到一致状态。3）部分同步：（断线后重复制）复制偏移量：通过对比主从服务器的复制偏移量，程序可以很容易地知道主从服务器是否处于一致状态。复制积压缓冲区：主服务保存最近的写命令到复制积压缓冲区，是一个先进先出队列服务器运行ID：从服务器记录上次同步的主服务器的Id。


### 扩展问题
如何把一个文件快速下发到100w个服务器

gossip算法？Gossip有众多的别名“闲话算法”、“疫情传播算法”、“病毒感染算法”、“谣言传播算法”。
如何判断一个图是否连同？

DFS、BFS、并查集

3. 如何实现一个引用计数指针，以及其中要注意的点？
```
这也是一个比较有内容的问题。大致说了一下方案，面试官又追问了诸如入侵性与非入侵性设计的区别、优劣，以及析构对象时多动态库架构情况下本地堆问题，
还有引用计数的多线程安全问题，有锁怎么实现，无锁怎么实现。

```
5. 为什么stl中的内存分配器要设计为一个模板参数而不是一个构造函数参数？这个就属于瞎聊了，各抒己见呗。最后扯到类型系统如何帮助程序员排错之类的问题。


