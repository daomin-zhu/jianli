悲观锁乐观锁
```
悲观锁
    总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁
    （共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）。传统的关系型数据库里边就用到了很多这种锁机制，
    比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。Java中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。
乐观锁
    总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，
    可以使用版本号机制和CAS算法实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。
    在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。

两种锁的使用场景
    从上面对两种锁的介绍，我们知道两种锁各有优缺点，不可认为一种好于另一种，像乐观锁适用于写比较少的情况下（多读场景），
    即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。
    但如果是多写的情况，一般会经常产生冲突，
    这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适。
```
CAS
```
 CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。
 当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。
    CAS采用的是一种非阻塞算法（nonblocking algorithms），
    一个线程的失败或者挂起不应该影响其他线程的失败或挂起的算法。
```

进程与线程的区别
```
进程：
    在操作系统中能够独立运行，并且作为资源分配的基本单位。它表示运行中的程序。系统运行一个程序就是一个进程从创建、运行到消亡的过程。
线程：
    是一个比进程更小的执行单位，能够完成进程中的一个功能，也被称为轻量级进程。一个进程在其执行的过程中可以产生多个线程。同类的多个线程共享进程的堆和方法区资源，
    但每个线程有自己的程序计数器、虚拟机栈和本地方法栈，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多

线程共享的环境包括：进程代码段、进程的公有数据(利用这些共享的数据，线程很容易的实现相互之间的通讯)、进程打开的文件描述符、信号的处理器、进程的当前目录和进程用户ID与进程组ID。
```
2、什么是上下文切换?
```
　　即使单核处理器也支持多线程执行代码，CPU通过给每个线程分配CPU时间片来实现这个机制。
    时间片是CPU分配给各个线程的时间，因为时间片非常短，所以CPU通过不停地切换线程执行，让我们感觉多个线程是同时执行的。（时间片一般是几十毫秒）
　　CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。
    但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再加载这个任务的状态。
    所以任务从保存到加载的过程就是一次上下文切换。上下文切换会影响多线程的执行速度。
```
 3、并发与并行？
 ```
    并发指的是多个任务交替进行，并行则是指真正意义上的“同时进行”。
　　实际上，如果系统内只有一个CPU，使用多线程时，在真实系统环境下不能并行，只能通过切换时间片的方式交替进行，从而并发执行任务。
    真正的并行只能出现在拥有多个CPU的系统中。
```
5、什么是线程死锁?如何避免死锁?
```
 　 多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。
    假如线程 A 持有资源 2，线程 B 持有资源 1，他们同时都想申请对方的资源，所以这两个线程就会互相等待而进入死锁状态。
避免死锁的几个常见方法：
    避免一个线程同时获取多个锁
    避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。
    尝试使用定时锁，使用 lock.tryLock(timeout) 来代替使用内部锁机制。
    对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。
```
线程安全问题
```
    当多个线程访问某个方法时，不管你通过怎样的调用方式或者说这些线程如何交替的执行，我们在主程序中不需要去做任何的同步，
    这个类的结果行为都是我们设想的正确行为，那么我们就可以说这个类时线程安全的。
    线程安全问题指的是在某一线程从开始访问到结束访问某一数据期间，该数据被其他的线程所修改，那么对于当前线程而言，该线程就发生了线程安全问题，
    表现形式为数据的缺失，数据不一致等。
　　线程安全问题发生的条件：
　　　　1）多线程环境下，即存在包括自己在内存在有多个线程。
　　　　2）多线程环境下存在共享资源，且多线程操作该共享资源。
　　　　3）多个线程必须对该共享资源有非原子性操作。
线程安全问题的解决思路：
　　　　1）尽量不使用共享变量，将不必要的共享变量变成局部变量来使用。
　　　　2）使用synchronized关键字同步代码块，或者使用jdk包中提供的Lock为操作进行加锁。
　　　　3）使用ThreadLocal为每一个线程建立一个变量的副本，各个线程间独立操作，互不影响。
```
性能问题
```
　　线程的生命周期开销是非常大的，一个线程的创建到销毁都会占用大量的内存。同时如果不合理的创建了多个线程，
    cup的处理器数量小于了线程数量，那么将会有很多的线程被闲置，闲置的线程将会占用大量的内存，
    为垃圾回收带来很大压力，同时cup在分配线程时还会消耗其性能。
　　解决思路：
　　利用线程池，模拟一个池，预先创建有限合理个数的线程放入池中，当需要执行任务时从池中取出空闲的先去执行任务，
    执行完成后将线程归还到池中，这样就减少了线程的频繁创建和销毁，节省内存开销和减小了垃圾回收的压力。
    同时因为任务到来时本身线程已经存在，减少了创建线程时间，
    提高了执行效率，而且合理的创建线程池数量还会使各个线程都处于忙碌状态，提高任务执行效率，线程池还提供了拒绝策略，
    当任务数量到达某一临界区时，线程池将拒绝任务的进入，保持现有任务的顺利执行，减少池的压力。
```
活跃性问题
```
    死锁: 
        假如线程 A 持有资源 2，线程 B 持有资源 
        1，他们同时都想申请对方的资源，所以这两个线程就会互相等待而进入死锁状态。
            多个线程环形占用资源也是一样的会产生死锁问题。
　　解决方法：
        避免一个线程同时获取多个锁
    避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。
    尝试使用定时锁，使用 lock.tryLock(timeout) 来代替使用内部锁机制。
　　想要避免死锁，可以使用无锁函数（cas）或者使用重入锁（ReentrantLock），通过重入锁使线程中断或限时等待可以有效的规避死锁问题。

　　饥饿:
        饥饿指的是某一线程或多个线程因为某些原因一直获取不到资源，导致程序一直无法执行。
        如某一线程优先级太低导致一直分配不到资源，或者是某一线程一直占着某种资源不放，导致该线程无法执行等。
　　解决方法：
　　    与死锁相比，饥饿现象还是有可能在一段时间之后恢复执行的。
        可以设置合适的线程优先级来尽量避免饥饿的产生。
　　活锁: 
        活锁体现了一种谦让的美德，每个线程都想把资源让给对方，但是由于机器“智商”不够，可能会产生一直将资源让来让去，
        导致资源在两个线程间跳动而无法使某一线程真正的到资源并执行，这就是活锁的问题。
```
阻塞
```
　　阻塞是用来形容多线程的问题，几个线程之间共享临界区资源，那么当一个线程占用了临界区资源后，所有需要使用该资源的线程都需要进入该临界区等待，
    等待会导致线程挂起，一直不能工作，这种情况就是阻塞，如果某一线程一直都不释放资源，将会导致其他所有等待在这个临界区的线程都不能工作。
    当我们使用synchronized或重入锁时，我们得到的就是阻塞线程，如论是synchronized或者重入锁，都会在试图执行代码前，得到临界区的锁，
    如果得不到锁，线程将会被挂起等待，知道其他线程执行完成并释放锁且拿到锁为止。
　解决方法：
　　可以通过减少锁持有时间，读写锁分离，减小锁的粒度，锁分离，锁粗化等方式来优化锁的性能。
```
线程间的同步方式，最好说出具体的系统调用
```
临界区（Critical Section）、互斥对象（Mutex）：
    主要用于互斥控制；都具有拥有权的控制方法，只有拥有该对象的线程才能执行任务，所以拥有，执行完任务后一定要释放该对象。
信号量（Semaphore）、事件对象（Event）：
    事件对象是以通知的方式进行控制，主要用于同步控制！

1、临界区：通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。
    在任意时刻只允许一个线程对共享资源进行访问，如果有多个线程试图访问公共资源，
    那么在有一个线程进入后，其他试图访问公共资源的线程将被挂起，并一直等到进入临界区的线程离开，临界区在被释放后，其他线程才可以抢占。
    它并不是核心对象，不是属于操作系统维护的，而是属于进程维护的。
总结下关键段：
    1）关键段共初始化化、销毁、进入和离开关键区域四个函数。
    2）关键段可以解决线程的互斥问题，但因为具有“线程所有权”，所以无法解决同步问题。
    3）推荐关键段与旋转锁配合使用。

2、互斥对象：
    互斥对象和临界区很像，采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。
    因为互斥对象只有一个，所以能保证公共资源不会同时被多个线程同时访问。
    当前拥有互斥对象的线程处理完任务后必须将线程交出，以便其他线程访问该资源。
总结下互斥量Mutex：
    1）互斥量是内核对象，它与关键段都有“线程所有权”所以不能用于线程的同步。
    2）互斥量能够用于多个进程之间线程互斥问题，并且能完美的解决某进程意外终止所造成的“遗弃”问题。
3、信号量：
    信号量也是内核对象。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目
    在用CreateSemaphore()创建信号量时即要同时指出允许的最大资源计数和当前可用资源计数。
    一般是将当前可用资源计数设置为最 大资源计数，每增加一个线程对共享资源的访问，当前可用资源计数就会减1 ，
    只要当前可用资源计数是大于0 的，就可以发出信号量信号。但是当前可用计数减小 到0 时则说明当前占用资源的线程数已经达到了所允许的最大数目，
    不能在允许其他线程的进入，此时的信号量信号将无法发出。线程在处理完共享资源后，应在离 开的同时通过ReleaseSemaphore （）函数将当前可用资源计数加1 。
    在任何时候当前可用资源计数决不可能大于最大资源计数。
4、事件对象： 
    通过通知操作的方式来保持线程的同步，还可以方便实现对多个线程的优先级比较的操作
总结下事件Event
    1）事件是内核对象，事件分为手动置位事件和自动置位事件。事件Event内部它包含一个使用计数（所有内核对象都有），
        一个布尔值表示是手动置位事件还是自动置位事件，另一个布尔值用来表示事件有无触发。
    2）事件可以由SetEvent()来触发，由ResetEvent()来设成未触发。还可以由PulseEvent()来发出一个事件脉冲。
    3）事件可以解决线程间同步问题，因此也能解决互斥问题。
```
多线程的锁
```
pthread_mutex_t是互斥锁:
    同一瞬间只能有一个线程能够获取锁，其他线程在等待获取锁的时候会进入休眠状态。
    因此pthread_mutex_t消耗的CPU资源很小，但是性能不高，因为会引起线程切换。
pthread_spinlock_t是自旋锁:
    同一瞬间也只能有一个线程能够获取锁，不同的是，其他线程在等待获取锁的过程中并不进入睡眠状态，而是在 CPU上进入“自旋”等待。
    自旋锁的性能很高，但是只适合对很小的代码段加锁（或短期持有的锁），自旋锁对CPU的占用相对较高。
pthread_rwlock_t是读写锁:
    同时可以有多个线程获得读锁，同时只允许有一个线程获得写锁。其他线程在等待锁的时候同样会进入睡眠。
    读写锁在互斥锁的基础上，允许多个线程“读”，在某些场景下能提高性能。
```

Singleton的线程安全是个很有意思而且容易出错的话题
```
懒汉式(线程不安全)
    SingleInstance *SingleInstance::m_SingleInstance = NULL;
    SingleInstance* SingleInstance::GetInstance()
    {
	    if (m_SingleInstance == NULL)
	    {
		    m_SingleInstance = new (std::nothrow) SingleInstance;  
            // 没有加锁是线程不安全的，当线程并发时会创建多个实例
	    }
        return m_SingleInstance;
    }

懒汉式(线程安全)
//初始化静态成员变量
SingleInstance *SingleInstance::m_SingleInstance = NULL;
std::mutex SingleInstance::m_Mutex;
SingleInstance *&SingleInstance::GetInstance()
{
    //  这里使用了两个 if判断语句的技术称为双检锁；好处是，只有判断指针为空的时候才加锁，
    //  避免每次调用 GetInstance的方法都加锁，锁的开销毕竟还是有点大的。
    if (m_SingleInstance == NULL) 
    {
        std::unique_lock<std::mutex> lock(m_Mutex); // 加锁
        if (m_SingleInstance == NULL)
        {
            m_SingleInstance = new (std::nothrow) SingleInstance;
        }
    }
    return m_SingleInstance;
}

饿汉式(线程安全)
// 唯一单实例对象指针
static Singleton *g_pSingleton;
// 代码一运行就初始化创建实例 ，本身就线程安全
Singleton* Singleton::g_pSingleton = new (std::nothrow) Singleton;
Singleton* Singleton::GetInstance()
{
    return g_pSingleton;
}
```

```
进程间通信的方式：

进程间通信主要包括管道、系统IPC（包括消息队列、信号量、信号、共享内存等）、以及套接字socket。

1.管道：

管道主要包括无名管道和命名管道:管道可用于具有亲缘关系的父子进程间的通信，有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信

1.1 普通管道PIPE：

1)它是半双工的（即数据只能在一个方向上流动），具有固定的读端和写端

2)它只能用于具有亲缘关系的进程之间的通信（也是父子进程或者兄弟进程之间）

3)它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。

1.2 命名管道FIFO：

1)FIFO可以在无关的进程之间交换数据

2)FIFO有路径名与之相关联，它以一种特殊设备文件形式存在于文件系统中。


2. 系统IPC：

2.1 消息队列

消息队列，是消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列ID）来标记。 (消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等特点)具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息；

特点：

1)消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级。

2)消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。

3)消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取。


2.2 信号量semaphore

信号量（semaphore）与已经介绍过的 IPC 结构不同，它是一个计数器，可以用来控制多个进程对共享资源的访问。信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。

特点：

1)信号量用于进程间同步，若要在进程间传递数据需要结合共享内存。

2)信号量基于操作系统的 PV 操作，程序对信号量的操作都是原子操作。

3)每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数。

4)支持信号量组。


2.3 信号signal

信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。


2.4 共享内存（Shared Memory）

它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等

特点：

1)共享内存是最快的一种IPC，因为进程是直接对内存进行存取

2)因为多个进程可以同时操作，所以需要进行同步

3)信号量+共享内存通常结合在一起使用，信号量用来同步对共享内存的访问


3.套接字SOCKET：

socket也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同主机之间的进程通信。


线程间通信的方式:

临界区：通过多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问；

互斥量Synchronized/Lock：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问

信号量Semphare：为控制具有有限数量的用户资源而设计的，它允许多个线程在同一时刻去访问同一个资源，但一般需要限制同一时刻访问此资源的最大线程数目。

事件(信号)，Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作
```
```
信号量
信号量是一种特殊的变量，可用于线程同步。它只取自然数值，并且只支持两种操作：

P(SV):如果信号量SV大于0，将它减一；如果SV值为0，则挂起该线程。

V(SV)：如果有其他进程因为等待SV而挂起，则唤醒，然后将SV+1；否则直接将SV+1。

其系统调用为：

sem_wait（sem_t *sem）：以原子操作的方式将信号量减1，如果信号量值为0，则sem_wait将被阻塞，直到这个信号量具有非0值。

sem_post（sem_t *sem)：以原子操作将信号量值+1。当信号量大于0时，其他正在调用sem_wait等待信号量的线程将被唤醒。


互斥量

互斥量又称互斥锁，主要用于线程互斥，不能保证按序访问，可以和条件锁一起实现同步。当进入临界区      时，需要获得互斥锁并且加锁；当离开临界区时，需要对互斥锁解锁，以唤醒其他等待该互斥锁的线程。其主要的系统调用如下：

pthread_mutex_init:初始化互斥锁

pthread_mutex_destroy：销毁互斥锁

pthread_mutex_lock：以原子操作的方式给一个互斥锁加锁，如果目标互斥锁已经被上锁，pthread_mutex_lock调用将阻塞，直到该互斥锁的占有者将其解锁。

pthread_mutex_unlock:以一个原子操作的方式给一个互斥锁解锁。


条件变量

条件变量，又称条件锁，用于在线程之间同步共享数据的值。条件变量提供一种线程间通信机制：当某个共享数据达到某个值时，唤醒等待这个共享数据的一个/多个线程。即，当某个共享变量等于某个值时，调用 signal/broadcast。此时操作共享变量时需要加锁。其主要的系统调用如下：

pthread_cond_init:初始化条件变量

pthread_cond_destroy：销毁条件变量

pthread_cond_signal：唤醒一个等待目标条件变量的线程。哪个线程被唤醒取决于调度策略和优先级。

pthread_cond_wait：等待目标条件变量。需要一个加锁的互斥锁确保操作的原子性。该函数中在进入wait状态前首先进行解锁，然后接收到信号后会再加锁，保证该线程对共享资源正确访问。


```

线程池设计
1. 了解进程线程的基本概念，能用一种语言在一个平台上实现一个多线程的例子。
2. 了解为什么要用Mutex之类的工具做锁来同步和保护资源。弄懂诸如racing condition，死锁之类的概念。50%公司的见面题，用来砍死大无畏。
3. 了解编译器优化带来的影响，了解cache的影响，了解volatile，之类的概念。
```
memory barrier:
    内存屏障，大概意思就是，虽然你的代码是这么一行一行写下去，但是不管是编译器，还是CPU，都会按照自己的意思，看着高兴用不同的顺序来执行你的代码。
    所以有可能写在前面的代码被放在后面执行。因此你需要通过一系列的barrier和其他标记，来告诉它们，哪些移动是不行的，什么时候要刷cache，什么时候要同步。
```
4. 了解一下你主攻平台＋语言所提供的工具库，知道常用的工具的用法和使用场景：Mutex，Semaphore，原子操作集，Condition Variable，spin lock。这几个算是比较常用的，在各个平台＋语言也都有对应实现。老实说，spinlock，condition variable是我工作里从没用过的
5. 了解常用的多线程设计范式，比如读写锁（Reader/Writer Lock，非常经典的范式，有偏向读和写的不同变形，至少被要求写过3次），生产消费范式（写过2次），一些常用容器的实现，比如BlockingQueue（写过3次）或者concurrentHashmap（写过2次）。

BlockingQueue
```
LinkedBlockingQueue中维持两把锁，一把锁用于入队，一把锁用于出队，这也就意味着，同一时刻，
只能有一个线程执行入队，其余执行入队的线程将会被阻塞；同时，可以有另一个线程执行出队，
其余执行出队的线程将会被阻塞。换句话说，虽然入队和出队两个操作同时均只能有一个线程操作，
但是可以一个入队线程和一个出队线程共同执行，也就意味着可能同时有两个线程在操作队列，那么为了维持线程安全，
LinkedBlockingQueue使用一个AtomicInterger类型的变量表示当前队列中含有的元素个数，
所以可以确保两个线程之间操作底层队列是线程安全的。
```