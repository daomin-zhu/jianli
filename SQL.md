 MySQL索引方法？索引的优化？
```
B+Tree的特点:
数据都存储在叶子节点，并且每个叶子节点的数据都是按相同顺序（升序或降序）排列存储的，再者相邻的叶子节点都用指针连接在一点，这种结构非常适合于范围查找。
B-Tree索引能够显著加快访问数据的速度，因为存储引擎不再需要进行全表扫描来获取需要的数据，而是从索引的根节点逐层往下进行搜索，
    这大大缩小了存储引擎扫描数据的范围，因此对查询速度的提升非常明显。

主键索引 PRIMARY KEY：它是一种特殊的唯一索引，不允许有空值。一般是在建表的时候同时创建主键索引
唯一索引 UNIQUE：唯一索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一
普通索引 INDEX：这是最基本的索引，它没有任何限制
组合索引 INDEX：即一个索引包含多个列，多用于避免回表查询
全文索引 FULLTEXT：也称全文检索，是目前搜索引擎使用的一种关键技术
```
索引设计的原则
```
适合索引的列是出现在where子句中的列，或者连接子句中指定的列
基数较小的类，索引效果较差，没有必要在此列建立索引
使用短索引，如果对长字符串列进行索引，应该指定一个前缀长度，这样能够节省大量索引空间；
不要过度索引。索引需要额外的磁盘空间，并降低写操作的性能。在修改表内容的时候，索引会进行更新甚至重构，
            索引列越多，这个时间就会越长。所以只保持需要的索引有利于查询即可
```
回表：
```
当对一个列创建索引之后，索引会包含该列的键值及键值对应行所在的rowid。通过索引中记录的rowid访问表中的数据就叫回表。
回表次数太多会严重影响SQL性能，如果回表次数太多，就不应该走索引扫描，应该直接走全表扫描。
EXPLAIN命令结果中的Using Index意味着不会回表，通过索引就可以获得主要的数据。Using Where则意味着需要回表取数据。
```
索引优化规则：
```
如果MySQL估计使用索引比全表扫描还慢，则不会使用索引返回数据的比例是重要的指标，比例越低越容易命中索引。记住这个范围值——30%
前导模糊查询不能命中索引  
    EXPLAIN SELECT * FROM user WHERE name LIKE '%s%';
非前导模糊查询则可以使用索引，可优化为使用非前导模糊查询：
    EXPLAIN SELECT * FROM user WHERE name LIKE 's%';
数据类型出现隐式转换的时候不会命中索引，特别是当列类型是字符串，一定要将字符常量值用引号引起来
复合索引的情况下，查询条件不包含索引列最左边部分（不满足最左原则），不会命中符合索引
    注意，最左原则并不是说是查询条件的顺序 而是查询条件中是否包含索引最左列字段
union、in、or都能够命中索引，建议使用in
用or分割开的条件，如果or前的条件中列有索引，而后面的列中没有索引，那么涉及到的索引都不会被用到
    因为or后面的条件列中没有索引，那么后面的查询肯定要走全表扫描，在存在全表扫描的情况下，就没有必要多一次索引扫描增加IO访问
负向条件查询不能使用索引，可以优化为in查询。
    负向条件有：!=、<>、not in、not exists、not like等。
范围条件查询可以命中索引。范围条件有：<、<=、>、>=、between等。
数据库执行计算不会命中索引
利用覆盖索引进行查询，避免回表
建立索引的列，不允许为null。
更新十分频繁的字段上不宜建立索引：因为更新操作会变更B+树，重建索引。这个过程是十分消耗数据库性能的。
区分度不大的字段上不宜建立索引：类似于性别这种区分度不大的字段，建立索引的意义不大。因为不能有效过滤数据，性能和全表扫描相当。
另外返回数据的比例在30%以外的情况下，优化器不会选择使用索引。
业务上具有唯一特性的字段，即使是多个字段的组合，也必须建成唯一索引。虽然唯一索引会影响insert速度，但是对于查询的速度提升是非常明显的。
另外，即使在应用层做了非常完善的校验控制，只要没有唯一索引，在并发的情况下，依然有脏数据产生。
多表关联时，要保证关联字段上一定有索引。
创建索引时避免以下错误观念：
    索引越多越好，认为一个查询就需要建一个索引；
    宁缺勿滥，认为索引会消耗空间、严重拖慢更新和新增速度；
    抵制唯一索引，认为业务的唯一性一律需要在应用层通过“先查后插”方式解决；
    过早优化，在不了解系统的情况下就开始优化。
```
InnoDB与MyISAM区别？
```
1、InnoDB支持事务，MyISAM不支持，对于InnoDB每一条SQL语言都默认封装成事务，
    自动提交，这样会影响速度，所以最好把多条SQL语言放在begin和commit之间，
    组成一个事务； 
2、InnoDB支持外键，而MyISAM不支持。对一个包含外键的InnoDB表转为MYISAM会失败； 
3、InnoDB是聚集索引，使用B+Tree作为索引结构，数据文件是和（主键）索引绑在一起的
    （表数据文件本身就是按B+Tree组织的一个索引结构），必须要有主键，
    通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，
    然后再通过主键查询到数据。因此，主键不应该过大，
    因为主键太大，其他索引也都会很大。
MyISAM是非聚集索引，也是使用B+Tree作为索引结构，索引和数据文件是分离的，
    索引保存的是数据文件的指针。主键索引和辅助索引是独立的。
    也就是说：InnoDB的B+树主键索引的叶子节点就是数据文件，
    辅助索引的叶子节点是主键的值；
    而MyISAM的B+树主键索引和辅助索引的叶子节点都是数据文件的地址指针。
3、InnoDB不保存表的具体行数，执行select count(*) from table时需要全表扫描。
    而MyISAM用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，
    速度很快（注意不能加有任何WHERE条件）；
4、Innodb不支持全文索引，而MyISAM支持全文索引，
    在涉及全文索引领域的查询效率上MyISAM速度更快高；
    PS：5.7以后的InnoDB支持全文索引了
5、MyISAM表格可以被压缩后进行查询操作
6、InnoDB支持表、行(默认)级锁，而MyISAM支持表级锁
    InnoDB的行锁是实现在索引上的，而不是锁在物理行记录上。
    潜台词是，如果访问没有命中索引，也无法使用行锁，将要退化为表锁。
7、InnoDB表必须有主键（用户没有指定的话会自己找或生产一个主键），
    而Myisam可以没有
7、Innodb存储文件有frm、ibd，而Myisam是frm、MYD、MYI
        Innodb：frm是表定义文件，ibd是数据文件
        Myisam：frm是表定义文件，myd是数据文件，myi是索引文件
```
事务的ACID
```
原子性（A）：是指事务要么都成功，要么都失败。成功就影响数据库，失败就对数据库不影响，保持原样。
一致性（C）：是指应用层系统从一种正确的状态，在事务成功后，达成另一种正确的状态。比如：A、B账面共计100W，A向B转账，加上事务控制，转成功后，他们账户总额应还是100W，事务应保持这种应用逻辑正确一致。还有，转账（事务成功）前后，数据库内部的数据结构--比如账户表的主键、外键、列必须大于0、Btree、双向链表等约束需要是正确的，和原来一致的。
隔离性（I）：隔离是指当多个事务提交时，让它们按顺序串行提交，每个时刻只有一个事务提交。但隔离处理并发事务，效率很差。所以SQL标准制作者妥协了，提出了4种事务隔离等级（1，read-uncommited 未提交就读，可能产生脏读  2，read-commited 提交后读  可能产生不可重复读  3，repeatable-read 可重复读  可能产生幻读    4，serializable 序列化，最高级别，按顺序串行提交） 事务的隔离性实现详见https://zhuanlan.zhihu.com/p/27035174
持久性（D）：是指事务一旦提交后，对数据库中的数据改变是永久性的。
```
```
一）脏读：就是A事务在读取数据时，B事务对同一个数据修改了，但B未提交，A再读取时，读到了B修改后的数据，但是B事务提交失败，回滚，A后读到的数据就是B修改后的脏数据，此为脏读。
二）不可重复读：就是A事务读取数据，B事务改了这个数据，也提交成功了，A再读取就是B修改后的数据，再也不能重复读到最开始的那个数据值了，此为不可重复读
三）幻读：可重复读就是A事务读取数据，B事务改了这个数据（update），也提交成功了，A再读这个数据，SQL机制强行让A仍然读之前读到的数据值，这就是可重复读，这种机制对Insert操作无效，A事务在可重复读的机制下，读取数据，B事务insert一条数据，提交成功，A再读这个数据，会显示B插入的数据，此为幻读。
```
事务的四个隔离级别
```
Read uncommitted(未授权读取、读未提交)： 
    如果一个事务已经开始写数据，则另外一个事务则不允许同时进行写操作，但允许其他事务读此行数据。该隔离级别可以通过“排他写锁”实现。这样就避免了更新丢失，却可能出现脏读。也就是说事务B读取到了事务A未提交的数据。
Read committed（授权读取、读提交）： 
    读取数据的事务允许其他事务继续访问该行数据，但是未提交的写事务将会禁止其他事务访问该行。该隔离级别避免了脏读，但是却可能出现不可重复读。事务A事先读取了数据，事务B紧接了更新了数据，并提交了事务，而事务A再次读取该数据时，数据已经发生了改变。
Repeatable read（可重复读取）： 
    可重复读是指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据之间，即使第二个事务对数据进行修改，第一个事务两次读到的的数据是一样的。这样就发生了在一个事务内两次读到的数据是一样的，因此称为是可重复读。读取数据的事务将会禁止写事务（但允许读事务），写事务则禁止任何其他事务。这样避免了不可重复读取和脏读，但是有时可能出现幻象读。（读取数据的事务）这可以通过“共享读锁”和“排他写锁”实现。
Serializable（序列化）： 
    提供严格的事务隔离。它要求事务序列化执行，事务只能一个接着一个地执行，但不能并发执行。如果仅仅通过“行级锁”是无法实现事务序列化的，必须通过其他机制保证新插入的数据不会被刚执行查询操作的事务访问到。序列化是最高的事务隔离级别，同时代价也花费最高，性能很低，一般很少使用，在该级别下，事务顺序执行，不仅可以避免脏读、不可重复读，还避免了幻像读。 
```
```
悲观锁
    悲观锁，它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度。
    因此，在整个数据处理过程中，将数据处于锁定状态。
    悲观锁的实现，往往依靠数据库提供的锁机制。
    也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统的数据访问层中实现了加锁机制，也无法保证外部系统不会修改数据。
乐观锁（ Optimistic Locking ） 
    相对悲观锁而言，乐观锁假设认为数据一般情况下不会造成冲突，所以只会在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，
    如果发现冲突了，则返回用户错误的信息，让用户决定如何去做。实现乐观锁一般来说有以下2种方式：
使用版本号 
    使用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式。何谓数据版本？即为数据增加一个版本标识，一般是通过为数据库表增加一个数字类型的 “version” 字段来实现。当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值加一。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的version值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据。
使用时间戳 
    乐观锁定的第二种实现方式和第一种差不多，同样是在需要乐观锁控制的table中增加一个字段，名称无所谓，字段类型使用时间戳（timestamp）, 和上面的version类似，也是在更新提交的时候检查当前数据库中数据的时间戳和自己更新前取到的时间戳进行对比，如果一致则OK，否则就是版本冲突。
```


查询优化(从索引上优化，从SQL语言上优化)
```

```
B-与B+树区别？
```
B树和B+树区别：
关键字数量不同：B+树分支结点M个关键字，叶子节点也有M个；B树分支结点则存在 k-1 个关键码
数据存储位置不同：B+树数据存储在叶子结点上；B树存储在每个结点上；
查询不同：B+树是从根节点到叶子节点的路径；B树是只需要找到数据就可以
分支节点存储信息不同：B+树存索引信息；B树存的是数据关键字

小结：
B树：二叉树，每个结点只存储一个关键字，等于则命中，小于走左结点，大于走右结点；
B-树：多路搜索树，每个结点存储M/2到M个关键字，非叶子结点存储指向关键字范围的子结点；所有关键字在整颗树中出现，且只出现一次，非叶子结点可以命中；
B+树：在B-树基础上，为叶子结点增加链表指针，所有关键字都在叶子结点中出现，非叶子结点作为叶子结点的索引；B+树总是到叶子结点才命中；
B*树： 在B+树基础上，为非叶子结点也增加链表指针，将结点的最低利用率从1/2提高到2
```

MySQL的联合索引(又称多列索引)是什么？生效的条件？
```
对多个字段同时建立的索引(有顺序，ABC，ACB是完全不同的两种联合索引。)
为什么要用

以联合索引(a,b,c)为例

建立这样的索引相当于建立了索引a、ab、abc三个索引。一个索引顶三个索引当然是好事，毕竟每多一个索引，都会增加写操作的开销和磁盘空间的开销。
覆盖(动词)索引。同样的有联合索引（a,b,c），如果有如下的sql: select a,b,c from table where a=xxx and b = xxx。那么MySQL可以直接通过遍历索引取得数据，而无需读表，这减少了很多的随机io操作。减少io操作，特别的随机io其实是dba主要的优化策略。所以，在真正的实际应用中，覆盖索引是主要的提升性能的优化手段之一
索引列越多，通过索引筛选出的数据越少。有1000W条数据的表，有如下sql:select * from table where a = 1 and b =2 and c = 3,假设每个条件可以筛选出10%的数据，如果只有单值索引，那么通过该索引能筛选出1000W*10%=100w 条数据，然后再回表从100w条数据中找到符合b=2 and c= 3的数据，然后再排序，再分页；如果是复合索引，通过索引筛选出1000w *10% *10% *10%=1w，然后再排序、分页，哪个更高效，一眼便知

使用时注意什么

单个索引需要注意的事项，组合索引全部通用。比如索引列不要参与计算啊、or的两侧要么都索引列，要么都不是索引列啊、模糊匹配的时候%不要在头部啦等等

最左匹配原则。(A,B,C) 这样3列，mysql会首先匹配A，然后再B，C.
如果用(B,C)这样的数据来检索的话，就会找不到A使得索引失效。如果使用(A,C)这样的数据来检索的话，就会先找到所有A的值然后匹配C，此时联合索引是失效的。

把最常用的，筛选数据最多的字段放在左侧。
```
分库分表
```
为什么要分库分表（设计高并发系统的时候，数据库层面应该如何设计）？

首先要清楚，分库和分表是两回事，是两个独立的概念。分库和分表都是为了防止数据库服务因为同一时间的访问量（增删查改）过大导致宕机而设计的一种应对策略。

为什么要分库
一、单库单表存在的问题

假设你要设计一个电商网站，在一开始，User表、Order表、Product表等等各种表都在同一个数据库中，每个表都包含了大量的字段。在用户量比较少，访问量也比较少的时候，单库单表不存在问题。

但是公司可能发展的比较好，用户量开始大量增加，业务也越来越繁杂。一张表的字段可能有几十个甚至上百个，而且一张表存储的数据还很多，高达几千万数据，更难受的是这样的表还挺多。于是一个数据库的压力就太大了，一张表的压力也比较大。试想一下，我们在一张几千万数据的表中查询数据，压力本来就大，如果这张表还需要关联查询，那时间等等各个方面的压力就更大了。

（1）单库太大：数据库里面的表太多，所在服务器磁盘空间装不下，IO次数多CPU忙不过来。

（2）单表太大：一张表的字段太多，数据太多。查询起来困难。

此时就开始考虑如何解决问题了。

二、主从复制架构

单库单表下越来越不满足需求，此时我们先考虑进行读写分离。我们将数据库的写操作和读操作进行分离， 使用多个从库副本（Slaver）负责读，使用主库（Master）负责写， 从库从主库同步更新数据，保持数据一致。

这在一定程度上可以解决问题，但是用户超级多的时候，比如几个亿用户，此时写操作会越来越多，一个主库（Master）不能满足要求了，那就把主库拆分，这时候为了保证数据的一致性就要开始进行同步，此时会带来一系列问题：

（1）写操作拓展起来比较困难，因为要保证多个主库的数据一致性。

（2）复制延时：意思是同步带来的时间消耗。

（3）锁表率上升：读写分离，命中率少，锁表的概率提升。

（4）表变大，缓存率下降：此时缓存率一旦下降，带来的就是时间上的消耗。

注意，此时主从复制还是单库单表，只不过复制了很多份并进行同步。

主从复制架构随着用户量的增加、访问量的增加、数据量的增加依然会带来大量的问题，那就要考虑换一种解决思路。就是今天所讲的主题，分库分表。

三、分库分表

不管是分库还是分表，都有两种切分方式：水平切分和垂直切分。下面我们分别看看如何切分。

1、分表

（1）垂直分表

表中的字段较多，一般将不常用的、 数据较大、长度较长的拆分到“扩展表“。一般情况加表的字段可能有几百列，此时是按照字段进行数竖直切。注意垂直分是列多的情况。

（2）水平分表

单表的数据量太大。按照某种规则（RANGE,HASH取模等），切分到多张表里面去。 但是这些表还是在同一个库中，所以库级别的数据库操作还是有IO瓶颈。这种情况是不建议使用的，因为数据量是逐渐增加的，当数据量增加到一定的程度还需要再进行切分。比较麻烦。

2、分库

（1）垂直分库

一个数据库的表太多。此时就会按照一定业务逻辑进行垂直切，比如用户相关的表放在一个数据库里，订单相关的表放在一个数据库里。注意此时不同的数据库应该存放在不同的服务器上，此时磁盘空间、内存、TPS等等都会得到解决。

（2）水平分库

水平分库理论上切分起来是比较麻烦的，它是指将单张表的数据切分到多个服务器上去，每个服务器具有相应的库与表，只是表中数据集合不同。 水平分库分表能够有效的缓解单机和单库的性能瓶颈和压力，突破IO、连接数、硬件资源等的瓶颈。

四、分库分表之后的问题

1、联合查询困难
联合查询不仅困难，而且可以说是不可能，因为两个相关联的表可能会分布在不同的数据库，不同的服务器中。
2、需要支持事务
分库分表后，就需要支持分布式事务了。数据库本身为我们提供了事务管理功能，但是分库分表之后就不适用了。如果我们自己编程协调事务，代码方面就又开始了麻烦。
3、跨库join困难
分库分表后表之间的关联操作将受到限制，我们无法join位于不同分库的表，也无法join分表粒度不同的表， 结果原本一次查询能够完成的业务，可能需要多次查询才能完成。 我们可以使用全局表，所有库都拷贝一份。
4、结果合并麻烦
比如我们购买了商品，订单表可能进行了拆分等等，此时结果合并就比较困难。 
```

请你来手写一下快排的代码
```
快速排序，主要有两个操作，一个是切割操作，一个是递归操作。快速排序就是通过这两个操作的组合来完成的。那么这两个操作又都是怎么执行的呢？先说切割操作：计算当前队列的元素个数，小于等于 1 个时不进行切割操作以队列首位为基准，遍历整个队列大于基准的放到基准右边小于基准的放到基准左边以基准为切割线，把遍历后的队列切割成一大一小两个子队列（两个子队列均不包含基准）接着再说递归操作：对队列进行切割操作，得到A和B两个子队列（如果元素个数小于等于 1 个则不进行切割操作，退出递归）对A队列执行步骤一对B队列执行步骤一所以，总体来说，快速排序就是对队列不断递归执行切割操作，当递归完成，排序也就完成了。从另一个角度来说，也可以理解成利用递归的思想确定每个元素在队列中的位置，以此来完成排序。（因为每次
```
请你手写一下快排的代码
请问求第k大的数的方法以及各自的复杂度是怎样的，另外追问一下，当有相同元素时，还可以使用什么不同的方法求第k大的元素
请你来介绍一下各种排序算法及时间复杂度
请你说一说你知道的排序算法及其复杂度
请问海量数据如何去取最大的k个
请你说一说Top(K)问题
请问快排的时间复杂度最差是多少？什么时候时间最差
请问稳定排序哪几种？
请你介绍一下快排算法；以及什么是稳定性排序，快排是稳定性的吗；快排算法最差情况推导公式
```
定义假定在待排序的记录序列中，存在多个具有相同的关键字的记录，若经过排序，这些记录的相对次序保持不变，即在原序列中，A1=A2，且A1在A2之前，而在排序后的序列中，A1仍在A2之前，则称这种排序算法是稳定的；否则称为不稳定的。稳定也可以理解为一切皆在掌握中,元素的位置处在你在控制中.而不稳定算法有时就有点碰运气,随机的成分.当两元素相等时它们的位置在排序后可能仍然相同.但也可能不同.是未可知的.判断方法对于不稳定的排序算法，只要举出一个实例，即可说明它的不稳定性；而对于稳定的排序算法，必须对算法进行分析从而得到稳定的特性。需要注意的是，排序算法是否为稳定的是由具体算法决定的，不稳定的算法在某种条件下可以变为稳定的算法，而稳定的算法在某种条件下也可以变为不稳定的算法。算法思想的本身是独立于编程语言的,所以你写代码去实现算法的时候很多细节可以做不同的处理.采用不稳定算法不管你具体实现时怎么写代码,最终相同元素位置总是不确定的(可能位置没变也可能变了).而稳定排序算法是你在具体实现时如果细节方面处理的好就会是稳定的,但有些细节没处理得到的结果仍然是不稳定的.例如，对于如下冒泡排序算法，原本是稳定的排序算法，如果将记录交换的条件改成a[j].key>=a[j+1].key，则两个相等的记录就会交换位置。常见算法的稳定性（要记住）    不稳定排序算法堆排序、快速排序、希尔排序、直接选择排序    稳定排序算法基数排序、冒泡排序、直接插入排序、折半插入排序、归并排序稳定性的意义1、如果只是简单的进行数字的排序，那么稳定性将毫无意义。2、如果排序的内容仅仅是一个复杂对象的某一个数字属性，那么稳定性依旧将毫无意义（所谓的交换操作的开销已经算在算法的开销内了，如果嫌弃这种开销，不如换算法好了？）3、如果要排序的内容是一个复杂对象的多个数字属性，但是其原本的初始顺序毫无意义，那么稳定性依旧将毫无意义。4、除非要排序的内容是一个复杂对象的多个数字属性，且其原本的初始顺序存在意义，那么我们需要在二次排序的基础上保持原有排序的意义，才需要使用到稳定性的算法，例如要排序的内容是一组原本按照价格高低排序的对象，如今需要按照销量高低排序，使用稳定性算法，可以使得想同销量的对象依旧保持着价格高低的排序展现，只有销量不同的才会重新排序。（当然，如果需求不需要保持初始的排序意义，那么使用稳定性算法依旧将毫无意义）。工业界的意义1. 排序数值关联到其他信息，并且其他信息也会影响到顺序2. 排序算法影响到程序的健壮性3. 多次排序，想要延续以前排序顺序
```
