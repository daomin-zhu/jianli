悲观锁乐观锁
```
悲观锁:
定义:
    使用时锁定共享资源,使用后释放共享资源,使用期间其他线程不能访问
    总是认为线程不安全，不管什么情况都进行加锁，要是获取锁失败，就阻塞
乐观锁:
定义:
    读资源的时候不会锁定资源,在更新的时候判断资源是否被其他线程更新过
    总是认为是线程安全的，不怕别的线程修改变量，如果修改了我就再重新尝试
--------------------------------------------------------------------
实现:
    版本号机制:
        线程在读取数据时会获取版本号的值,在更新时会先判断版本值是否与
        之前读取的版本值一致,一致则更新数据,不一致重试更新操作
        直到更新成功
    CAS算法实现:
        compare and swap（比较与交换），是一种有名的无锁算法
        通过V(内存中的值)E(预期的值)N(新值)来实现CAS算法
        线程先比较V是否等于E,如果是表明V没有被处理过,可以直接处理，
        并将处理后的值N存入内存;如果V不等于E,表明V已经被处理过，线程
        从内存中获取并更新V值,知道V等于E,只进行处理
--------------------------------------------------------------
两种锁的使用场景:
    乐观锁适用于写比较少的情况,因为减少了资源的锁定,能够提高整个系统的吞吐量
    其他情况下用悲观锁比较合适
    可以理解为乐观锁处理资源抢夺的耗时比较大,但是处理的次数很少
    悲观锁为处理资源抢夺时耗时比较下,但是没次都会处理
```
读写锁
```
读锁:
    当读写锁被加了读锁时,其他线程对该锁加写锁会阻塞,加读锁会成功。
写锁:
    当读写锁被加了写锁时,其他线程对该锁加读锁或者写锁都会阻塞(不是失败)。
-------------------------------------------------------------------
```
公平锁与非公平锁
```
公平锁:
    定义:
        多个线程按照申请锁的顺序去获得锁,线程会直接去进入队列去排队,
        永远都是队列的第一位才能得到锁
    优点:
        所有的线程都能得到资源,不会饿死在队列中
    缺点:
        吞吐量会下降很多,队列里处理第一个线程,其他的线程都会阻塞,
        cpu唤醒阻塞线程的开销会很大
非公平锁:
    定义:
        多个线程去获取锁的时候,会直接去尝试获取,获取不到,在去进入等待队列,
        如果能够获取到,就直接获取到锁
    优点:
        可以减少CPU唤醒线程的开销,整体的吞吐效率会高点,CPU也不必去唤醒所有线程,
        会减少唤起线程的数量
    缺点:
        可能导致队列中的线程一致获取不到锁或者长时间获取不到锁,
        导致饿死
    
```
互斥锁与自旋锁
```
定义:
    互斥锁:
        睡眠类型的锁,获取锁失败,会陷入休眠,获取成功后在唤醒线程;
    自旋锁:
        一直占用CPU,在未获得锁的情况下,一直运行
原理:
    互斥锁:
        线程会从sleep(加锁)-->running(解锁),过程中有上下文的切换,
        cpu的抢占,信号的发送等开销
    自旋锁:
        线程一直是running(枷锁-->解锁),死循环检测锁的标志位,机制不复杂
区别:
    互斥锁的起始开销要高于自旋锁,但是基本是一劳永逸
    自旋锁是死循环检测,加锁会全程消耗CPU,开销会随持锁时间线性增长

```
可重入锁与不可重入锁
```
可重入锁:
定义:
    当一个线程获取了某个对象锁以后，还可以再次获得该对象锁
使用场景:
    可重入锁最大作用是避免死锁。
    当一个线程执行一个带锁的代码块或方法，同时代码块或方法里也获取同一个锁

不可重入锁:
    资源在释放前阻塞其他调用方,拒绝其他线程访问

```

进程与线程的区别
```
进程：
定义:
    在操作系统中能够独立运行，并且作为资源分配的基本单位。
    它表示运行中的程序。系统运行一个程序就是一个进程从创建、运行到消亡的过程。
线程：
定义:
    是一个比进程更小的执行单位，能够完成进程中的一个功能，也被称为轻量级进程。
    一个进程在其执行的过程中可以产生多个线程。同类的多个线程共享进程的堆和方法区资源，
    但每个线程有自己的程序计数器、虚拟机栈和本地方法栈，所以系统在产生一个线程，
    或是在各个线程之间作切换工作时，负担要比进程小得多
线程共享的环境包括：
    进程代码段、进程的公有数据(利用这些共享的数据，线程很容易的实现相互之间的通讯)、
    进程打开的文件描述符、信号的处理器、进程的当前目录和进程用户ID与进程组ID。
```
上下文切换
```
    CPU通过时间片分配算法循环执行任务,当前任务执行一个时间片后会切换到下一个任务
    线程切换前会保存上一个任务的状态,以便下次切换回这个任务时,可以再加载这个任务的状态
```
并发与并行
 ```
    并发指的是多个任务交替进行
    并行则是指真正意义上的“同时进行”。
```
什么是线程死锁?如何避免死锁?
```
线程死锁:
    多个线程同时等待某个资源被释放,无限期被阻塞
避免死锁的几个常见方法：
    避免一个线程同时获取多个锁
    避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。
    尝试使用定时锁，使用 lock.tryLock(timeout) 来代替使用内部锁机制。
    对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。
```
线程安全问题
```
线程安全:
    多个线程访问某个方法时,不需要做任何同步操作,每次执行的结果完全一致
    这样即可认为该方法线程安全

线程安全问题:
    指的是在某一线程从开始访问到结束访问某一数据期间，该数据被其他的线程所修改，
    那么对于当前线程而言，该线程就发生了线程安全问题，
    表现形式为数据的缺失，数据不一致等。
线程安全问题发生的条件：
　　　　1）多线程环境下，即存在包括自己在内存在有多个线程。
　　　　2）多线程环境下存在共享资源，且多线程操作该共享资源。
　　　　3）多个线程必须对该共享资源有非原子性操作。
线程安全问题的解决思路：
　　　　1）尽量不使用共享变量，将不必要的共享变量变成局部变量来使用。
　　　　2）使用synchronized关键字同步代码块，或者使用jdk包中提供的Lock为操作进行加锁。
　　　　3）使用ThreadLocal为每一个线程建立一个变量的副本，各个线程间独立操作，互不影响。
```
活跃性问题
```
    死锁: 
        假如线程 A 持有资源 2，线程 B 持有资源 
        1，他们同时都想申请对方的资源，所以这两个线程就会互相等待而进入死锁状态。
            多个线程环形占用资源也是一样的会产生死锁问题。
　　解决方法：
        避免一个线程同时获取多个锁
    避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。
    尝试使用定时锁，使用 lock.tryLock(timeout) 来代替使用内部锁机制。
　　想要避免死锁，可以使用无锁函数（cas）或者使用重入锁（ReentrantLock），
通过重入锁使线程中断或限时等待可以有效的规避死锁问题。

　　饥饿:
        饥饿指的是某一线程或多个线程因为某些原因一直获取不到资源，导致程序一直无法执行。
        如某一线程优先级太低导致一直分配不到资源，或者是某一线程一直占着某种资源不放，
        导致该线程无法执行等。
　　解决方法：
　　    与死锁相比，饥饿现象还是有可能在一段时间之后恢复执行的。
        可以设置合适的线程优先级来尽量避免饥饿的产生。
　　活锁: 
        活锁体现了一种谦让的美德，每个线程都想把资源让给对方，但是由于机器“智商”不够，可能会产生一直将资源让来让去，
        导致资源在两个线程间跳动而无法使某一线程真正的到资源并执行，这就是活锁的问题。
```
阻塞
```
　　几个线程之间共享临界区资源，那么当一个线程占用了临界区资源后，
    所有需要使用该资源的线程都需要进入该临界区等待，
    等待会导致线程挂起，一直不能工作，这种情况就是阻塞，
    如果某一线程一直都不释放资源，将会导致其他所有等待在这个临界区的线程都不能工作。

　解决方法：
　　可以通过减少锁持有时间，读写锁分离，减小锁的粒度，
    锁分离，锁粗化等方式来优化锁的性能。
```
线程间的同步方式
```
临界区、互斥对象：
    主要用于互斥控制；都具有拥有权的控制方法，
    只有拥有该对象的线程才能执行任务，所以拥有，执行完任务后一定要释放该对象。
信号量、事件对象：
    事件对象是以通知的方式进行控制，主要用于同步控制

临界区：
    通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。
    在任意时刻只允许一个线程对共享资源进行访问，如果有多个线程试图访问公共资源，
    那么在有一个线程进入后，其他试图访问公共资源的线程将被挂起，
    并一直等到进入临界区的线程离开，临界区在被释放后，其他线程才可以抢占。
    它并不是核心对象，不是属于操作系统维护的，而是属于进程维护的。
总结下关键段：
    1）关键段共初始化化、销毁、进入和离开关键区域四个函数。
    2）关键段可以解决线程的互斥问题，但因为具有“线程所有权”，所以无法解决同步问题。
    3）推荐关键段与旋转锁配合使用。

互斥对象：
    互斥对象和临界区很像，采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。
    因为互斥对象只有一个，所以能保证公共资源不会同时被多个线程同时访问。
    当前拥有互斥对象的线程处理完任务后必须将线程交出，以便其他线程访问该资源。
总结下互斥量Mutex：
    1）互斥量是内核对象，它与关键段都有“线程所有权”所以不能用于线程的同步。
    2）互斥量能够用于多个进程之间线程互斥问题，并且能完美的解决某进程意外终止所造成的“遗弃”问题。
3、信号量：
    信号量也是内核对象。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目
    在用CreateSemaphore()创建信号量时即要同时指出允许的最大资源计数和当前可用资源计数。
    一般是将当前可用资源计数设置为最 大资源计数，每增加一个线程对共享资源的访问，当前可用资源计数就会减1 ，
    只要当前可用资源计数是大于0 的，就可以发出信号量信号。但是当前可用计数减小 到0 时则说明当前占用资源的线程数已经达到了所允许的最大数目，
    不能在允许其他线程的进入，此时的信号量信号将无法发出。线程在处理完共享资源后，应在离 开的同时通过ReleaseSemaphore （）函数将当前可用资源计数加1 。
    在任何时候当前可用资源计数决不可能大于最大资源计数。
4、事件对象： 
    通过通知操作的方式来保持线程的同步，还可以方便实现对多个线程的优先级比较的操作
总结下事件Event
    1）事件是内核对象，事件分为手动置位事件和自动置位事件。事件Event内部它包含一个使用计数（所有内核对象都有），
        一个布尔值表示是手动置位事件还是自动置位事件，另一个布尔值用来表示事件有无触发。
    2）事件可以由SetEvent()来触发，由ResetEvent()来设成未触发。还可以由PulseEvent()来发出一个事件脉冲。
    3）事件可以解决线程间同步问题，因此也能解决互斥问题。
```
多线程的锁
```
pthread_mutex_t是互斥锁:
    同一瞬间只能有一个线程能够获取锁，其他线程在等待获取锁的时候会进入休眠状态。
    因此pthread_mutex_t消耗的CPU资源很小，但是性能不高，因为会引起线程切换。
pthread_spinlock_t是自旋锁:
    同一瞬间也只能有一个线程能够获取锁，不同的是，其他线程在等待获取锁的过程中并不进入睡眠状态，而是在 CPU上进入“自旋”等待。
    自旋锁的性能很高，但是只适合对很小的代码段加锁（或短期持有的锁），自旋锁对CPU的占用相对较高。
pthread_rwlock_t是读写锁:
    同时可以有多个线程获得读锁，同时只允许有一个线程获得写锁。其他线程在等待锁的时候同样会进入睡眠。
    读写锁在互斥锁的基础上，允许多个线程“读”，在某些场景下能提高性能。
```

Singleton的线程安全是个很有意思而且容易出错的话题
```
懒汉式(线程不安全)
    SingleInstance *SingleInstance::m_SingleInstance = NULL;
    SingleInstance* SingleInstance::GetInstance()
    {
	    if (m_SingleInstance == NULL)
	    {
		    m_SingleInstance = new (std::nothrow) SingleInstance;  
            // 没有加锁是线程不安全的，当线程并发时会创建多个实例
	    }
        return m_SingleInstance;
    }

懒汉式(线程安全)
//初始化静态成员变量
SingleInstance *SingleInstance::m_SingleInstance = NULL;
std::mutex SingleInstance::m_Mutex;
SingleInstance *&SingleInstance::GetInstance()
{
    //  这里使用了两个 if判断语句的技术称为双检锁；好处是，只有判断指针为空的时候才加锁，
    //  避免每次调用 GetInstance的方法都加锁，锁的开销毕竟还是有点大的。
    if (m_SingleInstance == NULL) 
    {
        std::unique_lock<std::mutex> lock(m_Mutex); // 加锁
        if (m_SingleInstance == NULL)
        {
            m_SingleInstance = new (std::nothrow) SingleInstance;
        }
    }
    return m_SingleInstance;
}

饿汉式(线程安全)
// 唯一单实例对象指针
static Singleton *g_pSingleton;
// 代码一运行就初始化创建实例 ，本身就线程安全
Singleton* Singleton::g_pSingleton = new (std::nothrow) Singleton;
Singleton* Singleton::GetInstance()
{
    return g_pSingleton;
}
```
进程间通信的方式
```
管道：
    主要包括无名管道和命名管道:管道可用于具有亲缘关系的父子进程间的通信，
    有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信

    普通管道PIPE：
        它是半双工的（即数据只能在一个方向上流动），具有固定的读端和写端
        它只能用于具有亲缘关系的进程之间的通信（也是父子进程或者兄弟进程之间）
        它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write等函数。
        但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。
    命名管道FIFO：
        FIFO可以在无关的进程之间交换数据
        FIFO有路径名与之相关联，它以一种特殊设备文件形式存在于文件系统中。
系统IPC：
消息队列:
    是消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列ID）来标记。 
    具有写权限得进程可以按照一定得规则向消息队列中添加新信息；
    对消息队列有读权限得进程则可以从消息队列中读取信息；

特点：
    消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级。
    消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。
    消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取。

信号量semaphore:
    它是一个计数器，可以用来控制多个进程对共享资源的访问。
    信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。

特点：
    信号量用于进程间同步，若要在进程间传递数据需要结合共享内存。
    信号量基于操作系统的 PV 操作，程序对信号量的操作都是原子操作。
    每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数。
    支持信号量组。

信号signal
    信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。

共享内存:
    它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。
    这种方式需要依靠某种同步操作，如互斥锁和信号量等
特点：
    共享内存是最快的一种IPC，因为进程是直接对内存进行存取
    因为多个进程可以同时操作，所以需要进行同步
    信号量+共享内存通常结合在一起使用，信号量用来同步对共享内存的访问
套接字SOCKET：
    socket也是一种进程间通信机制，与其他通信机制不同的是，
    它可用于不同主机之间的进程通信。

线程间通信的方式:

临界区：
    通过多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问；
互斥量Synchronized/Lock：
    采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问

信号量Semphare：
    为控制具有有限数量的用户资源而设计的，它允许多个线程在同一时刻去访问同一个资源，但一般需要限制同一时刻访问此资源的最大线程数目。
事件(信号)，Wait/Notify：
    通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作
```
线程同步方式
```
信号量：
    信号量是一种特殊的变量，可用于线程同步。它只取自然数值，并且只支持两种操作：
    P(SV):如果信号量SV大于0，将它减一；如果SV值为0，则挂起该线程。
    V(SV)：如果有其他进程因为等待SV而挂起，则唤醒，然后将SV+1；否则直接将SV+1。
其系统调用为：
    sem_wait（sem_t *sem）：
        以原子操作的方式将信号量减1，如果信号量值为0，
        则sem_wait将被阻塞，直到这个信号量具有非0值。
    sem_post（sem_t *sem)：
        以原子操作将信号量值+1。当信号量大于0时，
        其他正在调用sem_wait等待信号量的线程将被唤醒。

互斥量：
    主要用于线程互斥，不能保证按序访问，可以和条件锁一起实现同步。当进入临界区时，
    需要获得互斥锁并且加锁；当离开临界区时，需要对互斥锁解锁，
    以唤醒其他等待该互斥锁的线程。
其主要的系统调用如下：
    pthread_mutex_init:
        初始化互斥锁
    pthread_mutex_destroy：
        销毁互斥锁
    pthread_mutex_lock：
        以原子操作的方式给一个互斥锁加锁，如果目标互斥锁已经被上锁，
        pthread_mutex_lock调用将阻塞，直到该互斥锁的占有者将其解锁。
    pthread_mutex_unlock:
        以一个原子操作的方式给一个互斥锁解锁。
条件变量：
    用于在线程之间同步共享数据的值。
    条件变量提供一种线程间通信机制：
        当某个共享数据达到某个值时，唤醒等待这个共享数据的一个/多个线程。
        即，当某个共享变量等于某个值时，调用 signal/broadcast。此时操作共享变量时需要加锁。
    其主要的系统调用如下：
        pthread_cond_init:
            初始化条件变量
        pthread_cond_destroy：
            销毁条件变量
        pthread_cond_signal：
            唤醒一个等待目标条件变量的线程。哪个线程被唤醒取决于调度策略和优先级。
        pthread_cond_wait：
            等待目标条件变量。需要一个加锁的互斥锁确保操作的原子性。
            该函数中在进入wait状态前首先进行解锁，然后接收到信号后会再加锁，
            保证该线程对共享资源正确访问。
```

死锁的原理以及写一个死锁
```
产生死锁的四个必要条件：
互斥条件：一个资源每次只能被一个进程使用。
请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
不剥夺条件:进程已获得的资源，在末使用完之前，不能强行剥夺。
循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系

//线程1
void* threadFunc1(void* p)
{
    //printf("thread 1 running..\n");
    pthread_mutex_lock(&m_mutex1);
    A = 1;
    printf("thread 1 write source A\n");
    usleep(100);
    
    pthread_mutex_lock(&m_mutex2);
    B = 1;
    printf("thread 1 write source B\n");
    
    //解锁，实际上是跑不到这里的，因为前面已经死锁了
    pthread_mutex_unlock(&m_mutex2);
    pthread_mutex_unlock(&m_mutex1);
    
    return NULL;
}
 
//线程2
void* threadFunc2(void* p)
{
    //printf("thread 2 running..\n");
    pthread_mutex_lock(&m_mutex2);
    B = 1;
    printf("thread 2 write source B\n");
    usleep(100);
    
    pthread_mutex_lock(&m_mutex1);
    A = 1;
    printf("thread 2 write source A\n");
    
    //解锁，实际上是跑不到这里的，因为前面已经死锁了
    pthread_mutex_unlock(&m_mutex1);
    pthread_mutex_unlock(&m_mutex2);
    
    return NULL;
}

```
如何避免多线程的虚假唤醒问题。
```
虚假唤醒: 
    指条件变量会在条件不符合的时候也会唤醒,
    所以需要使用死循环来等待条件变量唤醒，避免丢失
```
2 magic fork了解吗？惊群问题知道吗？Nginx是如何解决的？
```
惊群:
    多个进程同时等待网络的连接事件，当这个事件发生时，这些进程被同时唤醒
Nginx中使用mutex互斥锁:
    使用全局互斥锁，每个子进程在epoll_wait()之前先去申请锁，申请到则继续处理，
    获取不到则等待，并设置了一个负载均衡的算法
    （当某一个子进程的任务量达到总设置量的7/8时，则不会再尝试去申请锁）来均衡各个进程的任务量
```
尝试多种方法实现一个守护进程，
```
int Create_Daemon()
{
    int pid;
    //屏蔽一些控制终端信号    
    signal(SIGTTOU,SIG_IGN);   
    signal(SIGTTIN,SIG_IGN);   
    signal(SIGTSTP,SIG_IGN);   
    signal(SIGHUP ,SIG_IGN); 
    //设置文件掩码
    umask(0);
    //调用fork函数，父进程退出
    pid = fork();
    if(pid < 0 )
    {
        printf("error fork");
        return -1;
    }
    else if(pid > 0)
    {//father
        exit(0);
    }
    //设置新会话
    setsid();
    //处理SIGCHlD信号
    signal(SIGCHLD,SIG_IGN);
    //禁止进程重新打开控制终端
    if(pid = fork())
    {//father
        exit(0);
    }
    else if(pid <0)
    {
        perror("fork");
        exit(-1);
    }
    //关闭打开的文件描述符
    close(0);close(1);close(2);
    //改变当前的工作目录
    chdir("/");
    return 0;
}
int main()
{
    Create_Daemon();
    while(1);
    return 0;
}
```


memory barrier:
```
即内存屏障：虽然你的代码是这么一行一行写下去，但是不管是编译器，还是CPU，
            都会按照自己的意思，看着高兴用不同的顺序来执行你的代码。
            所以有可能写在前面的代码被放在后面执行。因此你需要通过一系列的barrier和其他标记，
            来告诉它们，哪些移动是不行的，什么时候要刷cache，什么时候要同步。
```
BlockingQueue
```
LinkedBlockingQueue中维持两把锁，一把锁用于入队，一把锁用于出队，这也就意味着，同一时刻，
只能有一个线程执行入队，其余执行入队的线程将会被阻塞；同时，可以有另一个线程执行出队，
其余执行出队的线程将会被阻塞。换句话说，虽然入队和出队两个操作同时均只能有一个线程操作，
但是可以一个入队线程和一个出队线程共同执行，也就意味着可能同时有两个线程在操作队列，那么为了维持线程安全，
LinkedBlockingQueue使用一个AtomicInterger类型的变量表示当前队列中含有的元素个数，
所以可以确保两个线程之间操作底层队列是线程安全的。

```